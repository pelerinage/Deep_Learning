{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1JBKb7g770-E",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1JBKb7g770-E",
    "outputId": "ec6f1104-f7a9-46fa-cd44-36c2bb722e87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'TTS'...\n",
      "remote: Enumerating objects: 32844, done.\u001b[K\n",
      "remote: Counting objects: 100% (40/40), done.\u001b[K\n",
      "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
      "remote: Total 32844 (delta 21), reused 27 (delta 17), pack-reused 32804\u001b[K\n",
      "Receiving objects: 100% (32844/32844), 166.21 MiB | 25.20 MiB/s, done.\n",
      "Resolving deltas: 100% (23813/23813), done.\n",
      "Ignoring numpy: markers 'python_version > \"3.10\"' don't match your environment\n",
      "Ignoring numba: markers 'python_version < \"3.9\"' don't match your environment\n",
      "Collecting numpy==1.22.0 (from -r /content/TTS/requirements.txt (line 2))\n",
      "  Downloading numpy-1.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: cython>=0.29.30 in /usr/local/lib/python3.10/dist-packages (from -r /content/TTS/requirements.txt (line 4)) (3.0.8)\n",
      "Requirement already satisfied: scipy>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from -r /content/TTS/requirements.txt (line 5)) (1.11.4)\n",
      "Requirement already satisfied: torch>=2.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/TTS/requirements.txt (line 6)) (2.1.0+cu121)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from -r /content/TTS/requirements.txt (line 7)) (2.1.0+cu121)\n",
      "Requirement already satisfied: soundfile>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/TTS/requirements.txt (line 8)) (0.12.1)\n",
      "Requirement already satisfied: librosa>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/TTS/requirements.txt (line 9)) (0.10.1)\n",
      "Collecting scikit-learn>=1.3.0 (from -r /content/TTS/requirements.txt (line 10))\n",
      "  Downloading scikit_learn-1.4.1.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m94.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numba>=0.57.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/TTS/requirements.txt (line 12)) (0.58.1)\n",
      "Requirement already satisfied: inflect>=5.6.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/TTS/requirements.txt (line 13)) (7.0.0)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/TTS/requirements.txt (line 14)) (4.66.2)\n",
      "Collecting anyascii>=0.3.0 (from -r /content/TTS/requirements.txt (line 15))\n",
      "  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=6.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/TTS/requirements.txt (line 16)) (6.0.1)\n",
      "Requirement already satisfied: fsspec>=2023.6.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/TTS/requirements.txt (line 17)) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/TTS/requirements.txt (line 18)) (3.9.3)\n",
      "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/TTS/requirements.txt (line 19)) (23.2)\n",
      "Collecting mutagen==1.47.0 (from -r /content/TTS/requirements.txt (line 20))\n",
      "  Downloading mutagen-1.47.0-py3-none-any.whl (194 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: flask>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/TTS/requirements.txt (line 22)) (2.2.5)\n",
      "Collecting pysbd>=0.3.4 (from -r /content/TTS/requirements.txt (line 24))\n",
      "  Downloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting umap-learn>=0.5.1 (from -r /content/TTS/requirements.txt (line 26))\n",
      "  Downloading umap-learn-0.5.5.tar.gz (90 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.9/90.9 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: pandas<2.0,>=1.4 in /usr/local/lib/python3.10/dist-packages (from -r /content/TTS/requirements.txt (line 27)) (1.5.3)\n",
      "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/TTS/requirements.txt (line 29)) (3.7.1)\n",
      "Collecting trainer>=0.0.36 (from -r /content/TTS/requirements.txt (line 31))\n",
      "  Downloading trainer-0.0.36-py3-none-any.whl (51 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.2/51.2 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting coqpit>=0.0.16 (from -r /content/TTS/requirements.txt (line 33))\n",
      "  Downloading coqpit-0.0.17-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from -r /content/TTS/requirements.txt (line 35)) (0.42.1)\n",
      "Collecting pypinyin (from -r /content/TTS/requirements.txt (line 36))\n",
      "  Downloading pypinyin-0.50.0-py2.py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting hangul_romanize (from -r /content/TTS/requirements.txt (line 38))\n",
      "  Downloading hangul_romanize-0.1.0-py3-none-any.whl (4.6 kB)\n",
      "Collecting gruut[de,es,fr]==2.2.3 (from -r /content/TTS/requirements.txt (line 40))\n",
      "  Downloading gruut-2.2.3.tar.gz (73 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting jamo (from -r /content/TTS/requirements.txt (line 42))\n",
      "  Downloading jamo-0.4.1-py3-none-any.whl (9.5 kB)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from -r /content/TTS/requirements.txt (line 43)) (3.8.1)\n",
      "Collecting g2pkk>=0.1.1 (from -r /content/TTS/requirements.txt (line 44))\n",
      "  Downloading g2pkk-0.1.2-py3-none-any.whl (25 kB)\n",
      "Collecting bangla (from -r /content/TTS/requirements.txt (line 46))\n",
      "  Downloading bangla-0.0.2-py2.py3-none-any.whl (6.2 kB)\n",
      "Collecting bnnumerizer (from -r /content/TTS/requirements.txt (line 47))\n",
      "  Downloading bnnumerizer-0.0.2.tar.gz (4.7 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting bnunicodenormalizer (from -r /content/TTS/requirements.txt (line 48))\n",
      "  Downloading bnunicodenormalizer-0.1.6.tar.gz (39 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting einops>=0.6.0 (from -r /content/TTS/requirements.txt (line 50))\n",
      "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: transformers>=4.33.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/TTS/requirements.txt (line 51)) (4.37.2)\n",
      "Collecting encodec>=0.1.1 (from -r /content/TTS/requirements.txt (line 53))\n",
      "  Downloading encodec-0.1.1.tar.gz (3.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m102.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting unidecode>=1.3.2 (from -r /content/TTS/requirements.txt (line 55))\n",
      "  Downloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting num2words (from -r /content/TTS/requirements.txt (line 56))\n",
      "  Downloading num2words-0.5.13-py3-none-any.whl (143 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.3/143.3 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy[ja]>=3 in /usr/local/lib/python3.10/dist-packages (from -r /content/TTS/requirements.txt (line 57)) (3.7.4)\n",
      "Requirement already satisfied: Babel<3.0.0,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3->-r /content/TTS/requirements.txt (line 40)) (2.14.0)\n",
      "Collecting dateparser~=1.1.0 (from gruut[de,es,fr]==2.2.3->-r /content/TTS/requirements.txt (line 40))\n",
      "  Downloading dateparser-1.1.8-py2.py3-none-any.whl (293 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.8/293.8 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting gruut-ipa<1.0,>=0.12.0 (from gruut[de,es,fr]==2.2.3->-r /content/TTS/requirements.txt (line 40))\n",
      "  Downloading gruut-ipa-0.13.0.tar.gz (101 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting gruut_lang_en~=2.0.0 (from gruut[de,es,fr]==2.2.3->-r /content/TTS/requirements.txt (line 40))\n",
      "  Downloading gruut_lang_en-2.0.0.tar.gz (15.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.2/15.2 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting jsonlines~=1.2.0 (from gruut[de,es,fr]==2.2.3->-r /content/TTS/requirements.txt (line 40))\n",
      "  Downloading jsonlines-1.2.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting networkx<3.0.0,>=2.5.0 (from gruut[de,es,fr]==2.2.3->-r /content/TTS/requirements.txt (line 40))\n",
      "  Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting python-crfsuite~=0.9.7 (from gruut[de,es,fr]==2.2.3->-r /content/TTS/requirements.txt (line 40))\n",
      "  Downloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting gruut_lang_es~=2.0.0 (from gruut[de,es,fr]==2.2.3->-r /content/TTS/requirements.txt (line 40))\n",
      "  Downloading gruut_lang_es-2.0.0.tar.gz (31.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting gruut_lang_fr~=2.0.0 (from gruut[de,es,fr]==2.2.3->-r /content/TTS/requirements.txt (line 40))\n",
      "  Downloading gruut_lang_fr-2.0.2.tar.gz (10.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting gruut_lang_de~=2.0.0 (from gruut[de,es,fr]==2.2.3->-r /content/TTS/requirements.txt (line 40))\n",
      "  Downloading gruut_lang_de-2.0.0.tar.gz (18.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->-r /content/TTS/requirements.txt (line 6)) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->-r /content/TTS/requirements.txt (line 6)) (4.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->-r /content/TTS/requirements.txt (line 6)) (1.12)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->-r /content/TTS/requirements.txt (line 6)) (3.1.3)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->-r /content/TTS/requirements.txt (line 6)) (2.1.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.0->-r /content/TTS/requirements.txt (line 8)) (1.16.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->-r /content/TTS/requirements.txt (line 9)) (3.0.1)\n",
      "INFO: pip is looking at multiple versions of librosa to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting librosa>=0.10.0 (from -r /content/TTS/requirements.txt (line 9))\n",
      "  Downloading librosa-0.10.0.post2-py3-none-any.whl (253 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading librosa-0.10.0.post1-py3-none-any.whl (252 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading librosa-0.10.0-py3-none-any.whl (252 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.9/252.9 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->-r /content/TTS/requirements.txt (line 9)) (1.3.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->-r /content/TTS/requirements.txt (line 9)) (4.4.2)\n",
      "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->-r /content/TTS/requirements.txt (line 9)) (1.8.0)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->-r /content/TTS/requirements.txt (line 9)) (0.3.7)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->-r /content/TTS/requirements.txt (line 9)) (0.3)\n",
      "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->-r /content/TTS/requirements.txt (line 9)) (1.0.7)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->-r /content/TTS/requirements.txt (line 10)) (3.3.0)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.57.0->-r /content/TTS/requirements.txt (line 12)) (0.41.1)\n",
      "Requirement already satisfied: pydantic>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from inflect>=5.6.0->-r /content/TTS/requirements.txt (line 13)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->-r /content/TTS/requirements.txt (line 18)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->-r /content/TTS/requirements.txt (line 18)) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->-r /content/TTS/requirements.txt (line 18)) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->-r /content/TTS/requirements.txt (line 18)) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->-r /content/TTS/requirements.txt (line 18)) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->-r /content/TTS/requirements.txt (line 18)) (4.0.3)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask>=2.0.1->-r /content/TTS/requirements.txt (line 22)) (3.0.1)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask>=2.0.1->-r /content/TTS/requirements.txt (line 22)) (2.1.2)\n",
      "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask>=2.0.1->-r /content/TTS/requirements.txt (line 22)) (8.1.7)\n",
      "Collecting pynndescent>=0.5 (from umap-learn>=0.5.1->-r /content/TTS/requirements.txt (line 26))\n",
      "  Downloading pynndescent-0.5.11-py3-none-any.whl (55 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0,>=1.4->-r /content/TTS/requirements.txt (line 27)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0,>=1.4->-r /content/TTS/requirements.txt (line 27)) (2023.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->-r /content/TTS/requirements.txt (line 29)) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->-r /content/TTS/requirements.txt (line 29)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->-r /content/TTS/requirements.txt (line 29)) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->-r /content/TTS/requirements.txt (line 29)) (1.4.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->-r /content/TTS/requirements.txt (line 29)) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->-r /content/TTS/requirements.txt (line 29)) (3.1.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from trainer>=0.0.36->-r /content/TTS/requirements.txt (line 31)) (5.9.5)\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from trainer>=0.0.36->-r /content/TTS/requirements.txt (line 31)) (2.15.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->-r /content/TTS/requirements.txt (line 43)) (2023.12.25)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.33.0->-r /content/TTS/requirements.txt (line 51)) (0.20.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.33.0->-r /content/TTS/requirements.txt (line 51)) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.33.0->-r /content/TTS/requirements.txt (line 51)) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.33.0->-r /content/TTS/requirements.txt (line 51)) (0.4.2)\n",
      "Collecting docopt>=0.6.2 (from num2words->-r /content/TTS/requirements.txt (line 56))\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->-r /content/TTS/requirements.txt (line 57)) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->-r /content/TTS/requirements.txt (line 57)) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->-r /content/TTS/requirements.txt (line 57)) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->-r /content/TTS/requirements.txt (line 57)) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->-r /content/TTS/requirements.txt (line 57)) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->-r /content/TTS/requirements.txt (line 57)) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->-r /content/TTS/requirements.txt (line 57)) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->-r /content/TTS/requirements.txt (line 57)) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->-r /content/TTS/requirements.txt (line 57)) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->-r /content/TTS/requirements.txt (line 57)) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->-r /content/TTS/requirements.txt (line 57)) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->-r /content/TTS/requirements.txt (line 57)) (6.4.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->-r /content/TTS/requirements.txt (line 57)) (67.7.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->-r /content/TTS/requirements.txt (line 57)) (3.3.0)\n",
      "Collecting sudachipy!=0.6.1,>=0.5.2 (from spacy[ja]>=3->-r /content/TTS/requirements.txt (line 57))\n",
      "  Downloading SudachiPy-0.6.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m97.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sudachidict-core>=20211220 (from spacy[ja]>=3->-r /content/TTS/requirements.txt (line 57))\n",
      "  Downloading SudachiDict_core-20240109-py3-none-any.whl (71.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.8/71.8 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.0->-r /content/TTS/requirements.txt (line 8)) (2.21)\n",
      "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from dateparser~=1.1.0->gruut[de,es,fr]==2.2.3->-r /content/TTS/requirements.txt (line 40)) (5.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.1->-r /content/TTS/requirements.txt (line 6)) (2.1.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from jsonlines~=1.2.0->gruut[de,es,fr]==2.2.3->-r /content/TTS/requirements.txt (line 40)) (1.16.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa>=0.10.0->-r /content/TTS/requirements.txt (line 9)) (4.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.1->inflect>=5.6.0->-r /content/TTS/requirements.txt (line 13)) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.1->inflect>=5.6.0->-r /content/TTS/requirements.txt (line 13)) (2.16.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.33.0->-r /content/TTS/requirements.txt (line 51)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.33.0->-r /content/TTS/requirements.txt (line 51)) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.33.0->-r /content/TTS/requirements.txt (line 51)) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.33.0->-r /content/TTS/requirements.txt (line 51)) (2024.2.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy[ja]>=3->-r /content/TTS/requirements.txt (line 57)) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy[ja]>=3->-r /content/TTS/requirements.txt (line 57)) (0.1.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy[ja]>=3->-r /content/TTS/requirements.txt (line 57)) (0.16.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.1->-r /content/TTS/requirements.txt (line 6)) (1.3.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.36->-r /content/TTS/requirements.txt (line 31)) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.36->-r /content/TTS/requirements.txt (line 31)) (1.60.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.36->-r /content/TTS/requirements.txt (line 31)) (2.27.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.36->-r /content/TTS/requirements.txt (line 31)) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.36->-r /content/TTS/requirements.txt (line 31)) (3.5.2)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.36->-r /content/TTS/requirements.txt (line 31)) (3.20.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.36->-r /content/TTS/requirements.txt (line 31)) (0.7.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->trainer>=0.0.36->-r /content/TTS/requirements.txt (line 31)) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->trainer>=0.0.36->-r /content/TTS/requirements.txt (line 31)) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->trainer>=0.0.36->-r /content/TTS/requirements.txt (line 31)) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->trainer>=0.0.36->-r /content/TTS/requirements.txt (line 31)) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->trainer>=0.0.36->-r /content/TTS/requirements.txt (line 31)) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->trainer>=0.0.36->-r /content/TTS/requirements.txt (line 31)) (3.2.2)\n",
      "Building wheels for collected packages: umap-learn, bnnumerizer, bnunicodenormalizer, encodec, docopt, gruut-ipa, gruut_lang_de, gruut_lang_en, gruut_lang_es, gruut_lang_fr, gruut\n",
      "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for umap-learn: filename=umap_learn-0.5.5-py3-none-any.whl size=86832 sha256=6a034f765c7aea339b837d17f28cc15939b0626ee5bb5218537ea4d9626fd8ad\n",
      "  Stored in directory: /root/.cache/pip/wheels/3a/70/07/428d2b58660a1a3b431db59b806a10da736612ebbc66c1bcc5\n",
      "  Building wheel for bnnumerizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for bnnumerizer: filename=bnnumerizer-0.0.2-py3-none-any.whl size=5259 sha256=ed7d8f2f0a2e6dd206a6a8b6943cdb708ac046d6ce09b55480ea2c48ebb88bfc\n",
      "  Stored in directory: /root/.cache/pip/wheels/59/6b/e8/223172e7d5c9f72df3ea1a0d9258f3a8ab5b28e827728edef5\n",
      "  Building wheel for bnunicodenormalizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for bnunicodenormalizer: filename=bnunicodenormalizer-0.1.6-py3-none-any.whl size=22779 sha256=77466ba6224843aafcfd18c570326f9bb7d322000ce4b6d29924775a20b3ea9c\n",
      "  Stored in directory: /root/.cache/pip/wheels/f4/d7/e9/16732a619cbf5a63fdc9f6e2f9eb5fcf73fa023735237330e9\n",
      "  Building wheel for encodec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for encodec: filename=encodec-0.1.1-py3-none-any.whl size=45759 sha256=3e07cd6992eac9fc7f3ef48d8460149a07d01589147f8cc05104c8ca6e7ed649\n",
      "  Stored in directory: /root/.cache/pip/wheels/fc/36/cb/81af8b985a5f5e0815312d5e52b41263237af07b977e6bcbf3\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=d685225cff32aad09642ca02bb111424d8ce4646df03c17c821b1edf3c135c28\n",
      "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
      "  Building wheel for gruut-ipa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gruut-ipa: filename=gruut_ipa-0.13.0-py3-none-any.whl size=104873 sha256=67a3dcf2efcf94b29ffa85ea3887471fbd5106788420f5a9eeef4567d827cf6e\n",
      "  Stored in directory: /root/.cache/pip/wheels/7b/18/49/e4f500ecdf0babe757953f844e4d7cd1ea81c5503c09bfe984\n",
      "  Building wheel for gruut_lang_de (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gruut_lang_de: filename=gruut_lang_de-2.0.0-py3-none-any.whl size=18498182 sha256=e84c7facefae9f0ada298105dacb081f951761c4df8bc49a62ac07d93bd3ab4a\n",
      "  Stored in directory: /root/.cache/pip/wheels/95/9a/05/cfce98f0c41a1a540f15708c4a02df190b82d84cf91ef6bc7f\n",
      "  Building wheel for gruut_lang_en (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gruut_lang_en: filename=gruut_lang_en-2.0.0-py3-none-any.whl size=15297178 sha256=7887b3508c297f944aa268633e9348fa9ec3743926ab9a43f081acc5bf059011\n",
      "  Stored in directory: /root/.cache/pip/wheels/10/9c/fb/77c655a9fbd78cdb9935d0ab65d80ddd0a3bcf7dbe18261650\n",
      "  Building wheel for gruut_lang_es (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gruut_lang_es: filename=gruut_lang_es-2.0.0-py3-none-any.whl size=32173796 sha256=ac54f6d4fb0e05c8b3676d7073e26c491a5121d070eace8ec3f6f2bb33358f81\n",
      "  Stored in directory: /root/.cache/pip/wheels/9b/0a/90/788d92c07744b329b9283e37b29b064f5db6b1bb0442a1a19b\n",
      "  Building wheel for gruut_lang_fr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gruut_lang_fr: filename=gruut_lang_fr-2.0.2-py3-none-any.whl size=10968766 sha256=1cd5095d9ff01d78e9736c5b83fe8107c27c73ac2e5259fde23e5520a331d75c\n",
      "  Stored in directory: /root/.cache/pip/wheels/db/21/be/d0436e3f1cf9bf38b9bb9b4a476399c77a1ab19f7172b45e19\n",
      "  Building wheel for gruut (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gruut: filename=gruut-2.2.3-py3-none-any.whl size=75792 sha256=b8945f2a2f22addb36e6aea6f9ec5ddbff6b05bb37ac86bc677a49e5e6d5e7fd\n",
      "  Stored in directory: /root/.cache/pip/wheels/fc/57/a8/f9de532daf5214f53644f20f3a9e6f69269453c87df9c0a817\n",
      "Successfully built umap-learn bnnumerizer bnunicodenormalizer encodec docopt gruut-ipa gruut_lang_de gruut_lang_en gruut_lang_es gruut_lang_fr gruut\n",
      "Installing collected packages: sudachipy, python-crfsuite, jamo, hangul_romanize, gruut_lang_fr, gruut_lang_es, gruut_lang_en, gruut_lang_de, docopt, bnunicodenormalizer, bnnumerizer, bangla, unidecode, sudachidict-core, pysbd, pypinyin, numpy, num2words, networkx, mutagen, jsonlines, gruut-ipa, einops, coqpit, anyascii, g2pkk, dateparser, scikit-learn, gruut, pynndescent, librosa, encodec, umap-learn, trainer\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.25.2\n",
      "    Uninstalling numpy-1.25.2:\n",
      "      Successfully uninstalled numpy-1.25.2\n",
      "  Attempting uninstall: networkx\n",
      "    Found existing installation: networkx 3.2.1\n",
      "    Uninstalling networkx-3.2.1:\n",
      "      Successfully uninstalled networkx-3.2.1\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.2.2\n",
      "    Uninstalling scikit-learn-1.2.2:\n",
      "      Successfully uninstalled scikit-learn-1.2.2\n",
      "  Attempting uninstall: librosa\n",
      "    Found existing installation: librosa 0.10.1\n",
      "    Uninstalling librosa-0.10.1:\n",
      "      Successfully uninstalled librosa-0.10.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "chex 0.1.85 requires numpy>=1.24.1, but you have numpy 1.22.0 which is incompatible.\n",
      "plotnine 0.12.4 requires numpy>=1.23.0, but you have numpy 1.22.0 which is incompatible.\n",
      "pywavelets 1.5.0 requires numpy<2.0,>=1.22.4, but you have numpy 1.22.0 which is incompatible.\n",
      "tensorflow 2.15.0 requires numpy<2.0.0,>=1.23.5, but you have numpy 1.22.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed anyascii-0.3.2 bangla-0.0.2 bnnumerizer-0.0.2 bnunicodenormalizer-0.1.6 coqpit-0.0.17 dateparser-1.1.8 docopt-0.6.2 einops-0.7.0 encodec-0.1.1 g2pkk-0.1.2 gruut-2.2.3 gruut-ipa-0.13.0 gruut_lang_de-2.0.0 gruut_lang_en-2.0.0 gruut_lang_es-2.0.0 gruut_lang_fr-2.0.2 hangul_romanize-0.1.0 jamo-0.4.1 jsonlines-1.2.0 librosa-0.10.0 mutagen-1.47.0 networkx-2.8.8 num2words-0.5.13 numpy-1.22.0 pynndescent-0.5.11 pypinyin-0.50.0 pysbd-0.3.4 python-crfsuite-0.9.10 scikit-learn-1.4.1.post1 sudachidict-core-20240109 sudachipy-0.6.8 trainer-0.0.36 umap-learn-0.5.5 unidecode-1.3.8\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "63bf2238c10b475f88aa46305666efcd",
       "pip_warning": {
        "packages": [
         "numpy"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting TTS\n",
      "  Downloading TTS-0.22.0-cp310-cp310-manylinux1_x86_64.whl (938 kB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/938.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.2/938.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m931.8/938.0 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m938.0/938.0 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: cython>=0.29.30 in /usr/local/lib/python3.10/dist-packages (from TTS) (3.0.8)\n",
      "Requirement already satisfied: scipy>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from TTS) (1.11.4)\n",
      "Requirement already satisfied: torch>=2.1 in /usr/local/lib/python3.10/dist-packages (from TTS) (2.1.0+cu121)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from TTS) (2.1.0+cu121)\n",
      "Requirement already satisfied: soundfile>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.12.1)\n",
      "Requirement already satisfied: librosa>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.10.0)\n",
      "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (1.4.1.post1)\n",
      "Requirement already satisfied: inflect>=5.6.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (7.0.0)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from TTS) (4.66.2)\n",
      "Requirement already satisfied: anyascii>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.3.2)\n",
      "Requirement already satisfied: pyyaml>=6.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (6.0.1)\n",
      "Requirement already satisfied: fsspec>=2023.6.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from TTS) (3.9.3)\n",
      "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.10/dist-packages (from TTS) (23.2)\n",
      "Requirement already satisfied: flask>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from TTS) (2.2.5)\n",
      "Requirement already satisfied: pysbd>=0.3.4 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.3.4)\n",
      "Requirement already satisfied: umap-learn>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.5.5)\n",
      "Requirement already satisfied: pandas<2.0,>=1.4 in /usr/local/lib/python3.10/dist-packages (from TTS) (1.5.3)\n",
      "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (3.7.1)\n",
      "Requirement already satisfied: trainer>=0.0.32 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.0.36)\n",
      "Requirement already satisfied: coqpit>=0.0.16 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.0.17)\n",
      "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from TTS) (0.42.1)\n",
      "Requirement already satisfied: pypinyin in /usr/local/lib/python3.10/dist-packages (from TTS) (0.50.0)\n",
      "Requirement already satisfied: hangul-romanize in /usr/local/lib/python3.10/dist-packages (from TTS) (0.1.0)\n",
      "Requirement already satisfied: gruut[de,es,fr]==2.2.3 in /usr/local/lib/python3.10/dist-packages (from TTS) (2.2.3)\n",
      "Requirement already satisfied: jamo in /usr/local/lib/python3.10/dist-packages (from TTS) (0.4.1)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from TTS) (3.8.1)\n",
      "Requirement already satisfied: g2pkk>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.1.2)\n",
      "Requirement already satisfied: bangla in /usr/local/lib/python3.10/dist-packages (from TTS) (0.0.2)\n",
      "Requirement already satisfied: bnnumerizer in /usr/local/lib/python3.10/dist-packages (from TTS) (0.0.2)\n",
      "Requirement already satisfied: bnunicodenormalizer in /usr/local/lib/python3.10/dist-packages (from TTS) (0.1.6)\n",
      "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.7.0)\n",
      "Requirement already satisfied: transformers>=4.33.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (4.37.2)\n",
      "Requirement already satisfied: encodec>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.1.1)\n",
      "Requirement already satisfied: unidecode>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from TTS) (1.3.8)\n",
      "Requirement already satisfied: num2words in /usr/local/lib/python3.10/dist-packages (from TTS) (0.5.13)\n",
      "Requirement already satisfied: spacy[ja]>=3 in /usr/local/lib/python3.10/dist-packages (from TTS) (3.7.4)\n",
      "Requirement already satisfied: numpy==1.22.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (1.22.0)\n",
      "Requirement already satisfied: numba>=0.57.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.58.1)\n",
      "Requirement already satisfied: Babel<3.0.0,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3->TTS) (2.14.0)\n",
      "Requirement already satisfied: dateparser~=1.1.0 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3->TTS) (1.1.8)\n",
      "Requirement already satisfied: gruut-ipa<1.0,>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3->TTS) (0.13.0)\n",
      "Requirement already satisfied: gruut-lang-en~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3->TTS) (2.0.0)\n",
      "Requirement already satisfied: jsonlines~=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3->TTS) (1.2.0)\n",
      "Requirement already satisfied: networkx<3.0.0,>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3->TTS) (2.8.8)\n",
      "Requirement already satisfied: python-crfsuite~=0.9.7 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3->TTS) (0.9.10)\n",
      "Requirement already satisfied: gruut-lang-de~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3->TTS) (2.0.0)\n",
      "Requirement already satisfied: gruut-lang-es~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3->TTS) (2.0.0)\n",
      "Requirement already satisfied: gruut-lang-fr~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3->TTS) (2.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS) (4.0.3)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask>=2.0.1->TTS) (3.0.1)\n",
      "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask>=2.0.1->TTS) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask>=2.0.1->TTS) (2.1.2)\n",
      "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask>=2.0.1->TTS) (8.1.7)\n",
      "Requirement already satisfied: pydantic>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from inflect>=5.6.0->TTS) (2.6.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from inflect>=5.6.0->TTS) (4.9.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS) (3.0.1)\n",
      "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS) (1.3.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS) (4.4.2)\n",
      "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS) (1.8.0)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS) (0.3.7)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS) (0.3)\n",
      "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS) (1.0.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS) (1.4.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS) (2.8.2)\n",
      "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.10/dist-packages (from num2words->TTS) (0.6.2)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.57.0->TTS) (0.41.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0,>=1.4->TTS) (2023.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->TTS) (3.3.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.0->TTS) (1.16.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (6.4.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (67.7.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (3.3.0)\n",
      "Requirement already satisfied: sudachipy!=0.6.1,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (0.6.8)\n",
      "Requirement already satisfied: sudachidict-core>=20211220 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (20240109)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->TTS) (3.13.1)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->TTS) (1.12)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->TTS) (2.1.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from trainer>=0.0.32->TTS) (5.9.5)\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from trainer>=0.0.32->TTS) (2.15.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.33.0->TTS) (0.20.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.33.0->TTS) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.33.0->TTS) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.33.0->TTS) (0.4.2)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.10/dist-packages (from umap-learn>=0.5.1->TTS) (0.5.11)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.0->TTS) (2.21)\n",
      "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from dateparser~=1.1.0->gruut[de,es,fr]==2.2.3->TTS) (5.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask>=2.0.1->TTS) (2.1.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from jsonlines~=1.2.0->gruut[de,es,fr]==2.2.3->TTS) (1.16.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa>=0.10.0->TTS) (4.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.1->inflect>=5.6.0->TTS) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.1->inflect>=5.6.0->TTS) (2.16.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy[ja]>=3->TTS) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy[ja]>=3->TTS) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy[ja]>=3->TTS) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy[ja]>=3->TTS) (2024.2.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy[ja]>=3->TTS) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy[ja]>=3->TTS) (0.1.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy[ja]>=3->TTS) (0.16.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.1->TTS) (1.3.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (1.60.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (2.27.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (3.5.2)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (3.20.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (0.7.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->trainer>=0.0.32->TTS) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->trainer>=0.0.32->TTS) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->trainer>=0.0.32->TTS) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->trainer>=0.0.32->TTS) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->trainer>=0.0.32->TTS) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->trainer>=0.0.32->TTS) (3.2.2)\n",
      "Installing collected packages: TTS\n",
      "Successfully installed TTS-0.22.0\n"
     ]
    }
   ],
   "source": [
    "#colab setup\n",
    "\n",
    "!git clone https://github.com/coqui-ai/TTS\n",
    "!pip install -r /content/TTS/requirements.txt\n",
    "!pip install TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa2aec78",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fa2aec78",
    "outputId": "19a955a2-56ab-41a9-eade-493000d09df8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
      "Collecting pip\n",
      "  Downloading pip-24.0-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 23.1.2\n",
      "    Uninstalling pip-23.1.2:\n",
      "      Successfully uninstalled pip-23.1.2\n",
      "Successfully installed pip-24.0\n",
      "Requirement already satisfied: TTS in /usr/local/lib/python3.10/dist-packages (0.22.0)\n",
      "Requirement already satisfied: cython>=0.29.30 in /usr/local/lib/python3.10/dist-packages (from TTS) (3.0.8)\n",
      "Requirement already satisfied: scipy>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from TTS) (1.11.4)\n",
      "Requirement already satisfied: torch>=2.1 in /usr/local/lib/python3.10/dist-packages (from TTS) (2.1.0+cu121)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from TTS) (2.1.0+cu121)\n",
      "Requirement already satisfied: soundfile>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.12.1)\n",
      "Requirement already satisfied: librosa>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.10.0)\n",
      "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (1.4.1.post1)\n",
      "Requirement already satisfied: inflect>=5.6.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (7.0.0)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from TTS) (4.66.2)\n",
      "Requirement already satisfied: anyascii>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.3.2)\n",
      "Requirement already satisfied: pyyaml>=6.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (6.0.1)\n",
      "Requirement already satisfied: fsspec>=2023.6.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from TTS) (3.9.3)\n",
      "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.10/dist-packages (from TTS) (23.2)\n",
      "Requirement already satisfied: flask>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from TTS) (2.2.5)\n",
      "Requirement already satisfied: pysbd>=0.3.4 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.3.4)\n",
      "Requirement already satisfied: umap-learn>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.5.5)\n",
      "Requirement already satisfied: pandas<2.0,>=1.4 in /usr/local/lib/python3.10/dist-packages (from TTS) (1.5.3)\n",
      "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (3.7.1)\n",
      "Requirement already satisfied: trainer>=0.0.32 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.0.36)\n",
      "Requirement already satisfied: coqpit>=0.0.16 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.0.17)\n",
      "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from TTS) (0.42.1)\n",
      "Requirement already satisfied: pypinyin in /usr/local/lib/python3.10/dist-packages (from TTS) (0.50.0)\n",
      "Requirement already satisfied: hangul-romanize in /usr/local/lib/python3.10/dist-packages (from TTS) (0.1.0)\n",
      "Requirement already satisfied: gruut==2.2.3 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3->TTS) (2.2.3)\n",
      "Requirement already satisfied: jamo in /usr/local/lib/python3.10/dist-packages (from TTS) (0.4.1)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from TTS) (3.8.1)\n",
      "Requirement already satisfied: g2pkk>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.1.2)\n",
      "Requirement already satisfied: bangla in /usr/local/lib/python3.10/dist-packages (from TTS) (0.0.2)\n",
      "Requirement already satisfied: bnnumerizer in /usr/local/lib/python3.10/dist-packages (from TTS) (0.0.2)\n",
      "Requirement already satisfied: bnunicodenormalizer in /usr/local/lib/python3.10/dist-packages (from TTS) (0.1.6)\n",
      "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.7.0)\n",
      "Requirement already satisfied: transformers>=4.33.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (4.37.2)\n",
      "Requirement already satisfied: encodec>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.1.1)\n",
      "Requirement already satisfied: unidecode>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from TTS) (1.3.8)\n",
      "Requirement already satisfied: num2words in /usr/local/lib/python3.10/dist-packages (from TTS) (0.5.13)\n",
      "Requirement already satisfied: spacy>=3 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (3.7.4)\n",
      "Requirement already satisfied: numpy==1.22.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (1.22.0)\n",
      "Requirement already satisfied: numba>=0.57.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.58.1)\n",
      "Requirement already satisfied: Babel<3.0.0,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (2.14.0)\n",
      "Requirement already satisfied: dateparser~=1.1.0 in /usr/local/lib/python3.10/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (1.1.8)\n",
      "Requirement already satisfied: gruut-ipa<1.0,>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (0.13.0)\n",
      "Requirement already satisfied: gruut-lang-en~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (2.0.0)\n",
      "Requirement already satisfied: jsonlines~=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (1.2.0)\n",
      "Requirement already satisfied: networkx<3.0.0,>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (2.8.8)\n",
      "Requirement already satisfied: python-crfsuite~=0.9.7 in /usr/local/lib/python3.10/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (0.9.10)\n",
      "Requirement already satisfied: gruut-lang-fr~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3->TTS) (2.0.2)\n",
      "Requirement already satisfied: gruut-lang-de~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3->TTS) (2.0.0)\n",
      "Requirement already satisfied: gruut-lang-es~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3->TTS) (2.0.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS) (4.0.3)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask>=2.0.1->TTS) (3.0.1)\n",
      "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask>=2.0.1->TTS) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask>=2.0.1->TTS) (2.1.2)\n",
      "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask>=2.0.1->TTS) (8.1.7)\n",
      "Requirement already satisfied: pydantic>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from inflect>=5.6.0->TTS) (2.6.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from inflect>=5.6.0->TTS) (4.9.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS) (3.0.1)\n",
      "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS) (1.3.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS) (4.4.2)\n",
      "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS) (1.8.0)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS) (0.3.7)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS) (0.3)\n",
      "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS) (1.0.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS) (1.4.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS) (2.8.2)\n",
      "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.10/dist-packages (from num2words->TTS) (0.6.2)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.57.0->TTS) (0.41.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0,>=1.4->TTS) (2023.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->TTS) (3.3.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.0->TTS) (1.16.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (6.4.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (67.7.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (3.3.0)\n",
      "Requirement already satisfied: sudachipy!=0.6.1,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (0.6.8)\n",
      "Requirement already satisfied: sudachidict-core>=20211220 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (20240109)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->TTS) (3.13.1)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->TTS) (1.12)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->TTS) (2.1.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from trainer>=0.0.32->TTS) (5.9.5)\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from trainer>=0.0.32->TTS) (2.15.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.33.0->TTS) (0.20.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.33.0->TTS) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.33.0->TTS) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.33.0->TTS) (0.4.2)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.10/dist-packages (from umap-learn>=0.5.1->TTS) (0.5.11)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.0->TTS) (2.21)\n",
      "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from dateparser~=1.1.0->gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (5.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask>=2.0.1->TTS) (2.1.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from jsonlines~=1.2.0->gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (1.16.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa>=0.10.0->TTS) (4.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.1->inflect>=5.6.0->TTS) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.1->inflect>=5.6.0->TTS) (2.16.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->TTS) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->TTS) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->TTS) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->TTS) (2024.2.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy>=3->spacy[ja]>=3->TTS) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy>=3->spacy[ja]>=3->TTS) (0.1.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy>=3->spacy[ja]>=3->TTS) (0.16.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.1->TTS) (1.3.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (1.60.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (2.27.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (3.5.2)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (3.20.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (0.7.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->trainer>=0.0.32->TTS) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->trainer>=0.0.32->TTS) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->trainer>=0.0.32->TTS) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->trainer>=0.0.32->TTS) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->trainer>=0.0.32->TTS) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->trainer>=0.0.32->TTS) (3.2.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "## Install Coqui TTS\n",
    "! pip install -U pip\n",
    "! pip install TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "V5nCE-q1EwHr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "V5nCE-q1EwHr",
    "outputId": "8846d799-795d-4bbf-b323-87e5a05d1f6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.9.1\n",
      "  Downloading tensorflow-2.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (1.6.3)\n",
      "Collecting flatbuffers<2,>=1.12 (from tensorflow==2.9.1)\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.9.1)\n",
      "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (1.60.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (3.9.0)\n",
      "Collecting keras<2.10.0,>=2.9.0rc0 (from tensorflow==2.9.1)\n",
      "  Downloading keras-2.9.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting keras-preprocessing>=1.1.1 (from tensorflow==2.9.1)\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (16.0.6)\n",
      "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (1.22.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (3.3.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (23.2)\n",
      "Collecting protobuf<3.20,>=3.9.2 (from tensorflow==2.9.1)\n",
      "  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (787 bytes)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (67.7.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (1.16.0)\n",
      "Collecting tensorboard<2.10,>=2.9 (from tensorflow==2.9.1)\n",
      "  Downloading tensorboard-2.9.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (0.36.0)\n",
      "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0 (from tensorflow==2.9.1)\n",
      "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (1.14.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.9.1) (0.42.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2.27.0)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.10,>=2.9->tensorflow==2.9.1)\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.5.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2.31.0)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.10,>=2.9->tensorflow==2.9.1)\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.10,>=2.9->tensorflow==2.9.1)\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl.metadata (873 bytes)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2.1.5)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.2.2)\n",
      "Downloading tensorflow-2.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.7/511.7 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m102.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m105.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tensorboard-plugin-wit, keras, flatbuffers, tensorflow-estimator, tensorboard-data-server, protobuf, keras-preprocessing, gast, google-auth-oauthlib, tensorboard, tensorflow\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.15.0\n",
      "    Uninstalling keras-2.15.0:\n",
      "      Successfully uninstalled keras-2.15.0\n",
      "  Attempting uninstall: flatbuffers\n",
      "    Found existing installation: flatbuffers 23.5.26\n",
      "    Uninstalling flatbuffers-23.5.26:\n",
      "      Successfully uninstalled flatbuffers-23.5.26\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.15.0\n",
      "    Uninstalling tensorflow-estimator-2.15.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.15.0\n",
      "  Attempting uninstall: tensorboard-data-server\n",
      "    Found existing installation: tensorboard-data-server 0.7.2\n",
      "    Uninstalling tensorboard-data-server-0.7.2:\n",
      "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.3\n",
      "    Uninstalling protobuf-3.20.3:\n",
      "      Successfully uninstalled protobuf-3.20.3\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.5.4\n",
      "    Uninstalling gast-0.5.4:\n",
      "      Successfully uninstalled gast-0.5.4\n",
      "  Attempting uninstall: google-auth-oauthlib\n",
      "    Found existing installation: google-auth-oauthlib 1.2.0\n",
      "    Uninstalling google-auth-oauthlib-1.2.0:\n",
      "      Successfully uninstalled google-auth-oauthlib-1.2.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.15.2\n",
      "    Uninstalling tensorboard-2.15.2:\n",
      "      Successfully uninstalled tensorboard-2.15.2\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.15.0\n",
      "    Uninstalling tensorflow-2.15.0:\n",
      "      Successfully uninstalled tensorflow-2.15.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pandas-gbq 0.19.2 requires google-auth-oauthlib>=0.7.0, but you have google-auth-oauthlib 0.4.6 which is incompatible.\n",
      "tensorflow-datasets 4.9.4 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
      "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed flatbuffers-1.12 gast-0.4.0 google-auth-oauthlib-0.4.6 keras-2.9.0 keras-preprocessing-1.1.2 protobuf-3.19.6 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.9.1 tensorflow-estimator-2.9.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "d9fe580ccf0c485193dedf87086a40a4",
       "pip_warning": {
        "packages": [
         "google"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard==2.9.1 in /usr/local/lib/python3.10/dist-packages (2.9.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.9.1) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.9.1) (1.60.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.9.1) (2.27.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.9.1) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.9.1) (3.5.2)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.9.1) (1.22.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.9.1) (3.19.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.9.1) (2.31.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.9.1) (67.7.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.9.1) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.9.1) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.9.1) (3.0.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.9.1) (0.42.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.9.1) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.9.1) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.9.1) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.9.1) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard==2.9.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard==2.9.1) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard==2.9.1) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard==2.9.1) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard==2.9.1) (2.1.5)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard==2.9.1) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.9.1) (3.2.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.9.1\n",
    "!pip install tensorboard==2.9.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4hiCzMZC_vFP",
   "metadata": {
    "id": "4hiCzMZC_vFP"
   },
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "SNg-5nJW_9SW",
   "metadata": {
    "id": "SNg-5nJW_9SW"
   },
   "outputs": [],
   "source": [
    "import locale\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "\n",
    "# !pip install --upgrade numpy\n",
    "# !pip install tensorboard\n",
    "# !tensorboard --logdir /content/tts_train_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3cb0191-b8fc-4158-bd26-8423c2a8ba66",
   "metadata": {
    "id": "b3cb0191-b8fc-4158-bd26-8423c2a8ba66"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# BaseDatasetConfig: defines name, formatter and path of the dataset.\n",
    "from TTS.tts.configs.shared_configs import BaseDatasetConfig\n",
    "\n",
    "output_path = \"tts_train_dir\"\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae6b7019-3685-4b48-8917-c152e288d7e3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ae6b7019-3685-4b48-8917-c152e288d7e3",
    "outputId": "08615743-cde2-4ecd-b075-a656818a9d4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-02-28 22:17:44--  https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\n",
      "Resolving data.keithito.com (data.keithito.com)... 24.199.73.137\n",
      "Connecting to data.keithito.com (data.keithito.com)|24.199.73.137|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2748572632 (2.6G) [text/plain]\n",
      "Saving to: ‘tts_train_dir/LJSpeech-1.1.tar.bz2’\n",
      "\n",
      "tts_train_dir/LJSpe 100%[===================>]   2.56G  19.9MB/s    in 2m 13s  \n",
      "\n",
      "2024-02-28 22:19:58 (19.7 MB/s) - ‘tts_train_dir/LJSpeech-1.1.tar.bz2’ saved [2748572632/2748572632]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download and extract LJSpeech dataset.\n",
    "\n",
    "!wget -O $output_path/LJSpeech-1.1.tar.bz2 https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\n",
    "!tar -xf $output_path/LJSpeech-1.1.tar.bz2 -C $output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76cd3ab5-6387-45f1-b488-24734cc1beb5",
   "metadata": {
    "id": "76cd3ab5-6387-45f1-b488-24734cc1beb5"
   },
   "outputs": [],
   "source": [
    "dataset_config = BaseDatasetConfig(\n",
    "    formatter=\"ljspeech\", meta_file_train=\"metadata.csv\", path=os.path.join(output_path, \"LJSpeech-1.1/\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5876e46-2aee-4bcf-b6b3-9e3c535c553f",
   "metadata": {
    "id": "f5876e46-2aee-4bcf-b6b3-9e3c535c553f"
   },
   "source": [
    "We will begin by initializing the model training configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5483ca28-39d6-49f8-a18e-4fb53c50ad84",
   "metadata": {
    "id": "5483ca28-39d6-49f8-a18e-4fb53c50ad84"
   },
   "outputs": [],
   "source": [
    "# GlowTTSConfig: all model related values for training, validating and testing.\n",
    "from TTS.tts.configs.glow_tts_config import GlowTTSConfig\n",
    "config = GlowTTSConfig(\n",
    "    batch_size=16,\n",
    "    eval_batch_size=8,\n",
    "    num_loader_workers=4,\n",
    "    num_eval_loader_workers=4,\n",
    "    run_eval=True,\n",
    "    test_delay_epochs=-1,\n",
    "    epochs=10,\n",
    "    text_cleaner=\"phoneme_cleaners\",\n",
    "    use_phonemes=True,\n",
    "    phoneme_language=\"en-us\",\n",
    "    phoneme_cache_path=os.path.join(output_path, \"phoneme_cache\"),\n",
    "    print_step=25,\n",
    "    print_eval=False,\n",
    "    mixed_precision=True,\n",
    "    output_path=output_path,\n",
    "    datasets=[dataset_config],\n",
    "    save_step=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93ed377-80b7-447b-bd92-106bffa777ee",
   "metadata": {
    "id": "b93ed377-80b7-447b-bd92-106bffa777ee"
   },
   "source": [
    "Next we will initialize the audio processor which is used for feature extraction and audio I/O."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1b12f61-f851-4565-84dd-7640947e04ab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1b12f61-f851-4565-84dd-7640947e04ab",
    "outputId": "3131dd8c-8270-437e-9aaf-e5d007161c9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:True\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:45\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n"
     ]
    }
   ],
   "source": [
    "from TTS.utils.audio import AudioProcessor\n",
    "ap = AudioProcessor.init_from_config(config)\n",
    "# Modify sample rate if for a custom audio dataset:\n",
    "# ap.sample_rate = 22050\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d461683-b05e-403f-815f-8007bda08c38",
   "metadata": {
    "id": "1d461683-b05e-403f-815f-8007bda08c38"
   },
   "source": [
    "Next we will initialize the tokenizer which is used to convert text to sequences of token IDs.  If characters are not defined in the config, default characters are passed to the config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "014879b7-f18d-44c0-b24a-e10f8002113a",
   "metadata": {
    "id": "014879b7-f18d-44c0-b24a-e10f8002113a"
   },
   "outputs": [],
   "source": [
    "from TTS.tts.utils.text.tokenizer import TTSTokenizer\n",
    "tokenizer, config = TTSTokenizer.init_from_config(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3016e1-9e99-4c4f-94e3-fa89231fd978",
   "metadata": {
    "id": "df3016e1-9e99-4c4f-94e3-fa89231fd978"
   },
   "source": [
    "Next we will load data samples. Each sample is a list of ```[text, audio_file_path, speaker_name]```. You can define your custom sample loader returning the list of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cadd6ada-c8eb-4f79-b8fe-6d72850af5a7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cadd6ada-c8eb-4f79-b8fe-6d72850af5a7",
    "outputId": "8a91d671-e9af-4663-af6f-76e5dfd815f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Found 13100 files in /content/tts_train_dir/LJSpeech-1.1\n"
     ]
    }
   ],
   "source": [
    "from TTS.tts.datasets import load_tts_samples\n",
    "train_samples, eval_samples = load_tts_samples(\n",
    "    dataset_config,\n",
    "    eval_split=True,\n",
    "    eval_split_max_size=config.eval_split_max_size,\n",
    "    eval_split_size=config.eval_split_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8b451e-1fe1-4aa3-b69e-ab22b925bd19",
   "metadata": {
    "id": "db8b451e-1fe1-4aa3-b69e-ab22b925bd19"
   },
   "source": [
    "Now we're ready to initialize the model.\n",
    "\n",
    "Models take a config object and a speaker manager as input. Config defines the details of the model like the number of layers, the size of the embedding, etc. Speaker manager is used by multi-speaker models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac2ffe3e-ad0c-443e-800c-9b076ee811b4",
   "metadata": {
    "id": "ac2ffe3e-ad0c-443e-800c-9b076ee811b4"
   },
   "outputs": [],
   "source": [
    "from TTS.tts.models.glow_tts import GlowTTS\n",
    "model = GlowTTS(config, ap, tokenizer, speaker_manager=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kt3bjiOWOPr0",
   "metadata": {
    "id": "kt3bjiOWOPr0"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2832c56-889d-49a6-95b6-eb231892ecc6",
   "metadata": {
    "id": "e2832c56-889d-49a6-95b6-eb231892ecc6"
   },
   "source": [
    "Trainer provides a generic API to train all the 🐸TTS models with all its perks like mixed-precision training, distributed training, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f609945-4fe0-4d0d-b95e-11d7bfb63ebe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0f609945-4fe0-4d0d-b95e-11d7bfb63ebe",
    "outputId": "3f06ded7-2a61-4de5-c731-1b2322d08661"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " > Training Environment:\n",
      " | > Backend: Torch\n",
      " | > Mixed precision: True\n",
      " | > Precision: fp16\n",
      " | > Current device: 0\n",
      " | > Num. of GPUs: 1\n",
      " | > Num. of CPUs: 8\n",
      " | > Num. of Torch Threads: 4\n",
      " | > Torch seed: 54321\n",
      " | > Torch CUDNN: True\n",
      " | > Torch CUDNN deterministic: False\n",
      " | > Torch CUDNN benchmark: False\n",
      " | > Torch TF32 MatMul: False\n",
      " > Start Tensorboard: tensorboard --logdir=tts_train_dir/run-February-28-2024_10+25PM-0000000\n",
      "\n",
      " > Model has 28610257 parameters\n"
     ]
    }
   ],
   "source": [
    "from trainer import Trainer, TrainerArgs\n",
    "trainer = Trainer(\n",
    "    TrainerArgs(), config, output_path, model=model, train_samples=train_samples, eval_samples=eval_samples\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c07f99-3d1d-4bea-801e-9f33bbff0e9f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d4c07f99-3d1d-4bea-801e-9f33bbff0e9f",
    "outputId": "c217d200-918b-4819-d44f-790070d0b996"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 0/10\u001b[0m\n",
      " --> tts_train_dir/run-February-28-2024_10+25PM-0000000\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Pre-computing phonemes...\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/12969 [00:00<37:15,  5.80it/s]"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ɪnstɛd əv weɪtɪŋ ðɛɹ, ɔzwɔld əpɛɹəntli wɛnt æz fɑɹ əweɪ æz hi kʊd ænd bɔɹdɪd ðə fɚst oʊk klɪf bʌs wɪt͡ʃ keɪm əlɔŋ\n",
      " [!] Character '͡' not found in the vocabulary. Discarding it.\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 2058/12969 [01:26<05:49, 31.22it/s]"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ɪntu ðə “kɹeɪtɚ” dʌɡ aʊt ɪn ðə mɪdəl, pɔɹ ðə spʌnd͡ʒ, wɔɹm wɔtɚ, ðə məlæsɪz, ænd soʊdə dɪzɑlvd ɪn hɑt wɔtɚ.\n",
      " [!] Character '“' not found in the vocabulary. Discarding it.\n",
      "ɪntu ðə “kɹeɪtɚ” dʌɡ aʊt ɪn ðə mɪdəl, pɔɹ ðə spʌnd͡ʒ, wɔɹm wɔtɚ, ðə məlæsɪz, ænd soʊdə dɪzɑlvd ɪn hɑt wɔtɚ.\n",
      " [!] Character '”' not found in the vocabulary. Discarding it.\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12969/12969 [05:18<00:00, 40.71it/s]\n",
      "\n",
      "\u001b[1m > TRAINING (2024-02-28 22:30:58) \u001b[0m\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: False\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: True\n",
      "\t| > phonemizer:\n",
      "\t\t| > phoneme language: en-us\n",
      "\t\t| > phoneme backend: gruut\n",
      "\t| > 3 not found characters:\n",
      "\t| > ͡\n",
      "\t| > “\n",
      "\t| > ”\n",
      "| > Number of instances : 12969\n",
      " | > Preprocessing samples\n",
      " | > Max text length: 188\n",
      " | > Min text length: 13\n",
      " | > Avg text length: 100.90014650319993\n",
      " | \n",
      " | > Max audio length: 222643.0\n",
      " | > Min audio length: 24499.0\n",
      " | > Avg audio length: 144984.29755570978\n",
      " | > Num. instances discarded samples: 0\n",
      " | > Batch group size: 0.\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:31:03 -- STEP: 0/811 -- GLOBAL_STEP: 0\u001b[0m\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 4.2542  (4.254179239273071)\n",
      "     | > loader_time: 1.2591  (1.2591369152069092)\n",
      "\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:31:15 -- STEP: 25/811 -- GLOBAL_STEP: 25\u001b[0m\n",
      "     | > loss: 3.917332410812378  (3.938699467976888)\n",
      "     | > log_mle: 0.7339100241661072  (0.7293908437093098)\n",
      "     | > loss_dur: 3.183422327041626  (3.2093086083730062)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.8739, device='cuda:0')  (tensor(10.0279, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.4423  (0.47751773834228517)\n",
      "     | > loader_time: 0.0033  (2.9183677101135252)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:31:26 -- STEP: 50/811 -- GLOBAL_STEP: 50\u001b[0m\n",
      "     | > loss: 3.950969696044922  (3.885804754495621)\n",
      "     | > log_mle: 0.7359222769737244  (0.7307098567485808)\n",
      "     | > loss_dur: 3.2150473594665527  (3.15509489774704)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.7960, device='cuda:0')  (tensor(10.4105, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.4479  (0.45025078296661375)\n",
      "     | > loader_time: 0.0031  (1.460681028366089)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:31:37 -- STEP: 75/811 -- GLOBAL_STEP: 75\u001b[0m\n",
      "     | > loss: 3.8200550079345703  (3.8713053593268762)\n",
      "     | > log_mle: 0.7320234179496765  (0.731547608742347)\n",
      "     | > loss_dur: 3.088031530380249  (3.139757743248573)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.5830, device='cuda:0')  (tensor(10.5011, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.4274  (0.4418148136138916)\n",
      "     | > loader_time: 0.0026  (0.9748487504323323)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:31:48 -- STEP: 100/811 -- GLOBAL_STEP: 100\u001b[0m\n",
      "     | > loss: 3.923156261444092  (3.8667955001195273)\n",
      "     | > log_mle: 0.7285776734352112  (0.7322747892803616)\n",
      "     | > loss_dur: 3.1945786476135254  (3.1345207055409743)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.7674, device='cuda:0')  (tensor(10.5488, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.4579  (0.439662504196167)\n",
      "     | > loader_time: 0.0028  (0.7319681072235107)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:31:59 -- STEP: 125/811 -- GLOBAL_STEP: 125\u001b[0m\n",
      "     | > loss: 3.701988697052002  (3.8633346930794095)\n",
      "     | > log_mle: 0.7293785214424133  (0.7323171408280083)\n",
      "     | > loss_dur: 2.9726102352142334  (3.1310175439585803)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.4735, device='cuda:0')  (tensor(10.5813, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.5168  (0.4428188610076904)\n",
      "     | > loader_time: 0.0036  (0.5863407077789307)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:32:11 -- STEP: 150/811 -- GLOBAL_STEP: 150\u001b[0m\n",
      "     | > loss: 3.9233651161193848  (3.864311303411211)\n",
      "     | > log_mle: 0.7488939762115479  (0.7327539763280324)\n",
      "     | > loss_dur: 3.174471139907837  (3.131557319845472)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.8400, device='cuda:0')  (tensor(10.6052, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.4205  (0.44480343341827394)\n",
      "     | > loader_time: 0.0042  (0.48934276262919096)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:32:24 -- STEP: 175/811 -- GLOBAL_STEP: 175\u001b[0m\n",
      "     | > loss: 3.920154571533203  (3.8591128811691746)\n",
      "     | > log_mle: 0.7370527982711792  (0.7327193032611501)\n",
      "     | > loss_dur: 3.1831016540527344  (3.1263935710444595)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.8302, device='cuda:0')  (tensor(10.6138, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.4724  (0.4514884049551828)\n",
      "     | > loader_time: 0.004  (0.42008702141898013)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:32:36 -- STEP: 200/811 -- GLOBAL_STEP: 200\u001b[0m\n",
      "     | > loss: 3.839944839477539  (3.853180920450311)\n",
      "     | > log_mle: 0.7385188937187195  (0.7328974206196638)\n",
      "     | > loss_dur: 3.101425886154175  (3.1202834944976003)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.6931, device='cuda:0')  (tensor(10.6174, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.435  (0.45616916060447693)\n",
      "     | > loader_time: 0.0035  (0.3680742073059081)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:32:48 -- STEP: 225/811 -- GLOBAL_STEP: 225\u001b[0m\n",
      "     | > loss: 3.6917903423309326  (3.845084056188894)\n",
      "     | > log_mle: 0.7307160496711731  (0.7328711121581324)\n",
      "     | > loss_dur: 2.9610743522644043  (3.1122129384861434)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.3405, device='cuda:0')  (tensor(10.6116, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6111  (0.4604465262095134)\n",
      "     | > loader_time: 0.0042  (0.32785885386996794)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:33:01 -- STEP: 250/811 -- GLOBAL_STEP: 250\u001b[0m\n",
      "     | > loss: 3.746668815612793  (3.8412213295698168)\n",
      "     | > log_mle: 0.7279901504516602  (0.7327651977539065)\n",
      "     | > loss_dur: 3.018678665161133  (3.1084561268488566)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.4620, device='cuda:0')  (tensor(10.6124, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.4981  (0.46369357109069825)\n",
      "     | > loader_time: 0.0035  (0.2955574617385864)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:33:14 -- STEP: 275/811 -- GLOBAL_STEP: 275\u001b[0m\n",
      "     | > loss: 3.881491184234619  (3.839362633003379)\n",
      "     | > log_mle: 0.7398558259010315  (0.7327658099948239)\n",
      "     | > loss_dur: 3.1416354179382324  (3.1065968198596305)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.7252, device='cuda:0')  (tensor(10.6141, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.452  (0.4668849502910267)\n",
      "     | > loader_time: 0.0036  (0.2691894669966264)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:33:26 -- STEP: 300/811 -- GLOBAL_STEP: 300\u001b[0m\n",
      "     | > loss: 3.7703685760498047  (3.8374894857406616)\n",
      "     | > log_mle: 0.7355799078941345  (0.7326638624585912)\n",
      "     | > loss_dur: 3.0347886085510254  (3.1048256199935387)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.5168, device='cuda:0')  (tensor(10.6152, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.5655  (0.4683790675799052)\n",
      "     | > loader_time: 0.005  (0.2472596931457518)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:33:39 -- STEP: 325/811 -- GLOBAL_STEP: 325\u001b[0m\n",
      "     | > loss: 3.770617961883545  (3.834702481163873)\n",
      "     | > log_mle: 0.7304639220237732  (0.7325536249175905)\n",
      "     | > loss_dur: 3.040153980255127  (3.1021488530295245)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.5000, device='cuda:0')  (tensor(10.6138, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6409  (0.4719673406160795)\n",
      "     | > loader_time: 0.026  (0.22862645736107445)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:33:52 -- STEP: 350/811 -- GLOBAL_STEP: 350\u001b[0m\n",
      "     | > loss: 3.7748160362243652  (3.83043127340429)\n",
      "     | > log_mle: 0.7273236513137817  (0.7324391205521188)\n",
      "     | > loss_dur: 3.047492265701294  (3.0979921516250175)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.5372, device='cuda:0')  (tensor(10.6071, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.5977  (0.47502485956464496)\n",
      "     | > loader_time: 0.0045  (0.21266204833984362)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:34:06 -- STEP: 375/811 -- GLOBAL_STEP: 375\u001b[0m\n",
      "     | > loss: 3.82319974899292  (3.826504368978004)\n",
      "     | > log_mle: 0.7374433875083923  (0.7323676512665942)\n",
      "     | > loss_dur: 3.085756301879883  (3.094136714935304)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.6135, device='cuda:0')  (tensor(10.6006, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.5399  (0.47940775044759115)\n",
      "     | > loader_time: 0.0041  (0.19888178825378405)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:34:19 -- STEP: 400/811 -- GLOBAL_STEP: 400\u001b[0m\n",
      "     | > loss: 3.8027968406677246  (3.8223722372299584)\n",
      "     | > log_mle: 0.7344857454299927  (0.7322702051737366)\n",
      "     | > loss_dur: 3.0683109760284424  (3.090102028235412)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.5741, device='cuda:0')  (tensor(10.5921, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.4714  (0.48294800639152524)\n",
      "     | > loader_time: 0.0041  (0.18676843762397755)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:34:33 -- STEP: 425/811 -- GLOBAL_STEP: 425\u001b[0m\n",
      "     | > loss: 3.8191585540771484  (3.818463384674256)\n",
      "     | > log_mle: 0.7240486145019531  (0.7321926247642698)\n",
      "     | > loss_dur: 3.0951099395751953  (3.0862707563193457)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.5124, device='cuda:0')  (tensor(10.5846, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.5746  (0.48681052151848286)\n",
      "     | > loader_time: 0.0037  (0.17605395485373093)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:34:47 -- STEP: 450/811 -- GLOBAL_STEP: 450\u001b[0m\n",
      "     | > loss: 3.7282285690307617  (3.8130639336325904)\n",
      "     | > log_mle: 0.7269681692123413  (0.7321801765398543)\n",
      "     | > loss_dur: 3.001260280609131  (3.080883754383435)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.4673, device='cuda:0')  (tensor(10.5729, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.613  (0.49035677433013913)\n",
      "     | > loader_time: 0.0054  (0.1667360501819186)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:35:02 -- STEP: 475/811 -- GLOBAL_STEP: 475\u001b[0m\n",
      "     | > loss: 3.63895320892334  (3.809352538406208)\n",
      "     | > log_mle: 0.7325268983840942  (0.7321659347062467)\n",
      "     | > loss_dur: 2.906426429748535  (3.0771866019054137)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.2194, device='cuda:0')  (tensor(10.5638, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6507  (0.4945135467930844)\n",
      "     | > loader_time: 0.005  (0.15820660189578398)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:35:17 -- STEP: 500/811 -- GLOBAL_STEP: 500\u001b[0m\n",
      "     | > loss: 3.7562484741210938  (3.805175104919745)\n",
      "     | > log_mle: 0.7291257381439209  (0.7320661891479879)\n",
      "     | > loss_dur: 3.027122735977173  (3.0731089124874202)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.3807, device='cuda:0')  (tensor(10.5536, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.5467  (0.4993756384849548)\n",
      "     | > loader_time: 0.0049  (0.15057006120681754)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:35:32 -- STEP: 525/811 -- GLOBAL_STEP: 525\u001b[0m\n",
      "     | > loss: 3.641465187072754  (3.8003817368479607)\n",
      "     | > log_mle: 0.7286171317100525  (0.7318487798125997)\n",
      "     | > loss_dur: 2.9128479957580566  (3.0685329534475096)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.1666, device='cuda:0')  (tensor(10.5409, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6301  (0.5034968566894531)\n",
      "     | > loader_time: 0.005  (0.14361773536318814)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:35:46 -- STEP: 550/811 -- GLOBAL_STEP: 550\u001b[0m\n",
      "     | > loss: 3.6521825790405273  (3.7958654474329063)\n",
      "     | > log_mle: 0.7296583652496338  (0.7316671705908243)\n",
      "     | > loss_dur: 2.9225242137908936  (3.0641982740826084)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.1170, device='cuda:0')  (tensor(10.5282, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6562  (0.5064877696470781)\n",
      "     | > loader_time: 0.0051  (0.13731908538124768)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:36:01 -- STEP: 575/811 -- GLOBAL_STEP: 575\u001b[0m\n",
      "     | > loss: 3.735239267349243  (3.7907622282483935)\n",
      "     | > log_mle: 0.7277864813804626  (0.7315418375276884)\n",
      "     | > loss_dur: 3.0074527263641357  (3.0592203882943223)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.2657, device='cuda:0')  (tensor(10.5146, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6279  (0.5098523670694102)\n",
      "     | > loader_time: 0.0066  (0.13160391683163844)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:36:17 -- STEP: 600/811 -- GLOBAL_STEP: 600\u001b[0m\n",
      "     | > loss: 3.6501564979553223  (3.7853806960380685)\n",
      "     | > log_mle: 0.7237290143966675  (0.7314049087338526)\n",
      "     | > loss_dur: 2.9264276027679443  (3.053975785384745)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.1927, device='cuda:0')  (tensor(10.4996, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6854  (0.5144399750232694)\n",
      "     | > loader_time: 0.0041  (0.1265265198548634)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:36:32 -- STEP: 625/811 -- GLOBAL_STEP: 625\u001b[0m\n",
      "     | > loss: 3.7668228149414062  (3.780104887970095)\n",
      "     | > log_mle: 0.7289018034934998  (0.7312898211362885)\n",
      "     | > loss_dur: 3.0379209518432617  (3.0488150654769535)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.2658, device='cuda:0')  (tensor(10.4838, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.5564  (0.5184256481170652)\n",
      "     | > loader_time: 0.005  (0.12175079612731925)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:36:49 -- STEP: 650/811 -- GLOBAL_STEP: 650\u001b[0m\n",
      "     | > loss: 3.619781970977783  (3.774188484251499)\n",
      "     | > log_mle: 0.7228338122367859  (0.7310588943772018)\n",
      "     | > loss_dur: 2.8969480991363525  (3.043129589781165)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.0047, device='cuda:0')  (tensor(10.4666, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6285  (0.5238733115563022)\n",
      "     | > loader_time: 0.0038  (0.11728154475872324)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:37:05 -- STEP: 675/811 -- GLOBAL_STEP: 675\u001b[0m\n",
      "     | > loss: 3.619722366333008  (3.7690709906413145)\n",
      "     | > log_mle: 0.7314900755882263  (0.7309192878859386)\n",
      "     | > loss_dur: 2.8882322311401367  (3.0381517026657447)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.8724, device='cuda:0')  (tensor(10.4486, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.5729  (0.5284415902031787)\n",
      "     | > loader_time: 0.0052  (0.1131327247619628)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:37:22 -- STEP: 700/811 -- GLOBAL_STEP: 700\u001b[0m\n",
      "     | > loss: 3.468411445617676  (3.7637509432391845)\n",
      "     | > log_mle: 0.727805495262146  (0.730747139194738)\n",
      "     | > loss_dur: 2.7406060695648193  (3.0330038036125293)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.5928, device='cuda:0')  (tensor(10.4296, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.7088  (0.5328392662320812)\n",
      "     | > loader_time: 0.0053  (0.10928225040435782)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:37:39 -- STEP: 725/811 -- GLOBAL_STEP: 725\u001b[0m\n",
      "     | > loss: 3.6077423095703125  (3.75720974248606)\n",
      "     | > log_mle: 0.7295854687690735  (0.7305323649119672)\n",
      "     | > loss_dur: 2.878156900405884  (3.0266773774073674)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.8229, device='cuda:0')  (tensor(10.4080, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.7567  (0.5374702555557773)\n",
      "     | > loader_time: 0.0046  (0.10582687936980141)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:37:56 -- STEP: 750/811 -- GLOBAL_STEP: 750\u001b[0m\n",
      "     | > loss: 3.5519862174987793  (3.749830242749807)\n",
      "     | > log_mle: 0.720779299736023  (0.7303274975435161)\n",
      "     | > loss_dur: 2.831206798553467  (3.019502745447932)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.7091, device='cuda:0')  (tensor(10.3835, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6384  (0.5421996475855504)\n",
      "     | > loader_time: 0.0045  (0.10253771082560213)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:38:13 -- STEP: 775/811 -- GLOBAL_STEP: 775\u001b[0m\n",
      "     | > loss: 3.484286308288574  (3.7430228548112257)\n",
      "     | > log_mle: 0.7238872051239014  (0.7301728889833097)\n",
      "     | > loss_dur: 2.760399103164673  (3.012849966373319)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.5033, device='cuda:0')  (tensor(10.3595, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6909  (0.5469330212377727)\n",
      "     | > loader_time: 0.005  (0.09945114443379056)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:38:31 -- STEP: 800/811 -- GLOBAL_STEP: 800\u001b[0m\n",
      "     | > loss: 3.5521798133850098  (3.7360635295698916)\n",
      "     | > log_mle: 0.7194731831550598  (0.7299989676173736)\n",
      "     | > loss_dur: 2.8327066898345947  (3.006064562254314)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.5856, device='cuda:0')  (tensor(10.3336, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6586  (0.5517535784840577)\n",
      "     | > loader_time: 0.031  (0.0965417465567588)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: False\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: True\n",
      "\t| > phonemizer:\n",
      "\t\t| > phoneme language: en-us\n",
      "\t\t| > phoneme backend: gruut\n",
      "\t| > 3 not found characters:\n",
      "\t| > ͡\n",
      "\t| > “\n",
      "\t| > ”\n",
      "| > Number of instances : 131\n",
      " | > Preprocessing samples\n",
      " | > Max text length: 174\n",
      " | > Min text length: 20\n",
      " | > Avg text length: 100.76335877862596\n",
      " | \n",
      " | > Max audio length: 222643.0\n",
      " | > Min audio length: 34739.0\n",
      " | > Avg audio length: 144033.41221374046\n",
      " | > Num. instances discarded samples: 0\n",
      " | > Batch group size: 0.\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time: 0.006271839141845703 \u001b[0m(+0)\n",
      "     | > avg_loss: 3.4754193276166916 \u001b[0m(+0)\n",
      "     | > avg_log_mle: 0.7225209958851337 \u001b[0m(+0)\n",
      "     | > avg_loss_dur: 2.7528983056545258 \u001b[0m(+0)\n",
      "\n",
      " > BEST MODEL : tts_train_dir/run-February-28-2024_10+25PM-0000000/best_model_811.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 1/10\u001b[0m\n",
      " --> tts_train_dir/run-February-28-2024_10+25PM-0000000\n",
      "\n",
      "\u001b[1m > TRAINING (2024-02-28 22:38:53) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:39:04 -- STEP: 14/811 -- GLOBAL_STEP: 825\u001b[0m\n",
      "     | > loss: 3.4734795093536377  (3.6225356544767107)\n",
      "     | > log_mle: 0.7132700085639954  (0.7180112898349762)\n",
      "     | > loss_dur: 2.760209560394287  (2.904524326324463)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.3015, device='cuda:0')  (tensor(9.4026, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.5978  (0.6006881168910435)\n",
      "     | > loader_time: 0.003  (0.002783111163548061)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:39:18 -- STEP: 39/811 -- GLOBAL_STEP: 850\u001b[0m\n",
      "     | > loss: 3.5357203483581543  (3.5890630269661927)\n",
      "     | > log_mle: 0.7274304628372192  (0.7208584913840661)\n",
      "     | > loss_dur: 2.8082897663116455  (2.8682045141855874)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.3458, device='cuda:0')  (tensor(9.4119, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.5875  (0.5919997019645494)\n",
      "     | > loader_time: 0.0037  (0.002880499913142278)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:39:33 -- STEP: 64/811 -- GLOBAL_STEP: 875\u001b[0m\n",
      "     | > loss: 3.515397548675537  (3.5437054745852947)\n",
      "     | > log_mle: 0.7278879880905151  (0.7219261173158884)\n",
      "     | > loss_dur: 2.7875096797943115  (2.8217793442308903)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.3034, device='cuda:0')  (tensor(9.3346, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.5773  (0.5933038443326949)\n",
      "     | > loader_time: 0.0037  (0.003026481717824936)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:39:49 -- STEP: 89/811 -- GLOBAL_STEP: 900\u001b[0m\n",
      "     | > loss: 3.4856982231140137  (3.522456094120326)\n",
      "     | > log_mle: 0.727681040763855  (0.7224440233091292)\n",
      "     | > loss_dur: 2.758017063140869  (2.8000120580866095)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.3776, device='cuda:0')  (tensor(9.2885, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6257  (0.5957175399480239)\n",
      "     | > loader_time: 0.0032  (0.003083095121919439)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:40:04 -- STEP: 114/811 -- GLOBAL_STEP: 925\u001b[0m\n",
      "     | > loss: 3.4581520557403564  (3.5134621419404684)\n",
      "     | > log_mle: 0.7278242111206055  (0.7224727314815188)\n",
      "     | > loss_dur: 2.730327844619751  (2.790989403139081)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.9856, device='cuda:0')  (tensor(9.2570, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6347  (0.6001552866216289)\n",
      "     | > loader_time: 0.0032  (0.0031229822259200247)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:40:20 -- STEP: 139/811 -- GLOBAL_STEP: 950\u001b[0m\n",
      "     | > loss: 3.4995481967926025  (3.502834265180629)\n",
      "     | > log_mle: 0.7363924384117126  (0.7226216368538012)\n",
      "     | > loss_dur: 2.763155698776245  (2.7802126184641884)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.1214, device='cuda:0')  (tensor(9.2242, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6747  (0.6061861189149265)\n",
      "     | > loader_time: 0.0036  (0.0031853391112183493)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:40:36 -- STEP: 164/811 -- GLOBAL_STEP: 975\u001b[0m\n",
      "     | > loss: 3.352564811706543  (3.49282378975938)\n",
      "     | > log_mle: 0.7213801741600037  (0.7224962289740401)\n",
      "     | > loss_dur: 2.6311845779418945  (2.7703275506089367)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.7579, device='cuda:0')  (tensor(9.1859, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.5911  (0.6100864294098637)\n",
      "     | > loader_time: 0.0033  (0.0032268486371854455)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:40:52 -- STEP: 189/811 -- GLOBAL_STEP: 1000\u001b[0m\n",
      "     | > loss: 3.3378045558929443  (3.479283644408776)\n",
      "     | > log_mle: 0.7220686078071594  (0.7222188849928518)\n",
      "     | > loss_dur: 2.6157360076904297  (2.7570647474319205)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.6748, device='cuda:0')  (tensor(9.1384, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6474  (0.6125271749244159)\n",
      "     | > loader_time: 0.0034  (0.0032644372768503016)\n",
      "\n",
      "\n",
      " > CHECKPOINT : tts_train_dir/run-February-28-2024_10+25PM-0000000/checkpoint_1000.pth\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:41:12 -- STEP: 214/811 -- GLOBAL_STEP: 1025\u001b[0m\n",
      "     | > loss: 3.3093643188476562  (3.4672605723978203)\n",
      "     | > log_mle: 0.7195214033126831  (0.7221796002900489)\n",
      "     | > loss_dur: 2.5898427963256836  (2.745080962359347)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.6150, device='cuda:0')  (tensor(9.0908, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6546  (0.6193111878689199)\n",
      "     | > loader_time: 0.0035  (0.003279907681117548)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:41:28 -- STEP: 239/811 -- GLOBAL_STEP: 1050\u001b[0m\n",
      "     | > loss: 3.3997199535369873  (3.457224563574691)\n",
      "     | > log_mle: 0.7125651240348816  (0.7218634718132817)\n",
      "     | > loss_dur: 2.687154769897461  (2.735361080289385)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.7464, device='cuda:0')  (tensor(9.0474, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6166  (0.6220292227038774)\n",
      "     | > loader_time: 0.0032  (0.0033057972975854594)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:41:45 -- STEP: 264/811 -- GLOBAL_STEP: 1075\u001b[0m\n",
      "     | > loss: 3.4070072174072266  (3.4485789970918135)\n",
      "     | > log_mle: 0.7086113691329956  (0.7215376507603761)\n",
      "     | > loss_dur: 2.6983959674835205  (2.727041333913802)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.5620, device='cuda:0')  (tensor(9.0056, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.7  (0.6271298003919192)\n",
      "     | > loader_time: 0.0036  (0.0033389736305583606)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:42:01 -- STEP: 289/811 -- GLOBAL_STEP: 1100\u001b[0m\n",
      "     | > loss: 3.3434152603149414  (3.4414008381457473)\n",
      "     | > log_mle: 0.7224414348602295  (0.7212806921516733)\n",
      "     | > loss_dur: 2.620973825454712  (2.720120134650628)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.4483, device='cuda:0')  (tensor(8.9621, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6204  (0.6285999819481659)\n",
      "     | > loader_time: 0.0038  (0.0033909037038941706)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:42:19 -- STEP: 314/811 -- GLOBAL_STEP: 1125\u001b[0m\n",
      "     | > loss: 3.4631364345550537  (3.432589171798366)\n",
      "     | > log_mle: 0.7148128151893616  (0.7210515655909375)\n",
      "     | > loss_dur: 2.748323678970337  (2.7115375965264175)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.5683, device='cuda:0')  (tensor(8.9174, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6396  (0.6335185196748961)\n",
      "     | > loader_time: 0.0044  (0.0034313809340167202)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:42:35 -- STEP: 339/811 -- GLOBAL_STEP: 1150\u001b[0m\n",
      "     | > loss: 3.4105799198150635  (3.4251698230923453)\n",
      "     | > log_mle: 0.7303466796875  (0.7207811539855326)\n",
      "     | > loss_dur: 2.6802332401275635  (2.7043886606672154)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.4171, device='cuda:0')  (tensor(8.8751, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.5994  (0.6349999644411694)\n",
      "     | > loader_time: 0.0038  (0.00345843168838186)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:42:51 -- STEP: 364/811 -- GLOBAL_STEP: 1175\u001b[0m\n",
      "     | > loss: 3.277902603149414  (3.4177548577497294)\n",
      "     | > log_mle: 0.7074804306030273  (0.7204362885965092)\n",
      "     | > loss_dur: 2.5704221725463867  (2.6973185617845132)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.1757, device='cuda:0')  (tensor(8.8332, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.7419  (0.635482510367592)\n",
      "     | > loader_time: 0.0039  (0.0034860058145208678)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:43:08 -- STEP: 389/811 -- GLOBAL_STEP: 1200\u001b[0m\n",
      "     | > loss: 3.292123794555664  (3.411033102050232)\n",
      "     | > log_mle: 0.7163406610488892  (0.7201461534573668)\n",
      "     | > loss_dur: 2.5757832527160645  (2.690886941238049)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.0228, device='cuda:0')  (tensor(8.7906, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6602  (0.6382334606200067)\n",
      "     | > loader_time: 0.0037  (0.0035186046806276617)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:43:25 -- STEP: 414/811 -- GLOBAL_STEP: 1225\u001b[0m\n",
      "     | > loss: 3.3057425022125244  (3.403046238825517)\n",
      "     | > log_mle: 0.711790144443512  (0.7199164310803158)\n",
      "     | > loss_dur: 2.5939524173736572  (2.683129801266434)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.1204, device='cuda:0')  (tensor(8.7461, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6122  (0.6385132817254545)\n",
      "     | > loader_time: 0.004  (0.003538030933066843)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:43:42 -- STEP: 439/811 -- GLOBAL_STEP: 1250\u001b[0m\n",
      "     | > loss: 3.2101547718048096  (3.3947448969430423)\n",
      "     | > log_mle: 0.7141851782798767  (0.7196322297995614)\n",
      "     | > loss_dur: 2.495969533920288  (2.675112659675927)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.8232, device='cuda:0')  (tensor(8.7008, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6952  (0.640618016888177)\n",
      "     | > loader_time: 0.0043  (0.003566707728392443)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:43:58 -- STEP: 464/811 -- GLOBAL_STEP: 1275\u001b[0m\n",
      "     | > loss: 3.242947578430176  (3.387669715901901)\n",
      "     | > log_mle: 0.7053744792938232  (0.7193964186670448)\n",
      "     | > loss_dur: 2.5375730991363525  (2.6682732906834823)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.8423, device='cuda:0')  (tensor(8.6572, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6043  (0.6416298551806083)\n",
      "     | > loader_time: 0.0052  (0.0035988950523836863)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:44:15 -- STEP: 489/811 -- GLOBAL_STEP: 1300\u001b[0m\n",
      "     | > loss: 3.291198492050171  (3.38163565565472)\n",
      "     | > log_mle: 0.7082214951515198  (0.7190980019013572)\n",
      "     | > loss_dur: 2.582977056503296  (2.662537646927472)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.9516, device='cuda:0')  (tensor(8.6152, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6346  (0.6425794077797166)\n",
      "     | > loader_time: 0.0041  (0.003669526679384197)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:44:32 -- STEP: 514/811 -- GLOBAL_STEP: 1325\u001b[0m\n",
      "     | > loss: 3.1935296058654785  (3.375048910597419)\n",
      "     | > log_mle: 0.7108114957809448  (0.7187580904608104)\n",
      "     | > loss_dur: 2.482717990875244  (2.6562908127150173)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.6261, device='cuda:0')  (tensor(8.5725, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.642  (0.6435099427338236)\n",
      "     | > loader_time: 0.004  (0.003697128147466638)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:44:49 -- STEP: 539/811 -- GLOBAL_STEP: 1350\u001b[0m\n",
      "     | > loss: 3.25248122215271  (3.36842739206077)\n",
      "     | > log_mle: 0.7143325805664062  (0.7183354746875158)\n",
      "     | > loss_dur: 2.5381486415863037  (2.650091909964141)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.6880, device='cuda:0')  (tensor(8.5305, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6881  (0.6447390727076765)\n",
      "     | > loader_time: 0.0043  (0.003728070816436371)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:45:05 -- STEP: 564/811 -- GLOBAL_STEP: 1375\u001b[0m\n",
      "     | > loss: 3.1493802070617676  (3.362319485515567)\n",
      "     | > log_mle: 0.7077791690826416  (0.7179946653175013)\n",
      "     | > loss_dur: 2.441601037979126  (2.6443248120605514)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.4543, device='cuda:0')  (tensor(8.4898, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6927  (0.645469413581469)\n",
      "     | > loader_time: 0.0047  (0.003749856712124872)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:45:23 -- STEP: 589/811 -- GLOBAL_STEP: 1400\u001b[0m\n",
      "     | > loss: 3.191309928894043  (3.3568058839678163)\n",
      "     | > log_mle: 0.7130138278007507  (0.7176107516313044)\n",
      "     | > loss_dur: 2.4782960414886475  (2.639195124038411)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.3625, device='cuda:0')  (tensor(8.4501, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6373  (0.6469998966858219)\n",
      "     | > loader_time: 0.0049  (0.003780292938439672)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:45:40 -- STEP: 614/811 -- GLOBAL_STEP: 1425\u001b[0m\n",
      "     | > loss: 3.1772892475128174  (3.3506323836913716)\n",
      "     | > log_mle: 0.7076151967048645  (0.7172849458863758)\n",
      "     | > loss_dur: 2.4696741104125977  (2.633347430135994)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.3850, device='cuda:0')  (tensor(8.4096, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.8249  (0.6481787871071878)\n",
      "     | > loader_time: 0.0052  (0.003809422545790284)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:45:57 -- STEP: 639/811 -- GLOBAL_STEP: 1450\u001b[0m\n",
      "     | > loss: 3.118273973464966  (3.3442553078438007)\n",
      "     | > log_mle: 0.7050232887268066  (0.7168668996373626)\n",
      "     | > loss_dur: 2.413250684738159  (2.6273883997181393)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.2443, device='cuda:0')  (tensor(8.3694, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.7368  (0.6493584087383759)\n",
      "     | > loader_time: 0.0045  (0.0038316473714622534)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:46:14 -- STEP: 664/811 -- GLOBAL_STEP: 1475\u001b[0m\n",
      "     | > loss: 3.1819305419921875  (3.3387864662940245)\n",
      "     | > log_mle: 0.7043708562850952  (0.716510012117495)\n",
      "     | > loss_dur: 2.477559804916382  (2.622276447982673)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.3401, device='cuda:0')  (tensor(8.3301, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6573  (0.6504853073372896)\n",
      "     | > loader_time: 0.0043  (0.0038462913179972084)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:46:32 -- STEP: 689/811 -- GLOBAL_STEP: 1500\u001b[0m\n",
      "     | > loss: 3.1396889686584473  (3.3339139688516735)\n",
      "     | > log_mle: 0.705013632774353  (0.7161157053337041)\n",
      "     | > loss_dur: 2.4346752166748047  (2.6177982564242392)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.1551, device='cuda:0')  (tensor(8.2916, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6652  (0.652284348132129)\n",
      "     | > loader_time: 0.0045  (0.0038637374412857743)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:46:49 -- STEP: 714/811 -- GLOBAL_STEP: 1525\u001b[0m\n",
      "     | > loss: 3.0892434120178223  (3.328677136357091)\n",
      "     | > log_mle: 0.7024613618850708  (0.7156822725671346)\n",
      "     | > loss_dur: 2.386781930923462  (2.612994856861126)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.9988, device='cuda:0')  (tensor(8.2533, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6722  (0.6540101269046129)\n",
      "     | > loader_time: 0.0043  (0.003884501483927922)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:47:07 -- STEP: 739/811 -- GLOBAL_STEP: 1550\u001b[0m\n",
      "     | > loss: 3.0889692306518555  (3.3228476318519395)\n",
      "     | > log_mle: 0.7010434865951538  (0.7153055291214557)\n",
      "     | > loss_dur: 2.387925624847412  (2.607542095390806)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.9741, device='cuda:0')  (tensor(8.2154, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.7463  (0.6558317034751051)\n",
      "     | > loader_time: 0.0045  (0.003919931484010771)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:47:25 -- STEP: 764/811 -- GLOBAL_STEP: 1575\u001b[0m\n",
      "     | > loss: 3.1311280727386475  (3.31754778567409)\n",
      "     | > log_mle: 0.7067010402679443  (0.7148993614456416)\n",
      "     | > loss_dur: 2.424427032470703  (2.6026484179871257)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.0179, device='cuda:0')  (tensor(8.1785, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.7428  (0.6580176244231416)\n",
      "     | > loader_time: 0.0048  (0.00395126492565215)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:47:44 -- STEP: 789/811 -- GLOBAL_STEP: 1600\u001b[0m\n",
      "     | > loss: 3.196603775024414  (3.312028585429125)\n",
      "     | > log_mle: 0.7060093283653259  (0.7145437282452263)\n",
      "     | > loss_dur: 2.4905943870544434  (2.5974848509137027)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.0609, device='cuda:0')  (tensor(8.1410, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6905  (0.6600662290067876)\n",
      "     | > loader_time: 0.0061  (0.003977893725396411)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.004785299301147461 \u001b[0m(-0.0014865398406982422)\n",
      "     | > avg_loss:\u001b[92m 3.0740712136030197 \u001b[0m(-0.4013481140136719)\n",
      "     | > avg_log_mle:\u001b[92m 0.7001348435878754 \u001b[0m(-0.022386152297258377)\n",
      "     | > avg_loss_dur:\u001b[92m 2.3739363849163055 \u001b[0m(-0.3789619207382202)\n",
      "\n",
      " > BEST MODEL : tts_train_dir/run-February-28-2024_10+25PM-0000000/best_model_1622.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 2/10\u001b[0m\n",
      " --> tts_train_dir/run-February-28-2024_10+25PM-0000000\n",
      "\n",
      "\u001b[1m > TRAINING (2024-02-28 22:48:11) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:48:15 -- STEP: 3/811 -- GLOBAL_STEP: 1625\u001b[0m\n",
      "     | > loss: 3.397660732269287  (3.377751668294271)\n",
      "     | > log_mle: 0.6907182931900024  (0.7031353314717611)\n",
      "     | > loss_dur: 2.706942558288574  (2.6746163368225098)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.3336, device='cuda:0')  (tensor(7.2345, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.5553  (0.569483757019043)\n",
      "     | > loader_time: 0.0023  (0.0026454925537109375)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:48:29 -- STEP: 28/811 -- GLOBAL_STEP: 1650\u001b[0m\n",
      "     | > loss: 3.1449854373931885  (3.2714690225464955)\n",
      "     | > log_mle: 0.7078284621238708  (0.7016545491559165)\n",
      "     | > loss_dur: 2.437156915664673  (2.5698144861630032)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.7420, device='cuda:0')  (tensor(7.0973, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.6215  (0.5871278558458602)\n",
      "     | > loader_time: 0.0029  (0.0027264697211129324)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:48:44 -- STEP: 53/811 -- GLOBAL_STEP: 1675\u001b[0m\n",
      "     | > loss: 3.143923282623291  (3.2193596902883277)\n",
      "     | > log_mle: 0.7088834047317505  (0.7018752469206756)\n",
      "     | > loss_dur: 2.43503999710083  (2.517484453489195)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.9157, device='cuda:0')  (tensor(6.9886, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.5676  (0.5849660882410013)\n",
      "     | > loader_time: 0.003  (0.00285517044787137)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:49:00 -- STEP: 78/811 -- GLOBAL_STEP: 1700\u001b[0m\n",
      "     | > loss: 3.227736473083496  (3.1951386775725927)\n",
      "     | > log_mle: 0.6960310935974121  (0.7016692520716251)\n",
      "     | > loss_dur: 2.531705379486084  (2.493469430850102)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.9359, device='cuda:0')  (tensor(6.9216, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.6176  (0.5926318841102796)\n",
      "     | > loader_time: 0.0038  (0.0030187490658882335)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:49:15 -- STEP: 103/811 -- GLOBAL_STEP: 1725\u001b[0m\n",
      "     | > loss: 3.160365104675293  (3.1813019595099883)\n",
      "     | > log_mle: 0.6963627934455872  (0.7013691681102643)\n",
      "     | > loss_dur: 2.4640023708343506  (2.4799327989226394)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.6640, device='cuda:0')  (tensor(6.8692, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.6544  (0.5961640598704513)\n",
      "     | > loader_time: 0.0034  (0.003121681583737864)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:49:30 -- STEP: 128/811 -- GLOBAL_STEP: 1750\u001b[0m\n",
      "     | > loss: 3.039702892303467  (3.1688287667930126)\n",
      "     | > log_mle: 0.6972781419754028  (0.7005053064785899)\n",
      "     | > loss_dur: 2.3424246311187744  (2.468323463574051)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.4866, device='cuda:0')  (tensor(6.8213, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.5708  (0.6008317600935698)\n",
      "     | > loader_time: 0.0033  (0.003182819113135338)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:49:46 -- STEP: 153/811 -- GLOBAL_STEP: 1775\u001b[0m\n",
      "     | > loss: 3.0512683391571045  (3.1618005980074018)\n",
      "     | > log_mle: 0.7016432881355286  (0.6999824647030801)\n",
      "     | > loss_dur: 2.3496251106262207  (2.4618181356417574)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.3936, device='cuda:0')  (tensor(6.7831, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.583  (0.6020686486188105)\n",
      "     | > loader_time: 0.0035  (0.0032212734222412114)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:50:02 -- STEP: 178/811 -- GLOBAL_STEP: 1800\u001b[0m\n",
      "     | > loss: 3.139342784881592  (3.1496897976050215)\n",
      "     | > log_mle: 0.6960344314575195  (0.6989545082108359)\n",
      "     | > loss_dur: 2.4433083534240723  (2.4507352930776176)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.5044, device='cuda:0')  (tensor(6.7355, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.6971  (0.6060849227262348)\n",
      "     | > loader_time: 0.0033  (0.003247531612267655)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:50:18 -- STEP: 203/811 -- GLOBAL_STEP: 1825\u001b[0m\n",
      "     | > loss: 3.1176443099975586  (3.1405437086603323)\n",
      "     | > log_mle: 0.6862009763717651  (0.698053182345893)\n",
      "     | > loss_dur: 2.431443452835083  (2.44249052836977)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.3491, device='cuda:0')  (tensor(6.6909, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.6574  (0.6105732494974373)\n",
      "     | > loader_time: 0.003  (0.0032896983799676)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:50:34 -- STEP: 228/811 -- GLOBAL_STEP: 1850\u001b[0m\n",
      "     | > loss: 3.0558199882507324  (3.130210985217178)\n",
      "     | > log_mle: 0.684830367565155  (0.697034241860373)\n",
      "     | > loss_dur: 2.3709895610809326  (2.433176744402499)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.2924, device='cuda:0')  (tensor(6.6454, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.6441  (0.613709520875362)\n",
      "     | > loader_time: 0.0035  (0.0033239032092847324)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:50:50 -- STEP: 253/811 -- GLOBAL_STEP: 1875\u001b[0m\n",
      "     | > loss: 3.004312038421631  (3.1215386682819473)\n",
      "     | > log_mle: 0.6829534769058228  (0.6959608190144475)\n",
      "     | > loss_dur: 2.3213586807250977  (2.4255778487963155)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.0867, device='cuda:0')  (tensor(6.6023, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.7227  (0.6168557363065337)\n",
      "     | > loader_time: 0.0037  (0.003346143503905285)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:51:07 -- STEP: 278/811 -- GLOBAL_STEP: 1900\u001b[0m\n",
      "     | > loss: 3.1088943481445312  (3.115312022270916)\n",
      "     | > log_mle: 0.6811555624008179  (0.6948928938066361)\n",
      "     | > loss_dur: 2.427738666534424  (2.420419130393926)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.2667, device='cuda:0')  (tensor(6.5625, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.6768  (0.6201491553148778)\n",
      "     | > loader_time: 0.0042  (0.0033872359090571787)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:51:25 -- STEP: 303/811 -- GLOBAL_STEP: 1925\u001b[0m\n",
      "     | > loss: 3.0289506912231445  (3.110454530999213)\n",
      "     | > log_mle: 0.6808318495750427  (0.6938566331422764)\n",
      "     | > loss_dur: 2.348118782043457  (2.416597899037225)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.1277, device='cuda:0')  (tensor(6.5268, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.7357  (0.627614422599868)\n",
      "     | > loader_time: 0.0039  (0.0034259482972299306)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:51:42 -- STEP: 328/811 -- GLOBAL_STEP: 1950\u001b[0m\n",
      "     | > loss: 2.979571580886841  (3.104882229392122)\n",
      "     | > log_mle: 0.6781255602836609  (0.6927231453904293)\n",
      "     | > loss_dur: 2.301445960998535  (2.4121590845468566)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.9526, device='cuda:0')  (tensor(6.4896, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.6495  (0.6315741524463747)\n",
      "     | > loader_time: 0.004  (0.003475564282114913)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:51:59 -- STEP: 353/811 -- GLOBAL_STEP: 1975\u001b[0m\n",
      "     | > loss: 2.9705376625061035  (3.100165845314437)\n",
      "     | > log_mle: 0.6844552755355835  (0.69167319117457)\n",
      "     | > loss_dur: 2.2860822677612305  (2.408492654308718)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.8797, device='cuda:0')  (tensor(6.4557, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.7551  (0.6350214927122211)\n",
      "     | > loader_time: 0.0043  (0.0035346607986320518)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:52:16 -- STEP: 378/811 -- GLOBAL_STEP: 2000\u001b[0m\n",
      "     | > loss: 3.046368360519409  (3.09619332684411)\n",
      "     | > log_mle: 0.674690306186676  (0.6905523850804292)\n",
      "     | > loss_dur: 2.371678113937378  (2.405640941448312)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.9281, device='cuda:0')  (tensor(6.4227, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.7229  (0.6383170633719717)\n",
      "     | > loader_time: 0.0044  (0.0035939658129656754)\n",
      "\n",
      "\n",
      " > CHECKPOINT : tts_train_dir/run-February-28-2024_10+25PM-0000000/checkpoint_2000.pth\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:52:37 -- STEP: 403/811 -- GLOBAL_STEP: 2025\u001b[0m\n",
      "     | > loss: 2.9696531295776367  (3.0915739382466967)\n",
      "     | > log_mle: 0.6745449304580688  (0.68951599725127)\n",
      "     | > loss_dur: 2.2951083183288574  (2.402057942326548)\n",
      "     | > amp_scaler: 16384.0  (16424.655086848627)\n",
      "     | > grad_norm: tensor(5.8748, device='cuda:0')  (tensor(6.3757, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.7421  (0.6413041338435479)\n",
      "     | > loader_time: 0.0051  (0.003640542255146036)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:52:54 -- STEP: 428/811 -- GLOBAL_STEP: 2050\u001b[0m\n",
      "     | > loss: 3.0115909576416016  (3.087166249752045)\n",
      "     | > log_mle: 0.6701593399047852  (0.688396922060263)\n",
      "     | > loss_dur: 2.3414316177368164  (2.3987693279703097)\n",
      "     | > amp_scaler: 16384.0  (16422.28037383177)\n",
      "     | > grad_norm: tensor(5.8115, device='cuda:0')  (tensor(6.3450, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.7695  (0.6434979516769129)\n",
      "     | > loader_time: 0.0044  (0.003685166902631243)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:53:11 -- STEP: 453/811 -- GLOBAL_STEP: 2075\u001b[0m\n",
      "     | > loss: 2.984738349914551  (3.082795185232268)\n",
      "     | > log_mle: 0.6619842052459717  (0.6873468119840228)\n",
      "     | > loss_dur: 2.322754144668579  (2.3954483725903586)\n",
      "     | > amp_scaler: 16384.0  (16420.167770419426)\n",
      "     | > grad_norm: tensor(5.7304, device='cuda:0')  (tensor(6.3156, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.6568  (0.6450371810668883)\n",
      "     | > loader_time: 0.004  (0.0037157419764706104)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:53:28 -- STEP: 478/811 -- GLOBAL_STEP: 2100\u001b[0m\n",
      "     | > loss: 3.042123794555664  (3.079390297374965)\n",
      "     | > log_mle: 0.651923656463623  (0.6862882959294025)\n",
      "     | > loss_dur: 2.390200138092041  (2.3931020014455635)\n",
      "     | > amp_scaler: 16384.0  (16418.276150627607)\n",
      "     | > grad_norm: tensor(5.7308, device='cuda:0')  (tensor(6.2871, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.7557  (0.6479362518717559)\n",
      "     | > loader_time: 0.0044  (0.003748053786146092)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:53:45 -- STEP: 503/811 -- GLOBAL_STEP: 2125\u001b[0m\n",
      "     | > loss: 3.0137407779693604  (3.0758319218637458)\n",
      "     | > log_mle: 0.6615888476371765  (0.685207419556605)\n",
      "     | > loss_dur: 2.352151870727539  (2.3906245032551285)\n",
      "     | > amp_scaler: 16384.0  (16416.57256461231)\n",
      "     | > grad_norm: tensor(5.7709, device='cuda:0')  (tensor(6.2596, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.6394  (0.6490990300301771)\n",
      "     | > loader_time: 0.0042  (0.003781093991774451)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:54:04 -- STEP: 528/811 -- GLOBAL_STEP: 2150\u001b[0m\n",
      "     | > loss: 3.026015281677246  (3.0722695607127575)\n",
      "     | > log_mle: 0.6626167297363281  (0.6840114530288818)\n",
      "     | > loss_dur: 2.363398551940918  (2.3882581081354264)\n",
      "     | > amp_scaler: 16384.0  (16415.030303030286)\n",
      "     | > grad_norm: tensor(5.7143, device='cuda:0')  (tensor(6.2332, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.7302  (0.65239855466467)\n",
      "     | > loader_time: 0.0046  (0.003811917521736839)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:54:22 -- STEP: 553/811 -- GLOBAL_STEP: 2175\u001b[0m\n",
      "     | > loss: 3.0292985439300537  (3.06979563568212)\n",
      "     | > log_mle: 0.654895544052124  (0.6828430109601777)\n",
      "     | > loss_dur: 2.3744029998779297  (2.386952624398589)\n",
      "     | > amp_scaler: 16384.0  (16413.627486437596)\n",
      "     | > grad_norm: tensor(5.7134, device='cuda:0')  (tensor(6.2094, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.6647  (0.6560699081765813)\n",
      "     | > loader_time: 0.0048  (0.003843241531206514)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:54:41 -- STEP: 578/811 -- GLOBAL_STEP: 2200\u001b[0m\n",
      "     | > loss: 2.956376075744629  (3.0668416778109084)\n",
      "     | > log_mle: 0.6533627510070801  (0.681683422269294)\n",
      "     | > loss_dur: 2.303013324737549  (2.385158254613514)\n",
      "     | > amp_scaler: 16384.0  (16412.346020761226)\n",
      "     | > grad_norm: tensor(5.6163, device='cuda:0')  (tensor(6.1862, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.7449  (0.6599452375953176)\n",
      "     | > loader_time: 0.005  (0.003889129236082717)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:54:59 -- STEP: 603/811 -- GLOBAL_STEP: 2225\u001b[0m\n",
      "     | > loss: 3.063662528991699  (3.064386950994211)\n",
      "     | > log_mle: 0.6520461440086365  (0.6805684925311841)\n",
      "     | > loss_dur: 2.411616325378418  (2.3838184575734047)\n",
      "     | > amp_scaler: 16384.0  (16411.17081260363)\n",
      "     | > grad_norm: tensor(5.7054, device='cuda:0')  (tensor(6.1639, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.7583  (0.6629882989633543)\n",
      "     | > loader_time: 0.0044  (0.003928056799159516)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:55:18 -- STEP: 628/811 -- GLOBAL_STEP: 2250\u001b[0m\n",
      "     | > loss: 2.997567653656006  (3.061346826279998)\n",
      "     | > log_mle: 0.642391562461853  (0.6794398052107762)\n",
      "     | > loss_dur: 2.3551759719848633  (2.381907021164134)\n",
      "     | > amp_scaler: 16384.0  (16410.089171974505)\n",
      "     | > grad_norm: tensor(5.6544, device='cuda:0')  (tensor(6.1415, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.8033  (0.6663671519346299)\n",
      "     | > loader_time: 0.0048  (0.003961801908578085)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:55:36 -- STEP: 653/811 -- GLOBAL_STEP: 2275\u001b[0m\n",
      "     | > loss: 3.0528016090393066  (3.0581616453518365)\n",
      "     | > log_mle: 0.6426271200180054  (0.6782437669737968)\n",
      "     | > loss_dur: 2.4101743698120117  (2.3799178779216486)\n",
      "     | > amp_scaler: 16384.0  (16409.0903522205)\n",
      "     | > grad_norm: tensor(5.6964, device='cuda:0')  (tensor(6.1199, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.6678  (0.6680885785206535)\n",
      "     | > loader_time: 0.0046  (0.003992360364788344)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:55:54 -- STEP: 678/811 -- GLOBAL_STEP: 2300\u001b[0m\n",
      "     | > loss: 3.045776128768921  (3.056262410144187)\n",
      "     | > log_mle: 0.6401830315589905  (0.677063297381444)\n",
      "     | > loss_dur: 2.405593156814575  (2.3791991127627434)\n",
      "     | > amp_scaler: 16384.0  (16408.165191740405)\n",
      "     | > grad_norm: tensor(5.7017, device='cuda:0')  (tensor(6.1001, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.7354  (0.6693261443337857)\n",
      "     | > loader_time: 0.0046  (0.004011993562929049)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:56:12 -- STEP: 703/811 -- GLOBAL_STEP: 2325\u001b[0m\n",
      "     | > loss: 2.9980111122131348  (3.0543943794489246)\n",
      "     | > log_mle: 0.6415561437606812  (0.6758638517785388)\n",
      "     | > loss_dur: 2.356455087661743  (2.378530527416028)\n",
      "     | > amp_scaler: 16384.0  (16407.30583214793)\n",
      "     | > grad_norm: tensor(5.5614, device='cuda:0')  (tensor(6.0813, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.8347  (0.6715565538338538)\n",
      "     | > loader_time: 0.0045  (0.004031931862213876)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:56:31 -- STEP: 728/811 -- GLOBAL_STEP: 2350\u001b[0m\n",
      "     | > loss: 2.988685131072998  (3.0517888900997874)\n",
      "     | > log_mle: 0.643902063369751  (0.6746528453224317)\n",
      "     | > loss_dur: 2.344783067703247  (2.3771360447773553)\n",
      "     | > amp_scaler: 16384.0  (16406.505494505494)\n",
      "     | > grad_norm: tensor(5.6140, device='cuda:0')  (tensor(6.0626, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.7319  (0.67377778331002)\n",
      "     | > loader_time: 0.0045  (0.004058568687229368)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:56:50 -- STEP: 753/811 -- GLOBAL_STEP: 2375\u001b[0m\n",
      "     | > loss: 2.887326240539551  (3.0485171856949846)\n",
      "     | > log_mle: 0.64105224609375  (0.6734255982110237)\n",
      "     | > loss_dur: 2.246273994445801  (2.3750915875631167)\n",
      "     | > amp_scaler: 16384.0  (16405.758300132806)\n",
      "     | > grad_norm: tensor(5.3352, device='cuda:0')  (tensor(6.0438, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.8588  (0.6759298803955116)\n",
      "     | > loader_time: 0.0044  (0.0040868145536141565)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:57:08 -- STEP: 778/811 -- GLOBAL_STEP: 2400\u001b[0m\n",
      "     | > loss: 2.983114004135132  (3.045879715818979)\n",
      "     | > log_mle: 0.6325650215148926  (0.6722737940693893)\n",
      "     | > loss_dur: 2.3505489826202393  (2.3736059218262)\n",
      "     | > amp_scaler: 16384.0  (16405.059125964002)\n",
      "     | > grad_norm: tensor(5.4887, device='cuda:0')  (tensor(6.0267, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.704  (0.6780011028740888)\n",
      "     | > loader_time: 0.0049  (0.004113705728231786)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:57:27 -- STEP: 803/811 -- GLOBAL_STEP: 2425\u001b[0m\n",
      "     | > loss: 3.0198206901550293  (3.043280901677285)\n",
      "     | > log_mle: 0.6313121318817139  (0.6710534417911316)\n",
      "     | > loss_dur: 2.3885085582733154  (2.3722274603315157)\n",
      "     | > amp_scaler: 16384.0  (16404.403486924028)\n",
      "     | > grad_norm: tensor(5.5819, device='cuda:0')  (tensor(6.0099, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.6587  (0.6804139729900048)\n",
      "     | > loader_time: 0.0048  (0.004144615729155009)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.005386963486671448 \u001b[0m(+0.0006016641855239868)\n",
      "     | > avg_loss:\u001b[92m 2.895546182990074 \u001b[0m(-0.17852503061294556)\n",
      "     | > avg_log_mle:\u001b[92m 0.631906621158123 \u001b[0m(-0.06822822242975235)\n",
      "     | > avg_loss_dur:\u001b[92m 2.2636395543813705 \u001b[0m(-0.110296830534935)\n",
      "\n",
      " > BEST MODEL : tts_train_dir/run-February-28-2024_10+25PM-0000000/best_model_2433.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 3/10\u001b[0m\n",
      " --> tts_train_dir/run-February-28-2024_10+25PM-0000000\n",
      "\n",
      "\u001b[1m > TRAINING (2024-02-28 22:57:46) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:57:58 -- STEP: 17/811 -- GLOBAL_STEP: 2450\u001b[0m\n",
      "     | > loss: 2.928847312927246  (3.007547336466172)\n",
      "     | > log_mle: 0.6436948776245117  (0.6431548385059133)\n",
      "     | > loss_dur: 2.2851524353027344  (2.3643924909479477)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.4577, device='cuda:0')  (tensor(5.5772, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.587  (0.6068796270033893)\n",
      "     | > loader_time: 0.0038  (0.003586544710047105)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:58:14 -- STEP: 42/811 -- GLOBAL_STEP: 2475\u001b[0m\n",
      "     | > loss: 2.9094996452331543  (2.9873621577308294)\n",
      "     | > log_mle: 0.6321531534194946  (0.6413319877215794)\n",
      "     | > loss_dur: 2.277346611022949  (2.3460301614943)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.4669, device='cuda:0')  (tensor(5.5648, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.5973  (0.6086763767969039)\n",
      "     | > loader_time: 0.0038  (0.003653015409197126)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:58:29 -- STEP: 67/811 -- GLOBAL_STEP: 2500\u001b[0m\n",
      "     | > loss: 2.9613122940063477  (2.970099506093495)\n",
      "     | > log_mle: 0.6366007328033447  (0.6399492977270439)\n",
      "     | > loss_dur: 2.324711561203003  (2.3301502021391)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.5119, device='cuda:0')  (tensor(5.5387, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.6018  (0.6091219524839029)\n",
      "     | > loader_time: 0.0037  (0.0037036475850575007)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:58:45 -- STEP: 92/811 -- GLOBAL_STEP: 2525\u001b[0m\n",
      "     | > loss: 2.9873690605163574  (2.955019639885944)\n",
      "     | > log_mle: 0.629345715045929  (0.6390113875917767)\n",
      "     | > loss_dur: 2.3580234050750732  (2.316008246463279)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.4910, device='cuda:0')  (tensor(5.5128, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.609  (0.6106668451557987)\n",
      "     | > loader_time: 0.0042  (0.0036708194276560907)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:59:00 -- STEP: 117/811 -- GLOBAL_STEP: 2550\u001b[0m\n",
      "     | > loss: 2.974457263946533  (2.9518176836845202)\n",
      "     | > log_mle: 0.6273996233940125  (0.6368604465427561)\n",
      "     | > loss_dur: 2.347057580947876  (2.3149572274623784)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.5050, device='cuda:0')  (tensor(5.5031, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.6623  (0.6153210370968548)\n",
      "     | > loader_time: 0.004  (0.0036685405633388422)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:59:17 -- STEP: 142/811 -- GLOBAL_STEP: 2575\u001b[0m\n",
      "     | > loss: 3.0117762088775635  (2.9436204500601324)\n",
      "     | > log_mle: 0.6211719512939453  (0.6350299749575868)\n",
      "     | > loss_dur: 2.390604257583618  (2.308590469226032)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.5750, device='cuda:0')  (tensor(5.4883, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.6158  (0.6194443551587386)\n",
      "     | > loader_time: 0.0044  (0.003694151488827988)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:59:33 -- STEP: 167/811 -- GLOBAL_STEP: 2600\u001b[0m\n",
      "     | > loss: 2.8371899127960205  (2.9355454801799303)\n",
      "     | > log_mle: 0.6150081753730774  (0.6330976529035738)\n",
      "     | > loss_dur: 2.222181797027588  (2.3024478244210447)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.2395, device='cuda:0')  (tensor(5.4733, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.6364  (0.6224754955954183)\n",
      "     | > loader_time: 0.004  (0.0037177265761141297)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 22:59:49 -- STEP: 192/811 -- GLOBAL_STEP: 2625\u001b[0m\n",
      "     | > loss: 2.8538029193878174  (2.923360475649437)\n",
      "     | > log_mle: 0.6134674549102783  (0.6309976773336531)\n",
      "     | > loss_dur: 2.240335464477539  (2.2923627942800553)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.2915, device='cuda:0')  (tensor(5.4528, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.6346  (0.6254938083390397)\n",
      "     | > loader_time: 0.0041  (0.0037420118848482775)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:00:06 -- STEP: 217/811 -- GLOBAL_STEP: 2650\u001b[0m\n",
      "     | > loss: 2.8151357173919678  (2.9140524292871155)\n",
      "     | > log_mle: 0.6157706379890442  (0.6292534863344532)\n",
      "     | > loss_dur: 2.1993651390075684  (2.284798940755258)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.3211, device='cuda:0')  (tensor(5.4360, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.6224  (0.630449240108789)\n",
      "     | > loader_time: 0.0039  (0.003765423726376301)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:00:23 -- STEP: 242/811 -- GLOBAL_STEP: 2675\u001b[0m\n",
      "     | > loss: 2.8905327320098877  (2.9058720888185112)\n",
      "     | > log_mle: 0.618446409702301  (0.6271699169450553)\n",
      "     | > loss_dur: 2.2720863819122314  (2.278702169410457)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.3604, device='cuda:0')  (tensor(5.4210, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.6684  (0.6343266983662756)\n",
      "     | > loader_time: 0.0038  (0.003788741166926613)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:00:40 -- STEP: 267/811 -- GLOBAL_STEP: 2700\u001b[0m\n",
      "     | > loss: 2.7810394763946533  (2.8978299282016833)\n",
      "     | > log_mle: 0.6044280529022217  (0.6250869656323491)\n",
      "     | > loss_dur: 2.1766114234924316  (2.2727429589975223)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.2206, device='cuda:0')  (tensor(5.4075, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.6327  (0.6391061164913107)\n",
      "     | > loader_time: 0.0041  (0.003821014018540972)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:00:58 -- STEP: 292/811 -- GLOBAL_STEP: 2725\u001b[0m\n",
      "     | > loss: 2.7583765983581543  (2.8911496596793618)\n",
      "     | > log_mle: 0.6068018078804016  (0.6230730830806575)\n",
      "     | > loss_dur: 2.1515748500823975  (2.2680765749657024)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.1740, device='cuda:0')  (tensor(5.3942, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.6628  (0.6451463658515721)\n",
      "     | > loader_time: 0.0052  (0.0038714580339928198)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:01:15 -- STEP: 317/811 -- GLOBAL_STEP: 2750\u001b[0m\n",
      "     | > loss: 2.90620756149292  (2.8835314546097726)\n",
      "     | > log_mle: 0.5947247743606567  (0.6212879026349788)\n",
      "     | > loss_dur: 2.3114829063415527  (2.2622435499064957)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.3454, device='cuda:0')  (tensor(5.3793, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.6557  (0.6484743751561978)\n",
      "     | > loader_time: 0.0038  (0.0039040786610792864)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:01:33 -- STEP: 342/811 -- GLOBAL_STEP: 2775\u001b[0m\n",
      "     | > loss: 2.76802921295166  (2.8760444908811356)\n",
      "     | > log_mle: 0.5937820672988892  (0.6193842345859574)\n",
      "     | > loss_dur: 2.1742472648620605  (2.25666025577233)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.2350, device='cuda:0')  (tensor(5.3652, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.7029  (0.651990739922774)\n",
      "     | > loader_time: 0.0043  (0.003938703509102091)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:01:51 -- STEP: 367/811 -- GLOBAL_STEP: 2800\u001b[0m\n",
      "     | > loss: 2.820971965789795  (2.8682687626872485)\n",
      "     | > log_mle: 0.5889205932617188  (0.61753111395589)\n",
      "     | > loss_dur: 2.232051372528076  (2.25073764954341)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.2268, device='cuda:0')  (tensor(5.3507, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.6453  (0.655333342279335)\n",
      "     | > loader_time: 0.0044  (0.00396568119038678)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:02:08 -- STEP: 392/811 -- GLOBAL_STEP: 2825\u001b[0m\n",
      "     | > loss: 2.7678000926971436  (2.8614653318512215)\n",
      "     | > log_mle: 0.5812485814094543  (0.6156424816165648)\n",
      "     | > loss_dur: 2.186551570892334  (2.2458228499305495)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.2431, device='cuda:0')  (tensor(5.3373, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.6756  (0.6584765448862192)\n",
      "     | > loader_time: 0.004  (0.003991927419389995)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:02:26 -- STEP: 417/811 -- GLOBAL_STEP: 2850\u001b[0m\n",
      "     | > loss: 2.75396990776062  (2.8532927979668283)\n",
      "     | > log_mle: 0.5765471458435059  (0.6139023932907505)\n",
      "     | > loss_dur: 2.1774227619171143  (2.2393904058195697)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.2079, device='cuda:0')  (tensor(5.3227, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.6484  (0.6613428621269244)\n",
      "     | > loader_time: 0.0043  (0.0040229030078549445)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:02:44 -- STEP: 442/811 -- GLOBAL_STEP: 2875\u001b[0m\n",
      "     | > loss: 2.7042365074157715  (2.8448627836564024)\n",
      "     | > log_mle: 0.5791677236557007  (0.6120655060623563)\n",
      "     | > loss_dur: 2.1250686645507812  (2.2327972779985994)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.1236, device='cuda:0')  (tensor(5.3071, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.6524  (0.6640644451072313)\n",
      "     | > loader_time: 0.0049  (0.004050253742960242)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:03:02 -- STEP: 467/811 -- GLOBAL_STEP: 2900\u001b[0m\n",
      "     | > loss: 2.7276711463928223  (2.837311107545646)\n",
      "     | > log_mle: 0.5860247611999512  (0.6103268504398025)\n",
      "     | > loss_dur: 2.141646385192871  (2.226984256850574)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.0506, device='cuda:0')  (tensor(5.2933, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.784  (0.6672723717046244)\n",
      "     | > loader_time: 0.0047  (0.004085598461633065)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:03:20 -- STEP: 492/811 -- GLOBAL_STEP: 2925\u001b[0m\n",
      "     | > loss: 2.6806397438049316  (2.8307895747626715)\n",
      "     | > log_mle: 0.5748803615570068  (0.6085415361373403)\n",
      "     | > loss_dur: 2.105759382247925  (2.2222480366869655)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.9877, device='cuda:0')  (tensor(5.2804, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.69  (0.668201573980533)\n",
      "     | > loader_time: 0.0043  (0.004103924685377416)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:03:38 -- STEP: 517/811 -- GLOBAL_STEP: 2950\u001b[0m\n",
      "     | > loss: 2.6923553943634033  (2.8235164145205895)\n",
      "     | > log_mle: 0.567064106464386  (0.6067948472799598)\n",
      "     | > loss_dur: 2.125291347503662  (2.216721565165417)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.0328, device='cuda:0')  (tensor(5.2664, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.8354  (0.6713089813807946)\n",
      "     | > loader_time: 0.0062  (0.004136246915481538)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:03:56 -- STEP: 542/811 -- GLOBAL_STEP: 2975\u001b[0m\n",
      "     | > loss: 2.710404872894287  (2.815908907964222)\n",
      "     | > log_mle: 0.5568853616714478  (0.6049983193513649)\n",
      "     | > loss_dur: 2.153519630432129  (2.210910588612854)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.9787, device='cuda:0')  (tensor(5.2519, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.6452  (0.6729782164316774)\n",
      "     | > loader_time: 0.0044  (0.0041435860179887055)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:04:14 -- STEP: 567/811 -- GLOBAL_STEP: 3000\u001b[0m\n",
      "     | > loss: 2.6104021072387695  (2.808680047013352)\n",
      "     | > log_mle: 0.561305046081543  (0.6032781298198395)\n",
      "     | > loss_dur: 2.0490970611572266  (2.20540191719351)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.8776, device='cuda:0')  (tensor(5.2391, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.6375  (0.6739891929390986)\n",
      "     | > loader_time: 0.0041  (0.004150258170233834)\n",
      "\n",
      "\n",
      " > CHECKPOINT : tts_train_dir/run-February-28-2024_10+25PM-0000000/checkpoint_3000.pth\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:04:35 -- STEP: 592/811 -- GLOBAL_STEP: 3025\u001b[0m\n",
      "     | > loss: 2.661238193511963  (2.8015124644782103)\n",
      "     | > log_mle: 0.5670965909957886  (0.601595550775528)\n",
      "     | > loss_dur: 2.094141721725464  (2.1999169135013115)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.9450, device='cuda:0')  (tensor(5.2256, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.6481  (0.6753245483379103)\n",
      "     | > loader_time: 0.0041  (0.004164601097235809)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:04:52 -- STEP: 617/811 -- GLOBAL_STEP: 3050\u001b[0m\n",
      "     | > loss: 2.6456942558288574  (2.7943450426939447)\n",
      "     | > log_mle: 0.5581713914871216  (0.5999281350372287)\n",
      "     | > loss_dur: 2.0875229835510254  (2.1944169072702957)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.9229, device='cuda:0')  (tensor(5.2125, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.7345  (0.6764627078750336)\n",
      "     | > loader_time: 0.0054  (0.004175088394016654)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:05:10 -- STEP: 642/811 -- GLOBAL_STEP: 3075\u001b[0m\n",
      "     | > loss: 2.6512181758880615  (2.786786629403492)\n",
      "     | > log_mle: 0.5567520260810852  (0.5982466325210263)\n",
      "     | > loss_dur: 2.094466209411621  (2.1885399966967767)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.9655, device='cuda:0')  (tensor(5.1996, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.677  (0.6778855977400063)\n",
      "     | > loader_time: 0.0044  (0.004189799507830373)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:05:29 -- STEP: 667/811 -- GLOBAL_STEP: 3100\u001b[0m\n",
      "     | > loss: 2.6453981399536133  (2.779895557277743)\n",
      "     | > log_mle: 0.5418460369110107  (0.5965328193318541)\n",
      "     | > loss_dur: 2.1035521030426025  (2.1833627377671596)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.9016, device='cuda:0')  (tensor(5.1869, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.7765  (0.6798131455188382)\n",
      "     | > loader_time: 0.0052  (0.004207466674530169)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:05:47 -- STEP: 692/811 -- GLOBAL_STEP: 3125\u001b[0m\n",
      "     | > loss: 2.5924501419067383  (2.7736490454976965)\n",
      "     | > log_mle: 0.5488958358764648  (0.594787238822507)\n",
      "     | > loss_dur: 2.0435543060302734  (2.1788618068474515)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.8325, device='cuda:0')  (tensor(5.1757, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.7057  (0.6812178106666295)\n",
      "     | > loader_time: 0.0044  (0.004237111937793011)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:06:05 -- STEP: 717/811 -- GLOBAL_STEP: 3150\u001b[0m\n",
      "     | > loss: 2.4903221130371094  (2.7667834126965944)\n",
      "     | > log_mle: 0.5344772934913635  (0.5930795243926961)\n",
      "     | > loss_dur: 1.955844759941101  (2.1737038879713704)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.7324, device='cuda:0')  (tensor(5.1633, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.797  (0.6829351816882305)\n",
      "     | > loader_time: 0.0043  (0.004238815653440514)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:06:24 -- STEP: 742/811 -- GLOBAL_STEP: 3175\u001b[0m\n",
      "     | > loss: 2.5469465255737305  (2.759118600354364)\n",
      "     | > log_mle: 0.5420273542404175  (0.5914228934483385)\n",
      "     | > loss_dur: 2.0049190521240234  (2.16769570674536)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.7844, device='cuda:0')  (tensor(5.1502, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.7215  (0.6849218475208121)\n",
      "     | > loader_time: 0.0042  (0.004244493667006175)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:06:42 -- STEP: 767/811 -- GLOBAL_STEP: 3200\u001b[0m\n",
      "     | > loss: 2.590956211090088  (2.752046555241832)\n",
      "     | > log_mle: 0.53623366355896  (0.5898125669014345)\n",
      "     | > loss_dur: 2.054722547531128  (2.1622339878741235)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.8342, device='cuda:0')  (tensor(5.1380, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.6763  (0.6861106423075843)\n",
      "     | > loader_time: 0.0048  (0.004261962438033804)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:07:00 -- STEP: 792/811 -- GLOBAL_STEP: 3225\u001b[0m\n",
      "     | > loss: 2.4981393814086914  (2.7447532123387486)\n",
      "     | > log_mle: 0.5321521759033203  (0.5881986225193196)\n",
      "     | > loss_dur: 1.9659873247146606  (2.156554589819423)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.7174, device='cuda:0')  (tensor(5.1261, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.725  (0.6873874390366096)\n",
      "     | > loader_time: 0.0059  (0.004275800302775225)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0037384629249572754 \u001b[0m(-0.0016485005617141724)\n",
      "     | > avg_loss:\u001b[92m 2.439935624599457 \u001b[0m(-0.45561055839061737)\n",
      "     | > avg_log_mle:\u001b[92m 0.5381851829588413 \u001b[0m(-0.09372143819928169)\n",
      "     | > avg_loss_dur:\u001b[92m 1.9017504304647446 \u001b[0m(-0.361889123916626)\n",
      "\n",
      " > BEST MODEL : tts_train_dir/run-February-28-2024_10+25PM-0000000/best_model_3244.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 4/10\u001b[0m\n",
      " --> tts_train_dir/run-February-28-2024_10+25PM-0000000\n",
      "\n",
      "\u001b[1m > TRAINING (2024-02-28 23:07:25) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:07:30 -- STEP: 6/811 -- GLOBAL_STEP: 3250\u001b[0m\n",
      "     | > loss: 2.686654567718506  (2.606092095375061)\n",
      "     | > log_mle: 0.561168372631073  (0.5593898197015127)\n",
      "     | > loss_dur: 2.125486135482788  (2.046702226003011)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.0671, device='cuda:0')  (tensor(4.8324, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.5894  (0.5611374775568644)\n",
      "     | > loader_time: 0.0022  (0.0026466846466064453)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:07:45 -- STEP: 31/811 -- GLOBAL_STEP: 3275\u001b[0m\n",
      "     | > loss: 2.4836843013763428  (2.5561089054230717)\n",
      "     | > log_mle: 0.5484009981155396  (0.5556145233492696)\n",
      "     | > loss_dur: 1.9352833032608032  (2.0004943570783063)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.7250, device='cuda:0')  (tensor(4.7868, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.6034  (0.5779398410551009)\n",
      "     | > loader_time: 0.003  (0.0028097091182585684)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:08:00 -- STEP: 56/811 -- GLOBAL_STEP: 3300\u001b[0m\n",
      "     | > loss: 2.411099910736084  (2.524678915739059)\n",
      "     | > log_mle: 0.5480575561523438  (0.5547503690634453)\n",
      "     | > loss_dur: 1.8630424737930298  (1.9699285285813468)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.5719, device='cuda:0')  (tensor(4.7517, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.5779  (0.5885000271456585)\n",
      "     | > loader_time: 0.003  (0.002943239041737148)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:08:15 -- STEP: 81/811 -- GLOBAL_STEP: 3325\u001b[0m\n",
      "     | > loss: 2.333853244781494  (2.508275317557064)\n",
      "     | > log_mle: 0.5547095537185669  (0.5532471905519931)\n",
      "     | > loss_dur: 1.7791438102722168  (1.955028110080295)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.4568, device='cuda:0')  (tensor(4.7278, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.5784  (0.5890597502390545)\n",
      "     | > loader_time: 0.0026  (0.0029749105006088446)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:08:30 -- STEP: 106/811 -- GLOBAL_STEP: 3350\u001b[0m\n",
      "     | > loss: 2.4964776039123535  (2.496795519342961)\n",
      "     | > log_mle: 0.5501171350479126  (0.5507911904802858)\n",
      "     | > loss_dur: 1.946360468864441  (1.9460043131180529)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.7905, device='cuda:0')  (tensor(4.7113, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.6424  (0.5928848959364986)\n",
      "     | > loader_time: 0.0033  (0.003076033772162671)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:08:46 -- STEP: 131/811 -- GLOBAL_STEP: 3375\u001b[0m\n",
      "     | > loss: 2.5345611572265625  (2.4850893657626076)\n",
      "     | > log_mle: 0.5301220417022705  (0.548387962898225)\n",
      "     | > loss_dur: 2.004439115524292  (1.936701389669462)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.7796, device='cuda:0')  (tensor(4.6965, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.6989  (0.5984952813796419)\n",
      "     | > loader_time: 0.0037  (0.0031435981051612448)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:09:02 -- STEP: 156/811 -- GLOBAL_STEP: 3400\u001b[0m\n",
      "     | > loss: 2.3729283809661865  (2.477232392017658)\n",
      "     | > log_mle: 0.5278866291046143  (0.5457665412089764)\n",
      "     | > loss_dur: 1.8450417518615723  (1.9314658427849793)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.5249, device='cuda:0')  (tensor(4.6870, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.6069  (0.6056293891026427)\n",
      "     | > loader_time: 0.0036  (0.003204654424618452)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:09:18 -- STEP: 181/811 -- GLOBAL_STEP: 3425\u001b[0m\n",
      "     | > loss: 2.423189640045166  (2.4651811057032815)\n",
      "     | > log_mle: 0.5185612440109253  (0.5433512804257938)\n",
      "     | > loss_dur: 1.9046285152435303  (1.9218298183620306)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.6551, device='cuda:0')  (tensor(4.6693, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.6577  (0.6100948607724019)\n",
      "     | > loader_time: 0.0042  (0.0032911366520665627)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:09:35 -- STEP: 206/811 -- GLOBAL_STEP: 3450\u001b[0m\n",
      "     | > loss: 2.407438278198242  (2.4550887172661957)\n",
      "     | > log_mle: 0.5046420097351074  (0.5407029168987741)\n",
      "     | > loss_dur: 1.9027962684631348  (1.9143857926998324)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.6041, device='cuda:0')  (tensor(4.6560, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.6293  (0.6162225216337779)\n",
      "     | > loader_time: 0.0039  (0.003380504626672245)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:09:51 -- STEP: 231/811 -- GLOBAL_STEP: 3475\u001b[0m\n",
      "     | > loss: 2.410130023956299  (2.444007105641553)\n",
      "     | > log_mle: 0.5284092426300049  (0.538506664367982)\n",
      "     | > loss_dur: 1.881720781326294  (1.9055004315974908)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.5966, device='cuda:0')  (tensor(4.6412, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.6439  (0.6197235171413009)\n",
      "     | > loader_time: 0.0047  (0.003447601805517684)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:10:08 -- STEP: 256/811 -- GLOBAL_STEP: 3500\u001b[0m\n",
      "     | > loss: 2.402057647705078  (2.434458153322341)\n",
      "     | > log_mle: 0.5170481204986572  (0.5361246588872752)\n",
      "     | > loss_dur: 1.885009527206421  (1.8983334861695766)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.5626, device='cuda:0')  (tensor(4.6275, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.7007  (0.6234722631052136)\n",
      "     | > loader_time: 0.0039  (0.003507561981678009)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:10:25 -- STEP: 281/811 -- GLOBAL_STEP: 3525\u001b[0m\n",
      "     | > loss: 2.245293617248535  (2.427475021403033)\n",
      "     | > log_mle: 0.4982879161834717  (0.5337387749733029)\n",
      "     | > loss_dur: 1.747005581855774  (1.8937362381571976)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.3400, device='cuda:0')  (tensor(4.6191, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.6519  (0.629833812815439)\n",
      "     | > loader_time: 0.0041  (0.003561511158518944)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:10:43 -- STEP: 306/811 -- GLOBAL_STEP: 3550\u001b[0m\n",
      "     | > loss: 2.2418928146362305  (2.419745807554209)\n",
      "     | > log_mle: 0.51397705078125  (0.5316766531638851)\n",
      "     | > loss_dur: 1.7279157638549805  (1.8880691446510016)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.3632, device='cuda:0')  (tensor(4.6095, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.6587  (0.6346334764380863)\n",
      "     | > loader_time: 0.0039  (0.0035999335494695927)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:11:00 -- STEP: 331/811 -- GLOBAL_STEP: 3575\u001b[0m\n",
      "     | > loss: 2.314979314804077  (2.412469006737195)\n",
      "     | > log_mle: 0.49181613326072693  (0.5295571432733109)\n",
      "     | > loss_dur: 1.8231632709503174  (1.8829118542800858)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.4327, device='cuda:0')  (tensor(4.5996, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.6289  (0.6381628016330683)\n",
      "     | > loader_time: 0.0039  (0.0036416284267275713)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:11:17 -- STEP: 356/811 -- GLOBAL_STEP: 3600\u001b[0m\n",
      "     | > loss: 2.2974865436553955  (2.405162929818873)\n",
      "     | > log_mle: 0.5003264546394348  (0.5275612887036942)\n",
      "     | > loss_dur: 1.797160029411316  (1.8776016322414526)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.4635, device='cuda:0')  (tensor(4.5900, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.6626  (0.6400431434759933)\n",
      "     | > loader_time: 0.004  (0.0036754233113835367)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:11:34 -- STEP: 381/811 -- GLOBAL_STEP: 3625\u001b[0m\n",
      "     | > loss: 2.31158185005188  (2.3987137927158013)\n",
      "     | > log_mle: 0.49562156200408936  (0.525410891361438)\n",
      "     | > loss_dur: 1.8159602880477905  (1.8733028946273282)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.4920, device='cuda:0')  (tensor(4.5820, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.636  (0.6442311054139624)\n",
      "     | > loader_time: 0.004  (0.0037158956052124343)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:11:52 -- STEP: 406/811 -- GLOBAL_STEP: 3650\u001b[0m\n",
      "     | > loss: 2.3464159965515137  (2.391136721437203)\n",
      "     | > log_mle: 0.4977733790874481  (0.5236353042530904)\n",
      "     | > loss_dur: 1.8486425876617432  (1.8675014103574705)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.5400, device='cuda:0')  (tensor(4.5722, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.6508  (0.6479917476917135)\n",
      "     | > loader_time: 0.0044  (0.0037557526762262354)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:12:10 -- STEP: 431/811 -- GLOBAL_STEP: 3675\u001b[0m\n",
      "     | > loss: 2.258192539215088  (2.383542339652433)\n",
      "     | > log_mle: 0.48153677582740784  (0.5216558599831613)\n",
      "     | > loss_dur: 1.776655673980713  (1.8618864725471374)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.3840, device='cuda:0')  (tensor(4.5627, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.7624  (0.6518998383922533)\n",
      "     | > loader_time: 0.0043  (0.0037864548977455796)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:12:28 -- STEP: 456/811 -- GLOBAL_STEP: 3700\u001b[0m\n",
      "     | > loss: 2.29785418510437  (2.3765415141457025)\n",
      "     | > log_mle: 0.4753120541572571  (0.5197939394336)\n",
      "     | > loss_dur: 1.8225420713424683  (1.8567475686993515)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.4701, device='cuda:0')  (tensor(4.5541, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.7454  (0.6552740983795702)\n",
      "     | > loader_time: 0.0047  (0.003809760537063866)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:12:46 -- STEP: 481/811 -- GLOBAL_STEP: 3725\u001b[0m\n",
      "     | > loss: 2.2206528186798096  (2.3704669257459443)\n",
      "     | > log_mle: 0.48010608553886414  (0.5178995082259429)\n",
      "     | > loss_dur: 1.740546703338623  (1.8525674120056406)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.3487, device='cuda:0')  (tensor(4.5469, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.6516  (0.6577596599991257)\n",
      "     | > loader_time: 0.0045  (0.003835113033683285)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:13:04 -- STEP: 506/811 -- GLOBAL_STEP: 3750\u001b[0m\n",
      "     | > loss: 2.2580063343048096  (2.364316925229764)\n",
      "     | > log_mle: 0.47721192240715027  (0.5161169597164917)\n",
      "     | > loss_dur: 1.7807945013046265  (1.8481999600357688)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.4318, device='cuda:0')  (tensor(4.5389, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.6595  (0.6605681270478743)\n",
      "     | > loader_time: 0.0037  (0.003852248191833496)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:13:22 -- STEP: 531/811 -- GLOBAL_STEP: 3775\u001b[0m\n",
      "     | > loss: 2.2283289432525635  (2.357867618514097)\n",
      "     | > log_mle: 0.46703585982322693  (0.5142801198020945)\n",
      "     | > loss_dur: 1.7612930536270142  (1.8435874932678855)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.3294, device='cuda:0')  (tensor(4.5312, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.7667  (0.6629531352084461)\n",
      "     | > loader_time: 0.0046  (0.0038829114702012804)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:13:40 -- STEP: 556/811 -- GLOBAL_STEP: 3800\u001b[0m\n",
      "     | > loss: 2.2286288738250732  (2.351807231096915)\n",
      "     | > log_mle: 0.48631301522254944  (0.5125059715385064)\n",
      "     | > loss_dur: 1.7423158884048462  (1.8393012555383095)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.3825, device='cuda:0')  (tensor(4.5242, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.767  (0.6661002099942819)\n",
      "     | > loader_time: 0.0047  (0.003914267467937881)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:13:59 -- STEP: 581/811 -- GLOBAL_STEP: 3825\u001b[0m\n",
      "     | > loss: 2.187222719192505  (2.3455865686813886)\n",
      "     | > log_mle: 0.4571324586868286  (0.5107186986021252)\n",
      "     | > loss_dur: 1.7300902605056763  (1.8348678666425038)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.3289, device='cuda:0')  (tensor(4.5168, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.654  (0.6684477591883912)\n",
      "     | > loader_time: 0.0044  (0.003941124769988856)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:14:17 -- STEP: 606/811 -- GLOBAL_STEP: 3850\u001b[0m\n",
      "     | > loss: 2.174229383468628  (2.3397137457781527)\n",
      "     | > log_mle: 0.4745849072933197  (0.5090824321354974)\n",
      "     | > loss_dur: 1.6996444463729858  (1.8306313100034255)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.2417, device='cuda:0')  (tensor(4.5089, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.661  (0.6712049438615048)\n",
      "     | > loader_time: 0.0045  (0.003966251615643896)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:14:36 -- STEP: 631/811 -- GLOBAL_STEP: 3875\u001b[0m\n",
      "     | > loss: 2.1615560054779053  (2.3335000951014333)\n",
      "     | > log_mle: 0.45467689633369446  (0.5074017758698174)\n",
      "     | > loss_dur: 1.7068791389465332  (1.8260983153114985)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.3733, device='cuda:0')  (tensor(4.5018, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.6955  (0.6737083417677842)\n",
      "     | > loader_time: 0.0043  (0.004012816303694497)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:14:55 -- STEP: 656/811 -- GLOBAL_STEP: 3900\u001b[0m\n",
      "     | > loss: 2.1805591583251953  (2.3272281245487516)\n",
      "     | > log_mle: 0.4643465280532837  (0.5057587028912666)\n",
      "     | > loss_dur: 1.716212511062622  (1.8214694176141808)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.3249, device='cuda:0')  (tensor(4.4944, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.766  (0.6766139385176868)\n",
      "     | > loader_time: 0.0046  (0.004037756381965267)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:15:13 -- STEP: 681/811 -- GLOBAL_STEP: 3925\u001b[0m\n",
      "     | > loss: 2.1903340816497803  (2.3222444011951526)\n",
      "     | > log_mle: 0.4629165530204773  (0.5040929940215999)\n",
      "     | > loss_dur: 1.7274174690246582  (1.818151403628782)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.2730, device='cuda:0')  (tensor(4.4883, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.6732  (0.6791469959785584)\n",
      "     | > loader_time: 0.0049  (0.004065649800013516)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:15:32 -- STEP: 706/811 -- GLOBAL_STEP: 3950\u001b[0m\n",
      "     | > loss: 2.1154370307922363  (2.3166697167134527)\n",
      "     | > log_mle: 0.4524359107017517  (0.5024088884126032)\n",
      "     | > loss_dur: 1.6630011796951294  (1.8142608252193029)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.2415, device='cuda:0')  (tensor(4.4813, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.7284  (0.6817851694717622)\n",
      "     | > loader_time: 0.0061  (0.004093454849956391)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:15:51 -- STEP: 731/811 -- GLOBAL_STEP: 3975\u001b[0m\n",
      "     | > loss: 2.030287027359009  (2.3104797877300007)\n",
      "     | > log_mle: 0.45213234424591064  (0.5007710829886797)\n",
      "     | > loss_dur: 1.5781546831130981  (1.8097087019282392)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.0974, device='cuda:0')  (tensor(4.4733, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.8287  (0.6839970586727155)\n",
      "     | > loader_time: 0.0049  (0.004127159653544912)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:16:10 -- STEP: 756/811 -- GLOBAL_STEP: 4000\u001b[0m\n",
      "     | > loss: 2.126521348953247  (2.3043317615039802)\n",
      "     | > log_mle: 0.45639660954475403  (0.49915654992773467)\n",
      "     | > loss_dur: 1.6701246500015259  (1.8051752093292417)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.2085, device='cuda:0')  (tensor(4.4650, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.7005  (0.6861733135092194)\n",
      "     | > loader_time: 0.0045  (0.004158938057208186)\n",
      "\n",
      "\n",
      " > CHECKPOINT : tts_train_dir/run-February-28-2024_10+25PM-0000000/checkpoint_4000.pth\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:16:33 -- STEP: 781/811 -- GLOBAL_STEP: 4025\u001b[0m\n",
      "     | > loss: 2.103314161300659  (2.298067666504359)\n",
      "     | > log_mle: 0.4423777461051941  (0.4976565844347173)\n",
      "     | > loss_dur: 1.6609363555908203  (1.8004110801235205)\n",
      "     | > amp_scaler: 16384.0  (16404.97823303457)\n",
      "     | > grad_norm: tensor(4.2053, device='cuda:0')  (tensor(4.4510, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.7194  (0.6888279041773835)\n",
      "     | > loader_time: 0.0046  (0.004186792349235348)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:16:52 -- STEP: 806/811 -- GLOBAL_STEP: 4050\u001b[0m\n",
      "     | > loss: 2.0564169883728027  (2.292035524365924)\n",
      "     | > log_mle: 0.4535333514213562  (0.4960739127829416)\n",
      "     | > loss_dur: 1.6028835773468018  (1.7959616099930282)\n",
      "     | > amp_scaler: 16384.0  (16404.32754342432)\n",
      "     | > grad_norm: tensor(4.1369, device='cuda:0')  (tensor(4.4429, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.6744  (0.6907288454306627)\n",
      "     | > loader_time: 0.0049  (0.004207212043459305)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0034871697425842285 \u001b[0m(-0.0002512931823730469)\n",
      "     | > avg_loss:\u001b[92m 2.0234689712524414 \u001b[0m(-0.4164666533470154)\n",
      "     | > avg_log_mle:\u001b[92m 0.4511409308761358 \u001b[0m(-0.0870442520827055)\n",
      "     | > avg_loss_dur:\u001b[92m 1.5723280236124992 \u001b[0m(-0.32942240685224533)\n",
      "\n",
      " > BEST MODEL : tts_train_dir/run-February-28-2024_10+25PM-0000000/best_model_4055.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 5/10\u001b[0m\n",
      " --> tts_train_dir/run-February-28-2024_10+25PM-0000000\n",
      "\n",
      "\u001b[1m > TRAINING (2024-02-28 23:17:08) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:17:22 -- STEP: 20/811 -- GLOBAL_STEP: 4075\u001b[0m\n",
      "     | > loss: 2.190786838531494  (2.1773383140563967)\n",
      "     | > log_mle: 0.47062551975250244  (0.47806023210287096)\n",
      "     | > loss_dur: 1.7201614379882812  (1.699278086423874)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.3573, device='cuda:0')  (tensor(4.3018, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.5799  (0.5834261536598205)\n",
      "     | > loader_time: 0.0028  (0.002765655517578125)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:17:37 -- STEP: 45/811 -- GLOBAL_STEP: 4100\u001b[0m\n",
      "     | > loss: 1.9331400394439697  (2.1273025883568657)\n",
      "     | > log_mle: 0.46388906240463257  (0.47423611217074924)\n",
      "     | > loss_dur: 1.469251036643982  (1.6530664867824978)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.9370, device='cuda:0')  (tensor(4.2381, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.6174  (0.5924635834164089)\n",
      "     | > loader_time: 0.0033  (0.0029806031121148)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:17:53 -- STEP: 70/811 -- GLOBAL_STEP: 4125\u001b[0m\n",
      "     | > loss: 2.0925137996673584  (2.1097594669887005)\n",
      "     | > log_mle: 0.45226508378982544  (0.4724688334124429)\n",
      "     | > loss_dur: 1.6402487754821777  (1.6372906497546604)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.2156, device='cuda:0')  (tensor(4.2054, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.6457  (0.603811400277274)\n",
      "     | > loader_time: 0.0031  (0.0030825648988996234)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:18:08 -- STEP: 95/811 -- GLOBAL_STEP: 4150\u001b[0m\n",
      "     | > loss: 2.032606601715088  (2.094205704488252)\n",
      "     | > log_mle: 0.4589742422103882  (0.4710617219146929)\n",
      "     | > loss_dur: 1.5736324787139893  (1.6231439979452835)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.1221, device='cuda:0')  (tensor(4.1780, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.6145  (0.6104600479728297)\n",
      "     | > loader_time: 0.0032  (0.00314337830794485)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:18:25 -- STEP: 120/811 -- GLOBAL_STEP: 4175\u001b[0m\n",
      "     | > loss: 2.014941692352295  (2.084301370382308)\n",
      "     | > log_mle: 0.44763848185539246  (0.46788019488255184)\n",
      "     | > loss_dur: 1.5673032999038696  (1.6164211889108022)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.1067, device='cuda:0')  (tensor(4.1603, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.6356  (0.6182733456293743)\n",
      "     | > loader_time: 0.0034  (0.003211979071299235)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:18:41 -- STEP: 145/811 -- GLOBAL_STEP: 4200\u001b[0m\n",
      "     | > loss: 2.0216543674468994  (2.073583523980502)\n",
      "     | > log_mle: 0.4619845747947693  (0.46600127528453694)\n",
      "     | > loss_dur: 1.5596697330474854  (1.6075822632888268)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.0403, device='cuda:0')  (tensor(4.1382, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.6649  (0.6245903837269752)\n",
      "     | > loader_time: 0.004  (0.003281839962663322)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:18:58 -- STEP: 170/811 -- GLOBAL_STEP: 4225\u001b[0m\n",
      "     | > loss: 1.9498724937438965  (2.064486708360559)\n",
      "     | > log_mle: 0.4263238310813904  (0.4632738241377999)\n",
      "     | > loss_dur: 1.5235487222671509  (1.6012128956177658)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.8852, device='cuda:0')  (tensor(4.1205, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.6826  (0.6289349079132079)\n",
      "     | > loader_time: 0.0036  (0.003325675515567555)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:19:15 -- STEP: 195/811 -- GLOBAL_STEP: 4250\u001b[0m\n",
      "     | > loss: 1.9835577011108398  (2.052767371520018)\n",
      "     | > log_mle: 0.4443923830986023  (0.4607395821656936)\n",
      "     | > loss_dur: 1.5391652584075928  (1.5920277998997618)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.0086, device='cuda:0')  (tensor(4.1002, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.7342  (0.6350324300619273)\n",
      "     | > loader_time: 0.0036  (0.0033792813618977865)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:19:32 -- STEP: 220/811 -- GLOBAL_STEP: 4275\u001b[0m\n",
      "     | > loss: 1.9954620599746704  (2.043288250944832)\n",
      "     | > log_mle: 0.4416574537754059  (0.45867325934496794)\n",
      "     | > loss_dur: 1.553804636001587  (1.5846150013533509)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.9935, device='cuda:0')  (tensor(4.0836, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.7104  (0.6407203685153615)\n",
      "     | > loader_time: 0.0037  (0.0034172036431052467)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:19:49 -- STEP: 245/811 -- GLOBAL_STEP: 4300\u001b[0m\n",
      "     | > loss: 1.9002074003219604  (2.034874355063147)\n",
      "     | > log_mle: 0.45651158690452576  (0.456395624000199)\n",
      "     | > loss_dur: 1.4436957836151123  (1.578478737753265)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.8581, device='cuda:0')  (tensor(4.0678, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.7833  (0.645152470530296)\n",
      "     | > loader_time: 0.0037  (0.0034677768240169602)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:20:07 -- STEP: 270/811 -- GLOBAL_STEP: 4325\u001b[0m\n",
      "     | > loss: 1.9394352436065674  (2.027335732513005)\n",
      "     | > log_mle: 0.4364878237247467  (0.45409819925272904)\n",
      "     | > loss_dur: 1.502947449684143  (1.5732375387792235)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.8487, device='cuda:0')  (tensor(4.0537, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.6331  (0.6494708449752243)\n",
      "     | > loader_time: 0.0038  (0.0035053094228108725)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:20:24 -- STEP: 295/811 -- GLOBAL_STEP: 4350\u001b[0m\n",
      "     | > loss: 1.9894483089447021  (2.0211895902278068)\n",
      "     | > log_mle: 0.42828017473220825  (0.4520137176675312)\n",
      "     | > loss_dur: 1.5611681938171387  (1.5691758766012676)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.9517, device='cuda:0')  (tensor(4.0429, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.6749  (0.652788488743669)\n",
      "     | > loader_time: 0.0039  (0.003535856634883557)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:20:41 -- STEP: 320/811 -- GLOBAL_STEP: 4375\u001b[0m\n",
      "     | > loss: 1.920891523361206  (2.0147400010377168)\n",
      "     | > log_mle: 0.4248524606227875  (0.45025090463459494)\n",
      "     | > loss_dur: 1.4960390329360962  (1.56448910087347)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.8877, device='cuda:0')  (tensor(4.0310, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.6858  (0.6552549339830873)\n",
      "     | > loader_time: 0.0039  (0.0035615570843219755)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:20:59 -- STEP: 345/811 -- GLOBAL_STEP: 4400\u001b[0m\n",
      "     | > loss: 1.9645112752914429  (2.0081830366798084)\n",
      "     | > log_mle: 0.4256730377674103  (0.4483906601650127)\n",
      "     | > loss_dur: 1.538838267326355  (1.5597923800565194)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.8704, device='cuda:0')  (tensor(4.0177, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.6297  (0.6574183491693026)\n",
      "     | > loader_time: 0.0038  (0.0035839419434036033)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:21:16 -- STEP: 370/811 -- GLOBAL_STEP: 4425\u001b[0m\n",
      "     | > loss: 1.8758946657180786  (2.0018352183135804)\n",
      "     | > log_mle: 0.4207967221736908  (0.446602741850389)\n",
      "     | > loss_dur: 1.4550979137420654  (1.555232479121234)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.7980, device='cuda:0')  (tensor(4.0052, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.7104  (0.660550758645341)\n",
      "     | > loader_time: 0.0039  (0.0035964527645626584)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:21:34 -- STEP: 395/811 -- GLOBAL_STEP: 4450\u001b[0m\n",
      "     | > loss: 1.9044241905212402  (1.9956199821037608)\n",
      "     | > log_mle: 0.42384567856788635  (0.4448185551770126)\n",
      "     | > loss_dur: 1.4805785417556763  (1.550801430171049)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.7943, device='cuda:0')  (tensor(3.9929, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.6451  (0.6630270909659467)\n",
      "     | > loader_time: 0.0038  (0.003619739073741285)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:21:51 -- STEP: 420/811 -- GLOBAL_STEP: 4475\u001b[0m\n",
      "     | > loss: 1.842345952987671  (1.989112135909855)\n",
      "     | > log_mle: 0.4301917254924774  (0.44322355006422315)\n",
      "     | > loss_dur: 1.412154197692871  (1.54588858854203)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.7352, device='cuda:0')  (tensor(3.9808, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.7034  (0.6644105116526283)\n",
      "     | > loader_time: 0.004  (0.0036426691781906856)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:22:09 -- STEP: 445/811 -- GLOBAL_STEP: 4500\u001b[0m\n",
      "     | > loss: 1.847123384475708  (1.9825437143947324)\n",
      "     | > log_mle: 0.4084118604660034  (0.44147759180390433)\n",
      "     | > loss_dur: 1.4387115240097046  (1.5410661255375724)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.6944, device='cuda:0')  (tensor(3.9681, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.6397  (0.6666698991582632)\n",
      "     | > loader_time: 0.0047  (0.0036619079246949615)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:22:27 -- STEP: 470/811 -- GLOBAL_STEP: 4525\u001b[0m\n",
      "     | > loss: 1.915168046951294  (1.9767644887274907)\n",
      "     | > log_mle: 0.3932439088821411  (0.43984242557211123)\n",
      "     | > loss_dur: 1.5219241380691528  (1.536922066008791)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.8417, device='cuda:0')  (tensor(3.9570, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.6906  (0.6683840021174002)\n",
      "     | > loader_time: 0.0039  (0.0036755921992849797)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:22:45 -- STEP: 495/811 -- GLOBAL_STEP: 4550\u001b[0m\n",
      "     | > loss: 1.8316819667816162  (1.971055103311637)\n",
      "     | > log_mle: 0.42302215099334717  (0.43836831914054025)\n",
      "     | > loss_dur: 1.408659815788269  (1.5326867871814305)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.6279, device='cuda:0')  (tensor(3.9454, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.6666  (0.6705310330246432)\n",
      "     | > loader_time: 0.0041  (0.003692088945947512)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:23:02 -- STEP: 520/811 -- GLOBAL_STEP: 4575\u001b[0m\n",
      "     | > loss: 1.819458246231079  (1.9658721618927462)\n",
      "     | > log_mle: 0.3971291780471802  (0.4367517476471571)\n",
      "     | > loss_dur: 1.422329068183899  (1.5291204170538828)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.6747, device='cuda:0')  (tensor(3.9349, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.7137  (0.6717204061838294)\n",
      "     | > loader_time: 0.004  (0.0037113817838522103)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:23:20 -- STEP: 545/811 -- GLOBAL_STEP: 4600\u001b[0m\n",
      "     | > loss: 1.8363091945648193  (1.9601892171649775)\n",
      "     | > log_mle: 0.40227580070495605  (0.43524223664484984)\n",
      "     | > loss_dur: 1.4340333938598633  (1.5249469827074524)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.7380, device='cuda:0')  (tensor(3.9238, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.7189  (0.6734234109931034)\n",
      "     | > loader_time: 0.0038  (0.0037270633452529205)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:23:39 -- STEP: 570/811 -- GLOBAL_STEP: 4625\u001b[0m\n",
      "     | > loss: 1.8105263710021973  (1.9547004902571978)\n",
      "     | > log_mle: 0.41377389430999756  (0.43377402236587126)\n",
      "     | > loss_dur: 1.3967524766921997  (1.5209264702964245)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.5896, device='cuda:0')  (tensor(3.9123, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.6611  (0.6761815443373561)\n",
      "     | > loader_time: 0.0041  (0.00375129967405085)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:23:57 -- STEP: 595/811 -- GLOBAL_STEP: 4650\u001b[0m\n",
      "     | > loss: 1.8435375690460205  (1.9496282411222714)\n",
      "     | > log_mle: 0.4043123126029968  (0.4323830394183888)\n",
      "     | > loss_dur: 1.4392253160476685  (1.5172452043084534)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.6421, device='cuda:0')  (tensor(3.9012, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.8152  (0.6788946893034862)\n",
      "     | > loader_time: 0.0041  (0.0037731811779887735)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:24:16 -- STEP: 620/811 -- GLOBAL_STEP: 4675\u001b[0m\n",
      "     | > loss: 1.8005872964859009  (1.9443183925844023)\n",
      "     | > log_mle: 0.4092632532119751  (0.4310238835311705)\n",
      "     | > loss_dur: 1.3913240432739258  (1.5132945116489167)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.6550, device='cuda:0')  (tensor(3.8902, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.7568  (0.6807296114583171)\n",
      "     | > loader_time: 0.005  (0.0037906269873342205)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:24:35 -- STEP: 645/811 -- GLOBAL_STEP: 4700\u001b[0m\n",
      "     | > loss: 1.9171139001846313  (1.9389917290487968)\n",
      "     | > log_mle: 0.3926677703857422  (0.4296258584473484)\n",
      "     | > loss_dur: 1.5244461297988892  (1.5093658733737567)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.7698, device='cuda:0')  (tensor(3.8793, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.6725  (0.6837581272273102)\n",
      "     | > loader_time: 0.0043  (0.0038105543269667513)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:24:53 -- STEP: 670/811 -- GLOBAL_STEP: 4725\u001b[0m\n",
      "     | > loss: 1.8139935731887817  (1.9342199848659016)\n",
      "     | > log_mle: 0.37898075580596924  (0.4281903314056681)\n",
      "     | > loss_dur: 1.4350128173828125  (1.5060296567518323)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.5908, device='cuda:0')  (tensor(3.8692, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.7613  (0.6849874357678997)\n",
      "     | > loader_time: 0.0039  (0.0038239151684205924)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:25:12 -- STEP: 695/811 -- GLOBAL_STEP: 4750\u001b[0m\n",
      "     | > loss: 1.8042869567871094  (1.9296120240533965)\n",
      "     | > log_mle: 0.39261478185653687  (0.42675268478530776)\n",
      "     | > loss_dur: 1.4116721153259277  (1.5028593421839982)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.5676, device='cuda:0')  (tensor(3.8597, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.7858  (0.6870353245906688)\n",
      "     | > loader_time: 0.0053  (0.0038533028938787448)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:25:30 -- STEP: 720/811 -- GLOBAL_STEP: 4775\u001b[0m\n",
      "     | > loss: 1.7870399951934814  (1.924651746451856)\n",
      "     | > log_mle: 0.3769848942756653  (0.42535839130481085)\n",
      "     | > loss_dur: 1.4100550413131714  (1.4992933579617076)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.5182, device='cuda:0')  (tensor(3.8492, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.7195  (0.6889961202939345)\n",
      "     | > loader_time: 0.005  (0.0038810455136828953)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:25:49 -- STEP: 745/811 -- GLOBAL_STEP: 4800\u001b[0m\n",
      "     | > loss: 1.731446385383606  (1.9191070767857097)\n",
      "     | > log_mle: 0.39953505992889404  (0.4240277762381022)\n",
      "     | > loss_dur: 1.331911325454712  (1.4950793031078058)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.4498, device='cuda:0')  (tensor(3.8376, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.7025  (0.6911571374675567)\n",
      "     | > loader_time: 0.0046  (0.0039008070158478396)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:26:08 -- STEP: 770/811 -- GLOBAL_STEP: 4825\u001b[0m\n",
      "     | > loss: 1.751975655555725  (1.9141400848116206)\n",
      "     | > log_mle: 0.3869096040725708  (0.4227819664137704)\n",
      "     | > loss_dur: 1.3650660514831543  (1.4913581208749251)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.4532, device='cuda:0')  (tensor(3.8268, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.7762  (0.6930870557760259)\n",
      "     | > loader_time: 0.0056  (0.003938203043751904)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:26:28 -- STEP: 795/811 -- GLOBAL_STEP: 4850\u001b[0m\n",
      "     | > loss: 1.7375543117523193  (1.9089001012298308)\n",
      "     | > log_mle: 0.3861275911331177  (0.4214474972688927)\n",
      "     | > loss_dur: 1.3514267206192017  (1.4874526061351945)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.5027, device='cuda:0')  (tensor(3.8162, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.8144  (0.6955918854887376)\n",
      "     | > loader_time: 0.0047  (0.0039711559343637935)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.0059968531131744385 \u001b[0m(+0.00250968337059021)\n",
      "     | > avg_loss:\u001b[92m 1.683486357331276 \u001b[0m(-0.33998261392116547)\n",
      "     | > avg_log_mle:\u001b[92m 0.3854948915541172 \u001b[0m(-0.06564603932201862)\n",
      "     | > avg_loss_dur:\u001b[92m 1.2979914471507072 \u001b[0m(-0.274336576461792)\n",
      "\n",
      " > BEST MODEL : tts_train_dir/run-February-28-2024_10+25PM-0000000/best_model_4866.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 6/10\u001b[0m\n",
      " --> tts_train_dir/run-February-28-2024_10+25PM-0000000\n",
      "\n",
      "\u001b[1m > TRAINING (2024-02-28 23:26:55) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:27:02 -- STEP: 9/811 -- GLOBAL_STEP: 4875\u001b[0m\n",
      "     | > loss: 1.9658586978912354  (1.8795491059621174)\n",
      "     | > log_mle: 0.43416303396224976  (0.4173443847232395)\n",
      "     | > loss_dur: 1.5316956043243408  (1.462204721238878)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.7006, device='cuda:0')  (tensor(3.7002, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.5779  (0.5888272126515707)\n",
      "     | > loader_time: 0.0031  (0.0023728211720784507)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:27:17 -- STEP: 34/811 -- GLOBAL_STEP: 4900\u001b[0m\n",
      "     | > loss: 1.7154369354248047  (1.8007955901763018)\n",
      "     | > log_mle: 0.42426541447639465  (0.4114847735447042)\n",
      "     | > loss_dur: 1.2911715507507324  (1.3893108227673698)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.5062, device='cuda:0')  (tensor(3.5962, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.7087  (0.6080821261686438)\n",
      "     | > loader_time: 0.0039  (0.002846486428204705)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:27:33 -- STEP: 59/811 -- GLOBAL_STEP: 4925\u001b[0m\n",
      "     | > loss: 1.7502598762512207  (1.7695390046653101)\n",
      "     | > log_mle: 0.4231085181236267  (0.4109762492826429)\n",
      "     | > loss_dur: 1.3271512985229492  (1.3585627604339083)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.4425, device='cuda:0')  (tensor(3.5297, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.6469  (0.6096127437332929)\n",
      "     | > loader_time: 0.0033  (0.0030160920094635525)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:27:49 -- STEP: 84/811 -- GLOBAL_STEP: 4950\u001b[0m\n",
      "     | > loss: 1.6825408935546875  (1.755263818161828)\n",
      "     | > log_mle: 0.39185696840286255  (0.4097963145800999)\n",
      "     | > loss_dur: 1.2906838655471802  (1.3454675078392029)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.3531, device='cuda:0')  (tensor(3.4903, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.6474  (0.6131289516176496)\n",
      "     | > loader_time: 0.0034  (0.0031023195811680387)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:28:05 -- STEP: 109/811 -- GLOBAL_STEP: 4975\u001b[0m\n",
      "     | > loss: 1.7259080410003662  (1.7460322948770786)\n",
      "     | > log_mle: 0.3910539746284485  (0.40693392474716955)\n",
      "     | > loss_dur: 1.3348541259765625  (1.3390983780589676)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.4740, device='cuda:0')  (tensor(3.4695, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.6143  (0.6182682382951087)\n",
      "     | > loader_time: 0.0037  (0.0031811294205691836)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:28:21 -- STEP: 134/811 -- GLOBAL_STEP: 5000\u001b[0m\n",
      "     | > loss: 1.6540570259094238  (1.7368650036071664)\n",
      "     | > log_mle: 0.39528363943099976  (0.4046264933561211)\n",
      "     | > loss_dur: 1.2587734460830688  (1.3322385158111802)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.2367, device='cuda:0')  (tensor(3.4464, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.6084  (0.6208056709659632)\n",
      "     | > loader_time: 0.0035  (0.0032336267072763016)\n",
      "\n",
      "\n",
      " > CHECKPOINT : tts_train_dir/run-February-28-2024_10+25PM-0000000/checkpoint_5000.pth\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:28:39 -- STEP: 159/811 -- GLOBAL_STEP: 5025\u001b[0m\n",
      "     | > loss: 1.716792345046997  (1.7300108033905985)\n",
      "     | > log_mle: 0.37798500061035156  (0.40192050360283765)\n",
      "     | > loss_dur: 1.3388073444366455  (1.328090304848533)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.4366, device='cuda:0')  (tensor(3.4356, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.6946  (0.6249020789404334)\n",
      "     | > loader_time: 0.0035  (0.0032689286477910647)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:28:56 -- STEP: 184/811 -- GLOBAL_STEP: 5050\u001b[0m\n",
      "     | > loss: 1.6971465349197388  (1.7215454941210537)\n",
      "     | > log_mle: 0.36442482471466064  (0.39932534406366554)\n",
      "     | > loss_dur: 1.3327217102050781  (1.322220152486926)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.2777, device='cuda:0')  (tensor(3.4152, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.6278  (0.6290437540282372)\n",
      "     | > loader_time: 0.0036  (0.003302825533825418)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:29:13 -- STEP: 209/811 -- GLOBAL_STEP: 5075\u001b[0m\n",
      "     | > loss: 1.6869670152664185  (1.7136422931862787)\n",
      "     | > log_mle: 0.3771713972091675  (0.3969587465507562)\n",
      "     | > loss_dur: 1.309795618057251  (1.3166835490596356)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.3213, device='cuda:0')  (tensor(3.4021, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.658  (0.6327082494799603)\n",
      "     | > loader_time: 0.0039  (0.0033437692377555886)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:29:30 -- STEP: 234/811 -- GLOBAL_STEP: 5100\u001b[0m\n",
      "     | > loss: 1.6942343711853027  (1.706208882678268)\n",
      "     | > log_mle: 0.3665568232536316  (0.39489208875048876)\n",
      "     | > loss_dur: 1.3276774883270264  (1.3113167943098611)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.4037, device='cuda:0')  (tensor(3.3875, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.6892  (0.6378954292362574)\n",
      "     | > loader_time: 0.0035  (0.0033860084338065907)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:29:47 -- STEP: 259/811 -- GLOBAL_STEP: 5125\u001b[0m\n",
      "     | > loss: 1.6898976564407349  (1.6998039359751813)\n",
      "     | > log_mle: 0.37699341773986816  (0.3926733597595259)\n",
      "     | > loss_dur: 1.3129042387008667  (1.3071305774813917)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.3205, device='cuda:0')  (tensor(3.3746, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.7196  (0.6440218166955192)\n",
      "     | > loader_time: 0.0034  (0.0034126287261491577)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:30:05 -- STEP: 284/811 -- GLOBAL_STEP: 5150\u001b[0m\n",
      "     | > loss: 1.6405305862426758  (1.695333657969891)\n",
      "     | > log_mle: 0.37001699209213257  (0.3905612972210831)\n",
      "     | > loss_dur: 1.270513653755188  (1.3047723619031242)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.3299, device='cuda:0')  (tensor(3.3650, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.636  (0.646924845769372)\n",
      "     | > loader_time: 0.0037  (0.003440384293945742)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:30:22 -- STEP: 309/811 -- GLOBAL_STEP: 5175\u001b[0m\n",
      "     | > loss: 1.5652830600738525  (1.6902410906881191)\n",
      "     | > log_mle: 0.38315117359161377  (0.38888704574223865)\n",
      "     | > loss_dur: 1.1821318864822388  (1.3013540463925959)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.1008, device='cuda:0')  (tensor(3.3550, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.7048  (0.649520488232857)\n",
      "     | > loader_time: 0.0037  (0.00346827121228462)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:30:39 -- STEP: 334/811 -- GLOBAL_STEP: 5200\u001b[0m\n",
      "     | > loss: 1.5838654041290283  (1.6854965718920358)\n",
      "     | > log_mle: 0.36249250173568726  (0.3869321554185389)\n",
      "     | > loss_dur: 1.2213728427886963  (1.298564416919642)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.1501, device='cuda:0')  (tensor(3.3460, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.6428  (0.6523466431452133)\n",
      "     | > loader_time: 0.0039  (0.0035057010764847274)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:30:56 -- STEP: 359/811 -- GLOBAL_STEP: 5225\u001b[0m\n",
      "     | > loss: 1.5874903202056885  (1.6805175891493689)\n",
      "     | > log_mle: 0.365539014339447  (0.3854538938627271)\n",
      "     | > loss_dur: 1.2219512462615967  (1.2950636952036292)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.1373, device='cuda:0')  (tensor(3.3343, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.7298  (0.6538342094687037)\n",
      "     | > loader_time: 0.004  (0.0035302267101149716)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:31:13 -- STEP: 384/811 -- GLOBAL_STEP: 5250\u001b[0m\n",
      "     | > loss: 1.5576421022415161  (1.6762902236854036)\n",
      "     | > log_mle: 0.36321842670440674  (0.3835449295584114)\n",
      "     | > loss_dur: 1.1944236755371094  (1.2927452940493835)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.1249, device='cuda:0')  (tensor(3.3267, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.7596  (0.6557512885580463)\n",
      "     | > loader_time: 0.005  (0.003570375343163809)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:31:31 -- STEP: 409/811 -- GLOBAL_STEP: 5275\u001b[0m\n",
      "     | > loss: 1.593916654586792  (1.6713063883023624)\n",
      "     | > log_mle: 0.34914320707321167  (0.38215535930141564)\n",
      "     | > loss_dur: 1.244773507118225  (1.2891510299482105)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.2116, device='cuda:0')  (tensor(3.3180, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.7035  (0.6591596807419237)\n",
      "     | > loader_time: 0.0045  (0.0035981135146833584)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:31:48 -- STEP: 434/811 -- GLOBAL_STEP: 5300\u001b[0m\n",
      "     | > loss: 1.566659688949585  (1.6664865725600775)\n",
      "     | > log_mle: 0.3579755425453186  (0.38042870541596757)\n",
      "     | > loss_dur: 1.2086840867996216  (1.2860578680368078)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.1422, device='cuda:0')  (tensor(3.3092, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.6234  (0.6604839074446861)\n",
      "     | > loader_time: 0.004  (0.0036263251634237412)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:32:05 -- STEP: 459/811 -- GLOBAL_STEP: 5325\u001b[0m\n",
      "     | > loss: 1.5636409521102905  (1.6619208360289697)\n",
      "     | > log_mle: 0.3498345613479614  (0.3789811003831478)\n",
      "     | > loss_dur: 1.213806390762329  (1.2829397368794708)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.1165, device='cuda:0')  (tensor(3.3003, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.7148  (0.6600898491271443)\n",
      "     | > loader_time: 0.0039  (0.0036441495475685944)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:32:22 -- STEP: 484/811 -- GLOBAL_STEP: 5350\u001b[0m\n",
      "     | > loss: 1.5760316848754883  (1.6578459175657634)\n",
      "     | > log_mle: 0.33078116178512573  (0.3773862480008899)\n",
      "     | > loss_dur: 1.2452505826950073  (1.2804596704885007)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.1680, device='cuda:0')  (tensor(3.2918, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.7478  (0.661928713321686)\n",
      "     | > loader_time: 0.0039  (0.003661348307428282)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:32:40 -- STEP: 509/811 -- GLOBAL_STEP: 5375\u001b[0m\n",
      "     | > loss: 1.5647714138031006  (1.6541451185297638)\n",
      "     | > log_mle: 0.34697097539901733  (0.3759478868693407)\n",
      "     | > loss_dur: 1.2178003787994385  (1.2781972325386854)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.1954, device='cuda:0')  (tensor(3.2850, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.7165  (0.6637601730631473)\n",
      "     | > loader_time: 0.0043  (0.0036881841236107017)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:32:57 -- STEP: 534/811 -- GLOBAL_STEP: 5400\u001b[0m\n",
      "     | > loss: 1.5163297653198242  (1.6497112646531524)\n",
      "     | > log_mle: 0.3414016366004944  (0.37452359542194835)\n",
      "     | > loss_dur: 1.174928069114685  (1.2751876702915876)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.0483, device='cuda:0')  (tensor(3.2768, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.7862  (0.6645888317836806)\n",
      "     | > loader_time: 0.0042  (0.003707783052537326)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:33:15 -- STEP: 559/811 -- GLOBAL_STEP: 5425\u001b[0m\n",
      "     | > loss: 1.585209846496582  (1.6457810783642135)\n",
      "     | > log_mle: 0.3527258038520813  (0.37311548170548653)\n",
      "     | > loss_dur: 1.2324841022491455  (1.272665597884942)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.1280, device='cuda:0')  (tensor(3.2697, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.718  (0.6663989304216689)\n",
      "     | > loader_time: 0.0042  (0.003737116968908977)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:33:33 -- STEP: 584/811 -- GLOBAL_STEP: 5450\u001b[0m\n",
      "     | > loss: 1.5851447582244873  (1.6419275745953599)\n",
      "     | > log_mle: 0.3499745726585388  (0.37171684812805433)\n",
      "     | > loss_dur: 1.2351701259613037  (1.2702107272327772)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.1050, device='cuda:0')  (tensor(3.2628, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.76  (0.6687010040838421)\n",
      "     | > loader_time: 0.0047  (0.0037616029994128517)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:33:51 -- STEP: 609/811 -- GLOBAL_STEP: 5475\u001b[0m\n",
      "     | > loss: 1.5128979682922363  (1.638267052193189)\n",
      "     | > log_mle: 0.3390321135520935  (0.37039160596326065)\n",
      "     | > loss_dur: 1.1738659143447876  (1.267875447453342)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.0888, device='cuda:0')  (tensor(3.2556, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.8219  (0.67097046065996)\n",
      "     | > loader_time: 0.0047  (0.003799772810661931)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:34:10 -- STEP: 634/811 -- GLOBAL_STEP: 5500\u001b[0m\n",
      "     | > loss: 1.5372755527496338  (1.6342429890993637)\n",
      "     | > log_mle: 0.35411906242370605  (0.3691105882546127)\n",
      "     | > loss_dur: 1.1831564903259277  (1.265132402019923)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.0699, device='cuda:0')  (tensor(3.2484, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.6958  (0.6742089937914053)\n",
      "     | > loader_time: 0.0047  (0.003837338757439744)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:34:29 -- STEP: 659/811 -- GLOBAL_STEP: 5525\u001b[0m\n",
      "     | > loss: 1.5303202867507935  (1.6304324944934638)\n",
      "     | > log_mle: 0.3509005308151245  (0.36786076878741586)\n",
      "     | > loss_dur: 1.179419755935669  (1.2625717271984271)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.0197, device='cuda:0')  (tensor(3.2411, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.7158  (0.6767103939751022)\n",
      "     | > loader_time: 0.0048  (0.003867237629405647)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:34:48 -- STEP: 684/811 -- GLOBAL_STEP: 5550\u001b[0m\n",
      "     | > loss: 1.5039052963256836  (1.6273439336589899)\n",
      "     | > log_mle: 0.32719558477401733  (0.36647002054759614)\n",
      "     | > loss_dur: 1.176709771156311  (1.260873914462085)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.1665, device='cuda:0')  (tensor(3.2361, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.6901  (0.6796209623939102)\n",
      "     | > loader_time: 0.0049  (0.0039032251514189435)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:35:08 -- STEP: 709/811 -- GLOBAL_STEP: 5575\u001b[0m\n",
      "     | > loss: 1.5145277976989746  (1.6240468613687788)\n",
      "     | > log_mle: 0.33750683069229126  (0.3651702855890996)\n",
      "     | > loss_dur: 1.1770209074020386  (1.2588765774190187)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.9645, device='cuda:0')  (tensor(3.2309, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.8876  (0.6826778850367095)\n",
      "     | > loader_time: 0.0056  (0.003936733278131956)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:35:27 -- STEP: 734/811 -- GLOBAL_STEP: 5600\u001b[0m\n",
      "     | > loss: 1.5085151195526123  (1.6200989488035193)\n",
      "     | > log_mle: 0.33677738904953003  (0.3638820923885141)\n",
      "     | > loss_dur: 1.1717376708984375  (1.2562168581609192)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.0229, device='cuda:0')  (tensor(3.2243, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.8549  (0.6857064959138864)\n",
      "     | > loader_time: 0.0048  (0.003966825534602277)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:35:47 -- STEP: 759/811 -- GLOBAL_STEP: 5625\u001b[0m\n",
      "     | > loss: 1.5033296346664429  (1.6163678145691338)\n",
      "     | > log_mle: 0.32370686531066895  (0.3626214065177951)\n",
      "     | > loss_dur: 1.179622769355774  (1.253746409818276)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.0169, device='cuda:0')  (tensor(3.2176, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.7784  (0.6888762456469216)\n",
      "     | > loader_time: 0.0063  (0.004005800279861066)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:36:06 -- STEP: 784/811 -- GLOBAL_STEP: 5650\u001b[0m\n",
      "     | > loss: 1.526179552078247  (1.6125467168737428)\n",
      "     | > log_mle: 0.3184947371482849  (0.3614250356521532)\n",
      "     | > loss_dur: 1.207684874534607  (1.2511216830842364)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.0624, device='cuda:0')  (tensor(3.2108, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.833  (0.6910862548618889)\n",
      "     | > loader_time: 0.0049  (0.00403679511985)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:36:24 -- STEP: 809/811 -- GLOBAL_STEP: 5675\u001b[0m\n",
      "     | > loss: 1.5027172565460205  (1.6089194124502362)\n",
      "     | > log_mle: 0.3298097252845764  (0.3601700344177051)\n",
      "     | > loss_dur: 1.1729074716567993  (1.2487493802060028)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.9814, device='cuda:0')  (tensor(3.2040, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.6383  (0.6919309977989987)\n",
      "     | > loader_time: 0.0048  (0.004063606556914789)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.004926159977912903 \u001b[0m(-0.0010706931352615356)\n",
      "     | > avg_loss:\u001b[92m 1.4469773098826408 \u001b[0m(-0.2365090474486351)\n",
      "     | > avg_log_mle:\u001b[92m 0.3279441297054291 \u001b[0m(-0.057550761848688126)\n",
      "     | > avg_loss_dur:\u001b[92m 1.1190331801772118 \u001b[0m(-0.17895826697349548)\n",
      "\n",
      " > BEST MODEL : tts_train_dir/run-February-28-2024_10+25PM-0000000/best_model_5677.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 7/10\u001b[0m\n",
      " --> tts_train_dir/run-February-28-2024_10+25PM-0000000\n",
      "\n",
      "\u001b[1m > TRAINING (2024-02-28 23:36:39) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:36:55 -- STEP: 23/811 -- GLOBAL_STEP: 5700\u001b[0m\n",
      "     | > loss: 1.5672709941864014  (1.561974250751993)\n",
      "     | > log_mle: 0.3429136276245117  (0.36029628567073657)\n",
      "     | > loss_dur: 1.2243573665618896  (1.2016779598982439)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.3191, device='cuda:0')  (tensor(3.1734, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.5659  (0.5877306772314983)\n",
      "     | > loader_time: 0.0027  (0.0027307738428530488)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:37:10 -- STEP: 48/811 -- GLOBAL_STEP: 5725\u001b[0m\n",
      "     | > loss: 1.5119106769561768  (1.519710898399353)\n",
      "     | > log_mle: 0.3683152198791504  (0.35701867068807286)\n",
      "     | > loss_dur: 1.1435954570770264  (1.162692221502463)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.0191, device='cuda:0')  (tensor(3.0827, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.5663  (0.588994801044464)\n",
      "     | > loader_time: 0.0029  (0.0028786311546961465)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:37:25 -- STEP: 73/811 -- GLOBAL_STEP: 5750\u001b[0m\n",
      "     | > loss: 1.4529705047607422  (1.5067465468628765)\n",
      "     | > log_mle: 0.37654125690460205  (0.3551133119896666)\n",
      "     | > loss_dur: 1.0764292478561401  (1.15163322670819)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.9741, device='cuda:0')  (tensor(3.0417, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.5874  (0.5940019431179516)\n",
      "     | > loader_time: 0.0033  (0.0029821820455054712)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:37:41 -- STEP: 98/811 -- GLOBAL_STEP: 5775\u001b[0m\n",
      "     | > loss: 1.473451852798462  (1.496949008532933)\n",
      "     | > log_mle: 0.34971851110458374  (0.3536678972292919)\n",
      "     | > loss_dur: 1.123733401298523  (1.1432811082625869)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.9633, device='cuda:0')  (tensor(3.0106, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.7149  (0.6019508254771332)\n",
      "     | > loader_time: 0.0044  (0.0030797525328032822)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:37:56 -- STEP: 123/811 -- GLOBAL_STEP: 5800\u001b[0m\n",
      "     | > loss: 1.514528751373291  (1.4910665983107032)\n",
      "     | > log_mle: 0.3425164818763733  (0.3502854990765331)\n",
      "     | > loss_dur: 1.172012209892273  (1.1407810963266265)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.9380, device='cuda:0')  (tensor(2.9980, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.6049  (0.6046898772076865)\n",
      "     | > loader_time: 0.0033  (0.0031203157533475053)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:38:12 -- STEP: 148/811 -- GLOBAL_STEP: 5825\u001b[0m\n",
      "     | > loss: 1.4984418153762817  (1.4844262688546568)\n",
      "     | > log_mle: 0.31346726417541504  (0.3478886831451107)\n",
      "     | > loss_dur: 1.1849745512008667  (1.1365375824876731)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.9791, device='cuda:0')  (tensor(2.9866, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.6199  (0.608737521880382)\n",
      "     | > loader_time: 0.0041  (0.003180550562368857)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:38:28 -- STEP: 173/811 -- GLOBAL_STEP: 5850\u001b[0m\n",
      "     | > loss: 1.3839099407196045  (1.4790310515144662)\n",
      "     | > log_mle: 0.3278830051422119  (0.3454255327323958)\n",
      "     | > loss_dur: 1.0560269355773926  (1.1336055167148569)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.8620, device='cuda:0')  (tensor(2.9754, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.6489  (0.6144037136452736)\n",
      "     | > loader_time: 0.0035  (0.0032257578965556415)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:38:45 -- STEP: 198/811 -- GLOBAL_STEP: 5875\u001b[0m\n",
      "     | > loss: 1.5217697620391846  (1.472651929566355)\n",
      "     | > log_mle: 0.32142144441604614  (0.3429078267078207)\n",
      "     | > loss_dur: 1.2003482580184937  (1.1297440992461316)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.1081, device='cuda:0')  (tensor(2.9675, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.6051  (0.6190347803963556)\n",
      "     | > loader_time: 0.0035  (0.0032846494154496627)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:39:02 -- STEP: 223/811 -- GLOBAL_STEP: 5900\u001b[0m\n",
      "     | > loss: 1.3338549137115479  (1.466278678633173)\n",
      "     | > log_mle: 0.30776792764663696  (0.34055560693612547)\n",
      "     | > loss_dur: 1.0260869264602661  (1.1257230674204808)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.6294, device='cuda:0')  (tensor(2.9538, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.6895  (0.624329853485518)\n",
      "     | > loader_time: 0.0036  (0.00334580703701139)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:39:18 -- STEP: 248/811 -- GLOBAL_STEP: 5925\u001b[0m\n",
      "     | > loss: 1.4223603010177612  (1.4617922979016462)\n",
      "     | > log_mle: 0.30826008319854736  (0.3382782404941897)\n",
      "     | > loss_dur: 1.1141002178192139  (1.1235140523602891)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.9412, device='cuda:0')  (tensor(2.9454, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.7104  (0.627800835717109)\n",
      "     | > loader_time: 0.0037  (0.003381706053210843)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:39:34 -- STEP: 273/811 -- GLOBAL_STEP: 5950\u001b[0m\n",
      "     | > loss: 1.4395853281021118  (1.4581721986169784)\n",
      "     | > log_mle: 0.32337141036987305  (0.33612539152522675)\n",
      "     | > loss_dur: 1.1162139177322388  (1.1220468025067791)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.8985, device='cuda:0')  (tensor(2.9397, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.73  (0.6296694462115948)\n",
      "     | > loader_time: 0.0034  (0.003423183392255734)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:39:52 -- STEP: 298/811 -- GLOBAL_STEP: 5975\u001b[0m\n",
      "     | > loss: 1.4414355754852295  (1.4550390479548672)\n",
      "     | > log_mle: 0.3176078200340271  (0.3341609327585106)\n",
      "     | > loss_dur: 1.1238278150558472  (1.1208781127961693)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.9074, device='cuda:0')  (tensor(2.9347, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.6821  (0.6355522911020576)\n",
      "     | > loader_time: 0.0038  (0.0034589183410542123)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:40:09 -- STEP: 323/811 -- GLOBAL_STEP: 6000\u001b[0m\n",
      "     | > loss: 1.4167089462280273  (1.4514320653289472)\n",
      "     | > log_mle: 0.3098136782646179  (0.3324920754683645)\n",
      "     | > loss_dur: 1.1068953275680542  (1.1189399876461674)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.9334, device='cuda:0')  (tensor(2.9293, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.6938  (0.6382589738804492)\n",
      "     | > loader_time: 0.0041  (0.0035111520312518896)\n",
      "\n",
      "\n",
      " > CHECKPOINT : tts_train_dir/run-February-28-2024_10+25PM-0000000/checkpoint_6000.pth\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:40:31 -- STEP: 348/811 -- GLOBAL_STEP: 6025\u001b[0m\n",
      "     | > loss: 1.418623447418213  (1.448226268949181)\n",
      "     | > log_mle: 0.30899471044540405  (0.3307294095384664)\n",
      "     | > loss_dur: 1.1096287965774536  (1.1174968566702694)\n",
      "     | > amp_scaler: 32768.0  (16996.04597701149)\n",
      "     | > grad_norm: tensor(2.7960, device='cuda:0')  (tensor(2.9255, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.7122  (0.6425844225390207)\n",
      "     | > loader_time: 0.0038  (0.0035529410702058637)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:40:47 -- STEP: 373/811 -- GLOBAL_STEP: 6050\u001b[0m\n",
      "     | > loss: 1.3984904289245605  (1.4446524851443632)\n",
      "     | > log_mle: 0.31360310316085815  (0.3290313608524947)\n",
      "     | > loss_dur: 1.0848873853683472  (1.1156211225340886)\n",
      "     | > amp_scaler: 32768.0  (18053.147453083107)\n",
      "     | > grad_norm: tensor(2.7964, device='cuda:0')  (tensor(2.9172, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.6751  (0.6432094056229171)\n",
      "     | > loader_time: 0.0044  (0.003581096275881852)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:41:05 -- STEP: 398/811 -- GLOBAL_STEP: 6075\u001b[0m\n",
      "     | > loss: 1.3648741245269775  (1.44166194763615)\n",
      "     | > log_mle: 0.3095545172691345  (0.3273258799284547)\n",
      "     | > loss_dur: 1.0553196668624878  (1.1143360671086517)\n",
      "     | > amp_scaler: 32768.0  (18977.44723618091)\n",
      "     | > grad_norm: tensor(2.7550, device='cuda:0')  (tensor(2.9156, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.7151  (0.6478587538752724)\n",
      "     | > loader_time: 0.0048  (0.0036230560523181706)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:41:23 -- STEP: 423/811 -- GLOBAL_STEP: 6100\u001b[0m\n",
      "     | > loss: 1.363944411277771  (1.4379625052706861)\n",
      "     | > log_mle: 0.2851203680038452  (0.32579887913755773)\n",
      "     | > loss_dur: 1.0788240432739258  (1.112163625146761)\n",
      "     | > amp_scaler: 32768.0  (19792.491725768326)\n",
      "     | > grad_norm: tensor(2.8135, device='cuda:0')  (tensor(2.9117, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.7356  (0.6503622560072734)\n",
      "     | > loader_time: 0.0038  (0.0036588870605396605)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:41:40 -- STEP: 448/811 -- GLOBAL_STEP: 6125\u001b[0m\n",
      "     | > loss: 1.3710459470748901  (1.43442832119763)\n",
      "     | > log_mle: 0.30559349060058594  (0.3242291270622185)\n",
      "     | > loss_dur: 1.0654524564743042  (1.1101991938693179)\n",
      "     | > amp_scaler: 32768.0  (20516.57142857143)\n",
      "     | > grad_norm: tensor(2.9864, device='cuda:0')  (tensor(2.9105, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.786  (0.652692931571177)\n",
      "     | > loader_time: 0.0048  (0.0036915849362100872)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:41:58 -- STEP: 473/811 -- GLOBAL_STEP: 6150\u001b[0m\n",
      "     | > loss: 1.3802156448364258  (1.4315453813141557)\n",
      "     | > log_mle: 0.3087717890739441  (0.3227769229679229)\n",
      "     | > loss_dur: 1.0714439153671265  (1.1087684578421746)\n",
      "     | > amp_scaler: 32768.0  (21164.109936575056)\n",
      "     | > grad_norm: tensor(2.7456, device='cuda:0')  (tensor(2.9062, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.7128  (0.6547736597363591)\n",
      "     | > loader_time: 0.0041  (0.0037264027504789903)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:42:15 -- STEP: 498/811 -- GLOBAL_STEP: 6175\u001b[0m\n",
      "     | > loss: 1.3584167957305908  (1.4286101051123754)\n",
      "     | > log_mle: 0.2905982732772827  (0.32132033878062144)\n",
      "     | > loss_dur: 1.067818522453308  (1.1072897659726881)\n",
      "     | > amp_scaler: 32768.0  (21746.634538152615)\n",
      "     | > grad_norm: tensor(2.7946, device='cuda:0')  (tensor(2.9012, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.6801  (0.6568461517732306)\n",
      "     | > loader_time: 0.0043  (0.0037592582434535504)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:42:33 -- STEP: 523/811 -- GLOBAL_STEP: 6200\u001b[0m\n",
      "     | > loss: 1.3639755249023438  (1.4258150742113258)\n",
      "     | > log_mle: 0.28835850954055786  (0.31980615409792723)\n",
      "     | > loss_dur: 1.0756170749664307  (1.1060089197714962)\n",
      "     | > amp_scaler: 32768.0  (22273.468451242832)\n",
      "     | > grad_norm: tensor(2.8436, device='cuda:0')  (tensor(2.8966, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.728  (0.6591833248648999)\n",
      "     | > loader_time: 0.004  (0.0037918879470679318)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:42:51 -- STEP: 548/811 -- GLOBAL_STEP: 6225\u001b[0m\n",
      "     | > loss: 1.3757343292236328  (1.4230820077614201)\n",
      "     | > log_mle: 0.2887343168258667  (0.31839233876144807)\n",
      "     | > loss_dur: 1.0870000123977661  (1.1046896688912025)\n",
      "     | > amp_scaler: 32768.0  (22752.23357664234)\n",
      "     | > grad_norm: tensor(2.8300, device='cuda:0')  (tensor(2.8922, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.6721  (0.66241035061161)\n",
      "     | > loader_time: 0.0048  (0.0038165119442626506)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:43:09 -- STEP: 573/811 -- GLOBAL_STEP: 6250\u001b[0m\n",
      "     | > loss: 1.3702318668365479  (1.4203125357003743)\n",
      "     | > log_mle: 0.26401495933532715  (0.3170784470506573)\n",
      "     | > loss_dur: 1.1062169075012207  (1.1032340887537375)\n",
      "     | > amp_scaler: 32768.0  (23189.221640488657)\n",
      "     | > grad_norm: tensor(2.8390, device='cuda:0')  (tensor(2.8882, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.7286  (0.6639410629738478)\n",
      "     | > loader_time: 0.0043  (0.003842330519857623)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:43:27 -- STEP: 598/811 -- GLOBAL_STEP: 6275\u001b[0m\n",
      "     | > loss: 1.3064336776733398  (1.4177910344656506)\n",
      "     | > log_mle: 0.27654165029525757  (0.31588264303063884)\n",
      "     | > loss_dur: 1.029892086982727  (1.1019083920330495)\n",
      "     | > amp_scaler: 32768.0  (23589.672240802676)\n",
      "     | > grad_norm: tensor(2.6131, device='cuda:0')  (tensor(2.8851, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.6583  (0.6661513425833405)\n",
      "     | > loader_time: 0.0042  (0.003867444784744926)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:43:46 -- STEP: 623/811 -- GLOBAL_STEP: 6300\u001b[0m\n",
      "     | > loss: 1.3464131355285645  (1.415152756781296)\n",
      "     | > log_mle: 0.2930251955986023  (0.3146589242436149)\n",
      "     | > loss_dur: 1.053387999534607  (1.1004938329203735)\n",
      "     | > amp_scaler: 32768.0  (23957.983948635636)\n",
      "     | > grad_norm: tensor(2.7316, device='cuda:0')  (tensor(2.8810, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.7271  (0.6699106142187963)\n",
      "     | > loader_time: 0.0043  (0.0038953791843371445)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:44:05 -- STEP: 648/811 -- GLOBAL_STEP: 6325\u001b[0m\n",
      "     | > loss: 1.2902181148529053  (1.4123290812159774)\n",
      "     | > log_mle: 0.2878996729850769  (0.3134229919056835)\n",
      "     | > loss_dur: 1.0023183822631836  (1.0989060900461514)\n",
      "     | > amp_scaler: 32768.0  (24297.87654320988)\n",
      "     | > grad_norm: tensor(2.6058, device='cuda:0')  (tensor(2.8776, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.8341  (0.6735123024310595)\n",
      "     | > loader_time: 0.0046  (0.003918418913711736)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:44:25 -- STEP: 673/811 -- GLOBAL_STEP: 6350\u001b[0m\n",
      "     | > loss: 1.2855770587921143  (1.4101557671403828)\n",
      "     | > log_mle: 0.2864444851875305  (0.3121675435359554)\n",
      "     | > loss_dur: 0.999132513999939  (1.097988224135819)\n",
      "     | > amp_scaler: 32768.0  (24612.517087667176)\n",
      "     | > grad_norm: tensor(2.5792, device='cuda:0')  (tensor(2.8743, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.7762  (0.6765252923894601)\n",
      "     | > loader_time: 0.0046  (0.003946750691882923)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:44:43 -- STEP: 698/811 -- GLOBAL_STEP: 6375\u001b[0m\n",
      "     | > loss: 1.3919475078582764  (1.4079396393374255)\n",
      "     | > log_mle: 0.2731795907020569  (0.3108900819603558)\n",
      "     | > loss_dur: 1.1187679767608643  (1.097049558231003)\n",
      "     | > amp_scaler: 32768.0  (24904.618911174795)\n",
      "     | > grad_norm: tensor(2.9622, device='cuda:0')  (tensor(2.8709, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.7635  (0.6781338162955032)\n",
      "     | > loader_time: 0.0045  (0.003970438908027713)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:45:02 -- STEP: 723/811 -- GLOBAL_STEP: 6400\u001b[0m\n",
      "     | > loss: 1.319859504699707  (1.405234234791409)\n",
      "     | > log_mle: 0.2799590229988098  (0.30964002421288095)\n",
      "     | > loss_dur: 1.0399004220962524  (1.0955942112380528)\n",
      "     | > amp_scaler: 32768.0  (25176.520055325043)\n",
      "     | > grad_norm: tensor(2.7751, device='cuda:0')  (tensor(2.8665, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.6947  (0.6804456704220166)\n",
      "     | > loader_time: 0.0057  (0.004001230619755028)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:45:21 -- STEP: 748/811 -- GLOBAL_STEP: 6425\u001b[0m\n",
      "     | > loss: 1.312286615371704  (1.4022356411990005)\n",
      "     | > log_mle: 0.2817842960357666  (0.3083851619519017)\n",
      "     | > loss_dur: 1.0305023193359375  (1.0938504801236357)\n",
      "     | > amp_scaler: 32768.0  (25430.24598930482)\n",
      "     | > grad_norm: tensor(2.5239, device='cuda:0')  (tensor(2.8618, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.7478  (0.6829772744586757)\n",
      "     | > loader_time: 0.0049  (0.00403152111379858)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:45:39 -- STEP: 773/811 -- GLOBAL_STEP: 6450\u001b[0m\n",
      "     | > loss: 1.351211428642273  (1.3995906271878997)\n",
      "     | > log_mle: 0.2789841890335083  (0.3073100657389053)\n",
      "     | > loss_dur: 1.0722272396087646  (1.0922805623742913)\n",
      "     | > amp_scaler: 32768.0  (25667.56015523934)\n",
      "     | > grad_norm: tensor(3.0329, device='cuda:0')  (tensor(2.8586, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.7867  (0.6848590077897398)\n",
      "     | > loader_time: 0.0048  (0.004065923518073512)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:45:58 -- STEP: 798/811 -- GLOBAL_STEP: 6475\u001b[0m\n",
      "     | > loss: 1.3306410312652588  (1.3967774957044985)\n",
      "     | > log_mle: 0.27267199754714966  (0.3060421343883479)\n",
      "     | > loss_dur: 1.057969093322754  (1.0907353620630742)\n",
      "     | > amp_scaler: 32768.0  (25890.00501253134)\n",
      "     | > grad_norm: tensor(2.7469, device='cuda:0')  (tensor(2.8583, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.7313  (0.687027761810704)\n",
      "     | > loader_time: 0.0051  (0.0040885054676753855)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.0050541311502456665 \u001b[0m(+0.00012797117233276367)\n",
      "     | > avg_loss:\u001b[92m 1.2783755287528038 \u001b[0m(-0.16860178112983704)\n",
      "     | > avg_log_mle:\u001b[92m 0.27563806995749474 \u001b[0m(-0.05230605974793434)\n",
      "     | > avg_loss_dur:\u001b[92m 1.0027374662458897 \u001b[0m(-0.1162957139313221)\n",
      "\n",
      " > BEST MODEL : tts_train_dir/run-February-28-2024_10+25PM-0000000/best_model_6488.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 8/10\u001b[0m\n",
      " --> tts_train_dir/run-February-28-2024_10+25PM-0000000\n",
      "\n",
      "\u001b[1m > TRAINING (2024-02-28 23:46:21) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:46:30 -- STEP: 12/811 -- GLOBAL_STEP: 6500\u001b[0m\n",
      "     | > loss: 1.290050983428955  (1.3946218689282734)\n",
      "     | > log_mle: 0.2996971011161804  (0.310586874683698)\n",
      "     | > loss_dur: 0.9903538227081299  (1.0840349793434143)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.7295, device='cuda:0')  (tensor(2.8529, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.7182  (0.5954227844874064)\n",
      "     | > loader_time: 0.0031  (0.002891381581624349)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:46:45 -- STEP: 37/811 -- GLOBAL_STEP: 6525\u001b[0m\n",
      "     | > loss: 1.3203915357589722  (1.347751975059509)\n",
      "     | > log_mle: 0.3152279853820801  (0.3041916586257316)\n",
      "     | > loss_dur: 1.005163550376892  (1.0435603148228414)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.7483, device='cuda:0')  (tensor(2.8323, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.5798  (0.5925971881763354)\n",
      "     | > loader_time: 0.0031  (0.0030162978816676784)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:47:01 -- STEP: 62/811 -- GLOBAL_STEP: 6550\u001b[0m\n",
      "     | > loss: 1.2945165634155273  (1.3246971503380802)\n",
      "     | > log_mle: 0.3103327751159668  (0.3037642048251244)\n",
      "     | > loss_dur: 0.9841837882995605  (1.0209329397447644)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.6905, device='cuda:0')  (tensor(2.7667, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.5968  (0.5980656377730829)\n",
      "     | > loader_time: 0.0033  (0.003070477516420426)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:47:16 -- STEP: 87/811 -- GLOBAL_STEP: 6575\u001b[0m\n",
      "     | > loss: 1.2365467548370361  (1.3155648598725769)\n",
      "     | > log_mle: 0.2980284094810486  (0.30286306896428944)\n",
      "     | > loss_dur: 0.9385184049606323  (1.0127017888529541)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.5602, device='cuda:0')  (tensor(2.7349, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.6451  (0.6025964035384954)\n",
      "     | > loader_time: 0.0032  (0.0031392848354646528)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:47:32 -- STEP: 112/811 -- GLOBAL_STEP: 6600\u001b[0m\n",
      "     | > loss: 1.250980019569397  (1.3105945491365019)\n",
      "     | > log_mle: 0.2837318778038025  (0.29967348756534706)\n",
      "     | > loss_dur: 0.9672481417655945  (1.0109210610389705)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.5690, device='cuda:0')  (tensor(2.7257, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.6059  (0.6073861462729317)\n",
      "     | > loader_time: 0.0032  (0.0031714694840567453)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:47:48 -- STEP: 137/811 -- GLOBAL_STEP: 6625\u001b[0m\n",
      "     | > loss: 1.2989885807037354  (1.3051563910324204)\n",
      "     | > log_mle: 0.28555601835250854  (0.29769874358699266)\n",
      "     | > loss_dur: 1.0134326219558716  (1.007457645705146)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.7961, device='cuda:0')  (tensor(2.7145, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.6466  (0.616799544243917)\n",
      "     | > loader_time: 0.0039  (0.0032465597138787708)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:48:05 -- STEP: 162/811 -- GLOBAL_STEP: 6650\u001b[0m\n",
      "     | > loss: 1.3339452743530273  (1.3013176432362303)\n",
      "     | > log_mle: 0.28816187381744385  (0.2951512031349135)\n",
      "     | > loss_dur: 1.0457834005355835  (1.006166437157878)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.7074, device='cuda:0')  (tensor(2.7068, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.6248  (0.6221913555522024)\n",
      "     | > loader_time: 0.0037  (0.0033386827986917377)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:48:21 -- STEP: 187/811 -- GLOBAL_STEP: 6675\u001b[0m\n",
      "     | > loss: 1.2035304307937622  (1.2948569518359585)\n",
      "     | > log_mle: 0.2367563247680664  (0.2922143400671646)\n",
      "     | > loss_dur: 0.9667741060256958  (1.0026426098563448)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.6455, device='cuda:0')  (tensor(2.6906, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.6935  (0.6267153490035929)\n",
      "     | > loader_time: 0.0043  (0.003425139156892338)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:48:39 -- STEP: 212/811 -- GLOBAL_STEP: 6700\u001b[0m\n",
      "     | > loss: 1.1997802257537842  (1.289951581437632)\n",
      "     | > log_mle: 0.2789270281791687  (0.2900992674085328)\n",
      "     | > loss_dur: 0.9208531379699707  (0.9998523131856369)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.4141, device='cuda:0')  (tensor(2.6876, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.7217  (0.6332646867014328)\n",
      "     | > loader_time: 0.0038  (0.0035044618372647267)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:48:56 -- STEP: 237/811 -- GLOBAL_STEP: 6725\u001b[0m\n",
      "     | > loss: 1.1681811809539795  (1.2852216430857206)\n",
      "     | > log_mle: 0.2859024405479431  (0.28786553813435345)\n",
      "     | > loss_dur: 0.8822788000106812  (0.997356104448374)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.2423, device='cuda:0')  (tensor(2.6789, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.6953  (0.6388977147355864)\n",
      "     | > loader_time: 0.0039  (0.0035708483764390906)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:49:13 -- STEP: 262/811 -- GLOBAL_STEP: 6750\u001b[0m\n",
      "     | > loss: 1.2066831588745117  (1.2813902319842618)\n",
      "     | > log_mle: 0.2800741195678711  (0.28571241161295463)\n",
      "     | > loss_dur: 0.9266089797019958  (0.9956778187788161)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.4200, device='cuda:0')  (tensor(2.6740, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.7612  (0.6433704800278176)\n",
      "     | > loader_time: 0.0043  (0.003610420773047527)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:49:30 -- STEP: 287/811 -- GLOBAL_STEP: 6775\u001b[0m\n",
      "     | > loss: 1.2532038688659668  (1.2793011424433471)\n",
      "     | > log_mle: 0.2524973154067993  (0.283487357952038)\n",
      "     | > loss_dur: 1.0007065534591675  (0.9958137822068104)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.6816, device='cuda:0')  (tensor(2.6750, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.6319  (0.646981337344605)\n",
      "     | > loader_time: 0.0038  (0.0036574573051638705)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:49:48 -- STEP: 312/811 -- GLOBAL_STEP: 6800\u001b[0m\n",
      "     | > loss: 1.2125072479248047  (1.2757392262036977)\n",
      "     | > log_mle: 0.2476576566696167  (0.28195005445144106)\n",
      "     | > loss_dur: 0.9648496508598328  (0.9937891700328917)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.6569, device='cuda:0')  (tensor(2.6674, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.6405  (0.650042760066497)\n",
      "     | > loader_time: 0.0042  (0.0036995273370009187)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:50:05 -- STEP: 337/811 -- GLOBAL_STEP: 6825\u001b[0m\n",
      "     | > loss: 1.2304357290267944  (1.2731368258728113)\n",
      "     | > log_mle: 0.2674904465675354  (0.28016900485630214)\n",
      "     | > loss_dur: 0.962945282459259  (0.9929678197784304)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.5948, device='cuda:0')  (tensor(2.6643, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.7399  (0.6531160648923245)\n",
      "     | > loader_time: 0.0045  (0.0037445265037015906)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:50:23 -- STEP: 362/811 -- GLOBAL_STEP: 6850\u001b[0m\n",
      "     | > loss: 1.1928088665008545  (1.2701593347675888)\n",
      "     | > log_mle: 0.2565966248512268  (0.27866096819303315)\n",
      "     | > loss_dur: 0.9362122416496277  (0.9914983662452481)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.4620, device='cuda:0')  (tensor(2.6654, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.7575  (0.657809473532998)\n",
      "     | > loader_time: 0.0052  (0.0037893010766466666)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:50:42 -- STEP: 387/811 -- GLOBAL_STEP: 6875\u001b[0m\n",
      "     | > loss: 1.2019062042236328  (1.2677230489962479)\n",
      "     | > log_mle: 0.23908138275146484  (0.27680547169628705)\n",
      "     | > loss_dur: 0.962824821472168  (0.9909175766838916)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.7286, device='cuda:0')  (tensor(2.6631, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.7704  (0.662062706565364)\n",
      "     | > loader_time: 0.004  (0.0038223328208430475)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:51:00 -- STEP: 412/811 -- GLOBAL_STEP: 6900\u001b[0m\n",
      "     | > loss: 1.259411334991455  (1.2648746570915852)\n",
      "     | > log_mle: 0.24203991889953613  (0.2755023362567125)\n",
      "     | > loss_dur: 1.017371416091919  (0.9893723204008579)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.7511, device='cuda:0')  (tensor(2.6633, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.8629  (0.6656679898789786)\n",
      "     | > loader_time: 0.0053  (0.003855985345192325)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:51:18 -- STEP: 437/811 -- GLOBAL_STEP: 6925\u001b[0m\n",
      "     | > loss: 1.2303918600082397  (1.261670620545097)\n",
      "     | > log_mle: 0.26556873321533203  (0.27394245922974647)\n",
      "     | > loss_dur: 0.9648231267929077  (0.9877281599513994)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.5766, device='cuda:0')  (tensor(2.6594, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.6549  (0.6684499872631012)\n",
      "     | > loader_time: 0.0045  (0.0038857590961238054)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:51:36 -- STEP: 462/811 -- GLOBAL_STEP: 6950\u001b[0m\n",
      "     | > loss: 1.2039289474487305  (1.258738976794404)\n",
      "     | > log_mle: 0.22678112983703613  (0.27250892981822344)\n",
      "     | > loss_dur: 0.9771477580070496  (0.9862300464601222)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.6430, device='cuda:0')  (tensor(2.6569, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.7613  (0.6714148970393391)\n",
      "     | > loader_time: 0.0041  (0.003914263341333956)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:51:55 -- STEP: 487/811 -- GLOBAL_STEP: 6975\u001b[0m\n",
      "     | > loss: 1.234037160873413  (1.2564985886736328)\n",
      "     | > log_mle: 0.24616968631744385  (0.2709277013978428)\n",
      "     | > loss_dur: 0.987867534160614  (0.9855708865414405)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.7286, device='cuda:0')  (tensor(2.6528, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.7394  (0.6742827642624872)\n",
      "     | > loader_time: 0.0043  (0.00394391230244411)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 23:52:13 -- STEP: 512/811 -- GLOBAL_STEP: 7000\u001b[0m\n",
      "     | > loss: 1.1667492389678955  (1.254100661026314)\n",
      "     | > log_mle: 0.2464638352394104  (0.26966878026723845)\n",
      "     | > loss_dur: 0.9202853441238403  (0.9844318802934136)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.5160, device='cuda:0')  (tensor(2.6491, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.7309  (0.6769079747609794)\n",
      "     | > loader_time: 0.0043  (0.003974258434027432)\n",
      "\n",
      "\n",
      " > CHECKPOINT : tts_train_dir/run-February-28-2024_10+25PM-0000000/checkpoint_7000.pth\n"
     ]
    }
   ],
   "source": [
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a85cd3b-1646-40ad-a6c2-49323e08eeec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5a85cd3b-1646-40ad-a6c2-49323e08eeec",
    "outputId": "c9e5247f-4281-4047-a0d8-cdedbf2d5913"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-29 18:07:55.413822: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-29 18:07:55.413880: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-29 18:07:55.415358: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-29 18:07:55.423175: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-29 18:07:56.458353: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.15.2 at http://localhost:6006/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "# !pip install tensorboard\n",
    "!tensorboard --logdir tts_train_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6dd47ed5-da8e-4bf9-b524-d686630d6961",
   "metadata": {
    "id": "6dd47ed5-da8e-4bf9-b524-d686630d6961"
   },
   "outputs": [],
   "source": [
    "import glob, os\n",
    "output_path = \"tts_train_dir\"\n",
    "ckpts = sorted([f for f in glob.glob(output_path+\"/*/*.pth\")])\n",
    "configs = sorted([f for f in glob.glob(output_path+\"/*/*.json\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd42bc7a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dd42bc7a",
    "outputId": "5c66bf40-45d4-495b-8a6a-9f84eee2d4a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Using model: glow_tts\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:True\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:45\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Text: Text for TTS\n",
      " > Text splitted to sentences.\n",
      "['Text for TTS']\n",
      " > Processing time: 0.5726485252380371\n",
      " > Real-time factor: 0.6844590189450737\n",
      " > Saving output to out.wav\n"
     ]
    }
   ],
   "source": [
    " !tts --text \"Text for TTS\" \\\n",
    "      --model_path tts_train_dir/run-February-28-2024_10+25PM-0000000/checkpoint_7000.pth \\\n",
    "      --config_path /content/tts_train_dir/run-February-28-2024_10+25PM-0000000/config.json \\\n",
    "      --out_path out.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0000bd6-6763-4a10-a74d-911dd08ebcff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "e0000bd6-6763-4a10-a74d-911dd08ebcff",
    "outputId": "d82ff064-94b8-4782-e8d6-a0ac7133950e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" >\n",
       "                    <source src=\"data:audio/x-wav;base64,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\" type=\"audio/x-wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "IPython.display.Audio(\"out.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950d9fc6-896f-4a2c-86fd-8fd1fcbbb3f7",
   "metadata": {
    "id": "950d9fc6-896f-4a2c-86fd-8fd1fcbbb3f7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
